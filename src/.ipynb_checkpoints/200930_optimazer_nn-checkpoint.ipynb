{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from utils import Paramset\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from neuralnetwork import NNClassifier\n",
    "import optuna\n",
    "\n",
    "\n",
    "class Objective:\n",
    "     \n",
    "    '''\n",
    "    # Usage\n",
    "    obj = Objective(LGBMRegressor(), X, y)\n",
    "    study = optuna.create_study(\n",
    "        sampler=optuna.samplers.RandomSampler(seed=123))\n",
    "    study.optimize(obj, n_trials=10, n_jobs=-1)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, x, y):\n",
    "        self.model = model\n",
    "        self.model_type = type(self.model).__name__\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_splits = 5\n",
    "        self.random_state = 1214\n",
    "        self.early_stopping_rounds = 20\n",
    "        paramset = Paramset(self.model)\n",
    "        paramset.swiching_lr('params_search')\n",
    "        self.PARAMS = paramset.generate_params()\n",
    "    \n",
    "    def __call__(self, trial):\n",
    "        if self.model_type == 'LGBMClassifier':\n",
    "            SPACE = {\n",
    "                'num_leaves': trial.suggest_int(\n",
    "                'num_leaves', 32, 2*32),\n",
    "                'subsample': trial.suggest_uniform('subsample', 0.60, 0.80),\n",
    "                'colsample_bytree': trial.suggest_uniform(\n",
    "                    'colsample_bytree', 0.60, 0.80),\n",
    "                'bagging_freq': trial.suggest_int(\n",
    "                    'bagging_freq', 1, 51, 5),\n",
    "                'min_child_weight': trial.suggest_loguniform(\n",
    "                    'min_child_weight', 1, 32),\n",
    "                'min_child_samples': int(trial.suggest_discrete_uniform(\n",
    "                    'min_child_samples', 128, 512, 16)),\n",
    "                'min_split_gain': trial.suggest_loguniform(\n",
    "                    'min_split_gain', 1e-5, 1e-1)\n",
    "            }\n",
    "            self.PARAMS.update(SPACE)\n",
    "            # cross validation\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits,\n",
    "            random_state=self.random_state, shuffle=True)\n",
    "            LOGLOSS = []\n",
    "            for tr_idx, va_idx in skf.split(self.x, self.y):\n",
    "                clf = Trainer(LGBMClassifier(**self.PARAMS))\n",
    "                clf.fit(\n",
    "                    self.x[tr_idx],\n",
    "                    self.y[tr_idx],\n",
    "                    self.x[va_idx],\n",
    "                    self.y[va_idx],\n",
    "                    self.early_stopping_rounds\n",
    "                )\n",
    "                y_pred = clf.predict_proba(self.x[va_idx])  # best_iteration\n",
    "                logloss = log_loss(self.y[va_idx], y_pred)\n",
    "                LOGLOSS.append(logloss)\n",
    "            return np.mean(LOGLOSS)\n",
    "        elif self.model_type == 'XGBClassifier':\n",
    "            SPACE = {\n",
    "                'subsample': trial.suggest_uniform(\n",
    "                    'subsample', 0.65, 0.85),\n",
    "                'colsample_bytree': trial.suggest_uniform(\n",
    "                    'colsample_bytree', 0.65, 0.80),\n",
    "                'gamma': trial.suggest_loguniform(\n",
    "                    'gamma', 1e-8, 1.0),\n",
    "                'min_child_weight': trial.suggest_loguniform(\n",
    "                    'min_child_weight', 1, 32)\n",
    "            }\n",
    "            self.PARAMS.update(SPACE)\n",
    "            # cross validation\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits,\n",
    "            random_state=self.random_state, shuffle=True)\n",
    "            LOGLOSS = []\n",
    "            for tr_idx, va_idx in skf.split(self.x, self.y):\n",
    "                clf = Trainer(XGBClassifier(**self.PARAMS))\n",
    "                clf.fit(\n",
    "                    self.x[tr_idx],\n",
    "                    self.y[tr_idx],\n",
    "                    self.x[va_idx],\n",
    "                    self.y[va_idx],\n",
    "                    self.early_stopping_rounds\n",
    "                )\n",
    "                y_pred = clf.predict_proba(self.x[va_idx])  # best_iteration\n",
    "                logloss = log_loss(self.y[va_idx], y_pred)\n",
    "                LOGLOSS.append(logloss)\n",
    "            return np.mean(LOGLOSS)\n",
    "        elif self.model_type == 'NNClassifier':\n",
    "            SPACE = {\n",
    "                \"input_dropout\": trial.suggest_uniform(\n",
    "                    \"input_dropout\", 0.0, 1.0),\n",
    "                \"hidden_layers\": trial.suggest_int(\n",
    "                    \"hidden_layers\", 1, 3),\n",
    "                'hidden_units': int(trial.suggest_discrete_uniform(\n",
    "                    'hidden_units', 64, 1024, 64)),\n",
    "                'hidden_dropout': trial.suggest_uniform(\n",
    "                    'hidden_dropout', 0.0, 1.0),\n",
    "                'batch_norm': trial.suggest_categorical(\n",
    "                'batch_norm', ['before_act', 'non']),\n",
    "                'batch_size': int(trial.suggest_discrete_uniform(\n",
    "                    'batch_size', 16, 96, 16))\n",
    "            }\n",
    "            self.PARAMS.update(SPACE)\n",
    "            self.PARAMS['input_shape'] = self.x.shape[1]\n",
    "            print(self.PARAMS)\n",
    "            # cross validation\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits,\n",
    "            random_state=self.random_state, shuffle=True)\n",
    "            LOGLOSS = []\n",
    "            for tr_idx, va_idx in skf.split(self.x, self.y):\n",
    "                clf = Trainer(NNClassifier(**self.PARAMS))\n",
    "                clf.fit(\n",
    "                    self.x[tr_idx],\n",
    "                    self.y[tr_idx],\n",
    "                    self.x[va_idx],\n",
    "                    self.y[va_idx],\n",
    "                    self.early_stopping_rounds\n",
    "                )\n",
    "                y_pred = clf.predict_proba(self.x[va_idx])\n",
    "                logloss = clf.get_model().history.history[\"val_loss\"][-(self.early_stopping_rounds+1)]\n",
    "                LOGLOSS.append(logloss)\n",
    "            return np.mean(LOGLOSS)\n",
    "            \n",
    "def optuna_search(obj, n_trials, n_jobs, random_state):\n",
    "    study = optuna.create_study(\n",
    "        sampler=optuna.samplers.RandomSampler(seed=random_state))\n",
    "    study.optimize(obj, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "brest_c = load_breast_cancer()\n",
    "X = brest_c['data']\n",
    "y = brest_c['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type is LGBMClassifiermodel type is LGBMClassifiermodel type is LGBMClassifier\n",
      "\n",
      "None\n",
      "None\n",
      "\n",
      "None\n",
      "model type is LGBMClassifier\n",
      "Nonemodel type is LGBMClassifiermodel type is LGBMClassifier\n",
      "\n",
      "\n",
      "NoneNone\n",
      "\n",
      "model type is LGBMClassifier\n",
      "None\n",
      "model type is LGBMClassifiermodel type is LGBMClassifier\n",
      "\n",
      "NoneNone\n",
      "\n",
      "model type is LGBMClassifier\n",
      "None\n",
      "model type is LGBMClassifiermodel type is LGBMClassifier\n",
      "\n",
      "NoneNone\n",
      "\n",
      "model type is LGBMClassifier\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-30 16:15:18,561] Finished trial#0 with value: 0.6603343289651606 with parameters: {'num_leaves': 32, 'subsample': 0.7205526752143288, 'colsample_bytree': 0.7089766365993794, 'bagging_freq': 46, 'min_child_weight': 8.680742718279156, 'min_child_samples': 272.0, 'min_split_gain': 0.00015493103643906671}. Best is trial#0 with value: 0.6603343289651606."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type is LGBMClassifiermodel type is LGBMClassifier"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NoneNone\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-30 16:15:19,576] Finished trial#1 with value: 0.6603343289651606 with parameters: {'num_leaves': 56, 'subsample': 0.7927325521002059, 'colsample_bytree': 0.6766883037651555, 'bagging_freq': 31, 'min_child_weight': 16.689208658650642, 'min_child_samples': 304.0, 'min_split_gain': 0.00037251107093913994}. Best is trial#0 with value: 0.6603343289651606.\n",
      "[I 2020-09-30 16:15:19,577] Finished trial#2 with value: 0.6603343289651606 with parameters: {'num_leaves': 57, 'subsample': 0.6142072116395774, 'colsample_bytree': 0.6174258599403081, 'bagging_freq': 16, 'min_child_weight': 3.583098488008466, 'min_child_samples': 496.0, 'min_split_gain': 3.642529868570474e-05}. Best is trial#0 with value: 0.6603343289651606.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 32,\n",
       " 'subsample': 0.7205526752143288,\n",
       " 'colsample_bytree': 0.7089766365993794,\n",
       " 'bagging_freq': 46,\n",
       " 'min_child_weight': 8.680742718279156,\n",
       " 'min_child_samples': 272.0,\n",
       " 'min_split_gain': 0.00015493103643906671}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials = 3\n",
    "n_jobs=-1\n",
    "random_state=0\n",
    "obj = Objective(LGBMClassifier(), X, y)\n",
    "optuna_search(obj, n_trials, n_jobs, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from utils import Paramset\n",
    "from neuralnetwork import NNClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "def obj(trial):\n",
    "    early_stopping_rounds = 10\n",
    "    n_splits = 3\n",
    "    random_state = 0\n",
    "    paramset = Paramset(NNClassifier())\n",
    "    paramset.swiching_lr('params_search')\n",
    "    PARAMS = paramset.generate_params()\n",
    "    \n",
    "    SPACE = {\n",
    "        \"input_dropout\": trial.suggest_uniform(\n",
    "            \"input_dropout\", 0.0, 1.0),\n",
    "        \"hidden_layers\": trial.suggest_int(\n",
    "            \"hidden_layers\", 1, 3),\n",
    "        'hidden_units': int(trial.suggest_discrete_uniform(\n",
    "            'hidden_units', 64, 1024, 64)),\n",
    "        'hidden_dropout': trial.suggest_uniform(\n",
    "            'hidden_dropout', 0.0, 1.0),\n",
    "        'batch_norm': trial.suggest_categorical(\n",
    "        'batch_norm', ['before_act', 'non']),\n",
    "        'batch_size': int(trial.suggest_discrete_uniform(\n",
    "            'batch_size', 16, 96, 16))\n",
    "    }\n",
    "    PARAMS.update(SPACE)\n",
    "    PARAMS['input_shape'] = x.shape[1]\n",
    "    print(PARAMS)\n",
    "    # cross validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits,\n",
    "    random_state=random_state, shuffle=True)\n",
    "    LOGLOSS = []\n",
    "    for tr_idx, va_idx in skf.split(x, y):\n",
    "        clf = Trainer(NNClassifier(**PARAMS))\n",
    "        clf.fit(\n",
    "            x[tr_idx],\n",
    "            y[tr_idx],\n",
    "            x[va_idx],\n",
    "            y[va_idx],\n",
    "            early_stopping_rounds\n",
    "        )\n",
    "        y_pred = clf.predict_proba(x[va_idx])\n",
    "        logloss = clf.get_model().history.history[\"val_loss\"][-(early_stopping_rounds+1)]\n",
    "        LOGLOSS.append(logloss)\n",
    "    return np.mean(LOGLOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.5488135039273248, 'hidden_layers': 2, 'hidden_units': 896, 'hidden_dropout': 0.8579456176227568, 'batch_norm': 'non', 'batch_size': 48, 'epochs': 10000}{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.6458941130666561, 'hidden_layers': 1, 'hidden_units': 320, 'hidden_dropout': 0.05671297731744318, 'batch_norm': 'before_act', 'batch_size': 48, 'epochs': 10000}\n",
      "\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "379/379 [==============================] - ETA: 2s - loss: 1.2222 - accuracy: 0.39 - ETA: 0s - loss: 2.6618 - accuracy: 0.69 - 1s 1ms/step - loss: 2.7279 - accuracy: 0.7256 - val_loss: 0.6089 - val_accuracy: 0.9579\n",
      "Epoch 2/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.91 - ETA: 0s - loss: 2.0995 - accuracy: 0.86 - 0s 318us/step - loss: 2.0174 - accuracy: 0.8681 - val_loss: 0.7579 - val_accuracy: 0.9526\n",
      "Epoch 3/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.9965 - accuracy: 0.87 - ETA: 0s - loss: 1.7322 - accuracy: 0.8917 - ETA: 4s - loss: 0.6928 - accuracy: 0.60 - 0s 367us/step - loss: 1.5956 - accuracy: 0.8997 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 4/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.0037 - accuracy: 0.93 - ETA: 0s - loss: 1.6151 - accuracy: 0.89 - 0s 315us/step - loss: 1.5146 - accuracy: 0.9050 - val_loss: 1.0542 - val_accuracy: 0.9316\n",
      "Epoch 5/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.6716 - accuracy: 0.89 - ETA: 0s - loss: 1.8739 - accuracy: 0.88 - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8654 - val_loss: 0.2487 - val_accuracy: 0.9158\n",
      "379/379 [==============================] - 0s 371us/step - loss: 1.6535 - accuracy: 0.8971 - val_loss: 0.9774 - val_accuracy: 0.9368\n",
      "Epoch 6/10000\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.6680 - accuracy: 0.8958Epoch 2/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 2.0952 - accuracy: 0.86 - 0s 228us/step - loss: 0.2359 - accuracy: 0.9261 - val_loss: 0.2429 - val_accuracy: 0.9632\n",
      "Epoch 3/10000\n",
      " - 0s 448us/step - loss: 1.8765 - accuracy: 0.8813 - val_loss: 0.8455 - val_accuracy: 0.9474\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000Epoch 7/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.89 - ETA: 0s - loss: 0.1608 - accuracy: 0.95 - ETA: 0s - loss: 1.2596 - accuracy: 0. - 0s 331us/step - loss: 0.1557 - accuracy: 0.9525 - val_loss: 0.2195 - val_accuracy: 0.9579\n",
      "336/379 [=========================>....] - ETA: 0s - loss: 1.3887 - accuracy: 0.9107Epoch 4/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.95 - 0s 444us/step - loss: 1.4420 - accuracy: 0.9077 - val_loss: 0.8201 - val_accuracy: 0.9474\n",
      "Epoch 8/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 1.0001 - accuracy: 0.9375 - 0s 176us/step - loss: 0.2505 - accuracy: 0.9103 - val_loss: 0.1501 - val_accuracy: 0.9632\n",
      "Epoch 5/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.93 - ETA: 0s - loss: 1.3359 - accuracy: 0.91 - 0s 172us/step - loss: 0.1976 - accuracy: 0.9261 - val_loss: 0.1323 - val_accuracy: 0.9474\n",
      "Epoch 6/10000\n",
      "379/379 [==============================] - 0s 410us/step - loss: 1.4371 - accuracy: 0.9103 - val_loss: 0.8437 - val_accuracy: 0.9474\n",
      "Epoch 9/10000 48/379 [==>...........................]\n",
      "379/379 [==============================]9792 - ETA: 0s - loss: 1.0113 - accuracy: 0.93 - 0s 182us/step - loss: 0.1425 - accuracy: 0.9499 - val_loss: 0.1749 - val_accuracy: 0.9684\n",
      "240/379 [=================>............]\n",
      " 48/379 [==>...........................]9250 - ETA: 0s - loss: 0.1227 - accuracy: 0.379/379 [==============================] - 0s 413us/step - loss: 1.3888 - accuracy: 0.9129 - val_loss: 0.5892 - val_accuracy: 0.9632\n",
      "379/379 [==============================] - 0s 198us/step - loss: 0.1337 - accuracy: 0.9393 - val_loss: 0.1669 - val_accuracy: 0.9684\n",
      "Epoch 10/10000Epoch 8/10000\n",
      "\n",
      " - 0s 167us/step - loss: 0.1857 - accuracy: 0.9129 - val_loss: 0.1515 - val_accuracy: 0.95260s - loss: 1.0037 - accuracy: 0.\n",
      "192/379 [==============>...............] - ETA: 0s - loss: 1.5805 - accuracy: 0.9010Epoch 9/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.91 - ETA: 0s - loss: 1.4735 - accuracy: 0.90 - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - 0s 433us/step - loss: 1.3905 - accuracy: 0.9129 - val_loss: 0.5892 - val_accuracy: 0.9632\n",
      "Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.3249 - accuracy: 0.85 - 0s 311us/step - loss: 0.1767 - accuracy: 0.9261 - val_loss: 0.1340 - val_accuracy: 0.9632\n",
      "Epoch 10/10000\n",
      "379/379 [==============================]8917 48/379 [==>...........................] - ETA: 0s - loss: 0.0495 - accuracy: 1.00 - ETA: 0s - loss: 0.1466 - accuracy: 0.94 - 0s 356us/step - loss: 1.7307 - accuracy: 0.8918 - val_loss: 0.8409 - val_accuracy: 0.9474\n",
      "Epoch 12/10000\n",
      " - 0s 227us/step - loss: 0.1431 - accuracy: 0.9393 - val_loss: 0.1309 - val_accuracy: 0.9579\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 2.3323 - accuracy: 0.8542Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.95 - ETA: 0s - loss: 2.1662 - accuracy: 0.86 - 0s 227us/step - loss: 0.1505 - accuracy: 0.9393 - val_loss: 0.1292 - val_accuracy: 0.9579\n",
      "Epoch 12/10000336/379 [=========================>....]\n",
      "379/379 [==============================]8571 - ETA: 0s - loss: 0.0982 - accuracy: 0.95 - 0s 430us/step - loss: 2.2789 - accuracy: 0.8575 - val_loss: 0.8409 - val_accuracy: 0.9474\n",
      "Epoch 13/10000\n",
      " - 0s 167us/step - loss: 0.2032 - accuracy: 0.9340 - val_loss: 0.1359 - val_accuracy: 0.9632\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.9965 - accuracy: 0.8750Epoch 13/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 1.9315 - accuracy: 0.87 - 0s 187us/step - loss: 0.1511 - accuracy: 0.9420 - val_loss: 0.1398 - val_accuracy: 0.9579\n",
      "Epoch 14/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.91 - 0s 374us/step - loss: 1.9195 - accuracy: 0.8786 - val_loss: 0.8351 - val_accuracy: 0.9474\n",
      "Epoch 14/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 0.6679 - accuracy: 0.9583 - 0s 158us/step - loss: 0.1637 - accuracy: 0.9393 - val_loss: 0.1376 - val_accuracy: 0.9526\n",
      "Epoch 15/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.83 - ETA: 0s - loss: 1.9359 - accuracy: 0.87 - 0s 169us/step - loss: 0.1977 - accuracy: 0.9103 - val_loss: 0.1438 - val_accuracy: 0.9526\n",
      "Epoch 16/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.97 - 0s 416us/step - loss: 1.6475 - accuracy: 0.8971 - val_loss: 0.6750 - val_accuracy: 0.9579\n",
      "Epoch 15/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 1.3322 - accuracy: 0.9167 - 0s 170us/step - loss: 0.2316 - accuracy: 0.8945 - val_loss: 0.1413 - val_accuracy: 0.9579\n",
      "Epoch 17/10000\n",
      "192/379 [==============>...............] - ETA: 0s - loss: 0.2186 - accuracy: 0.89 - ETA: 0s - loss: 1.6707 - accuracy: 0.336/379 [=========================>....]379/379 [==============================] - ETA: 0s - loss: 1.4766 - accuracy: 0.9077 - 0s 214us/step - loss: 0.1812 - accuracy: 0.9050 - val_loss: 0.1385 - val_accuracy: 0.9474\n",
      "Epoch 18/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 449us/step - loss: 1.4358 - accuracy: 0.9103 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 16/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.0037 - accuracy: 0.93 - 0s 164us/step - loss: 0.1400 - accuracy: 0.9525 - val_loss: 0.1360 - val_accuracy: 0.9526\n",
      "192/379 [==============>...............]\n",
      "379/379 [==============================]8958 - ETA: 0s - loss: 0.1393 - accuracy: 0.95 - ETA: 0s - loss: 1.6221 - accuracy: 0.89 - ETA: 0s - loss: 0.2141 - accuracy: 0.91 - 0s 450us/step - loss: 1.6077 - accuracy: 0.8997 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 17/10000\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.0001 - accuracy: 0.9375379/379 [==============================] - 0s 335us/step - loss: 0.1856 - accuracy: 0.9288 - val_loss: 0.1436 - val_accuracy: 0.9526\n",
      "Epoch 20/10000\n",
      "240/379 [=================>............] - ETA: 0s - loss: 0.1511 - accuracy: 0.91 - ETA: 0s - loss: 1.8030 - accuracy: 0.88336/379 [=========================>....]379/379 [==============================] - ETA: 0s - loss: 1.6237 - accuracy: 0.8988 - 0s 207us/step - loss: 0.1578 - accuracy: 0.9314 - val_loss: 0.1528 - val_accuracy: 0.9579\n",
      "Epoch 21/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.93 - 0s 432us/step - loss: 1.6086 - accuracy: 0.8997 - val_loss: 0.8446 - val_accuracy: 0.9474\n",
      "Epoch 18/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.6790 - accuracy: 0.83 - 0s 157us/step - loss: 0.1759 - accuracy: 0.9208 - val_loss: 0.1529 - val_accuracy: 0.9474\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.4285 - accuracy: 0.90 - 0s 395us/step - loss: 1.6257 - accuracy: 0.8971 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 19/10000\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 2.3359 - accuracy: 0.8542model type is NNClassifier\n",
      "None\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.8023 - accuracy: 0.88 - 0s 353us/step - loss: 1.6493 - accuracy: 0.8971 - val_loss: 0.7589 - val_accuracy: 0.9526\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "379/379 [==============================] - ETA: 3s - loss: 0.7040 - accuracy: 0.66 - ETA: 0s - loss: 2.8724 - accuracy: 0.74 - 1s 2ms/step - loss: 2.8814 - accuracy: 0.7599 - val_loss: 0.9142 - val_accuracy: 0.9368\n",
      "Epoch 2/10000\n",
      "379/379 [==============================]9028TA: 0s - loss: 0.3358 - accuracy: 0.97 48/379 [==>...........................] - ETA: 4s - loss: 0.7246 - accuracy: 0.60 - 0s 318us/step - loss: 1.6461 - accuracy: 0.8971 - val_loss: 1.5113 - val_accuracy: 0.9053\n",
      "Epoch 3/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.91 - ETA: 0s - loss: 2.1276 - accuracy: 0.86 - 0s 329us/step - loss: 2.1641 - accuracy: 0.8628 - val_loss: 1.3434 - val_accuracy: 0.9158\n",
      "Epoch 4/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.6571 - accuracy: 0.83 - ETA: 0s - loss: 1.9087 - accuracy: 0.87 - 0s 346us/step - loss: 1.7261 - accuracy: 0.8892 - val_loss: 1.0945 - val_accuracy: 0.9316\n",
      "379/379 [==============================]\n",
      " - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8575 - val_loss: 0.2120 - val_accuracy: 0.9632\n",
      "240/379 [=================>............] - ETA: 0s - loss: 2.3359 - accuracy: 0.85 - ETA: 0s - loss: 1.8680 - accuracy: 0.8833Epoch 2/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.93 - 0s 360us/step - loss: 1.6900 - accuracy: 0.8945 - val_loss: 1.0945 - val_accuracy: 0.9316\n",
      "Epoch 6/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.8518 - accuracy: 0.87 - 0s 179us/step - loss: 0.3738 - accuracy: 0.9208 - val_loss: 0.3937 - val_accuracy: 0.9421\n",
      "Epoch 3/10000\n",
      "379/379 [==============================]9000 48/379 [==>...........................] - ETA: 0s - loss: 0.3481 - accuracy: 0.89 - ETA: 0s - loss: 0.2350 - accuracy: 0.93 - 0s 384us/step - loss: 1.9661 - accuracy: 0.8760 - val_loss: 1.0087 - val_accuracy: 0.9368\n",
      "Epoch 7/10000\n",
      "379/379 [==============================] - 0s 234us/step - loss: 0.2233 - accuracy: 0.9367 - val_loss: 0.0930 - val_accuracy: 0.9579\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.3537 - accuracy: 0.8958Epoch 4/10000\n",
      " - ETA: 0s - loss: 1.5725 - accuracy: 0.8988TA: 0s - loss: 0.1717 - accuracy: 0.91 - ETA: 0s - loss: 1.6697 - accuracy: 0.89 - ETA: 0s - loss: 0.4202 - accuracy: 0.8336/379 [=========================>....]379/379 [==============================] - 0s 277us/step - loss: 0.3954 - accuracy: 0.8707 - val_loss: 0.1959 - val_accuracy: 0.9474\n",
      "Epoch 5/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 0.2152 - accuracy: 0.8958 - 0s 445us/step - loss: 1.7727 - accuracy: 0.8865 - val_loss: 1.9034 - val_accuracy: 0.8789\n",
      "Epoch 8/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.6571 - accuracy: 0.83 - 0s 202us/step - loss: 0.1988 - accuracy: 0.9340 - val_loss: 0.1111 - val_accuracy: 0.9474\n",
      "Epoch 6/10000192/379 [==============>...............] - ETA: 0s - loss: 2.2419 - accuracy: 0.8594\n",
      " - 0s 451us/step - loss: 2.3565 - accuracy: 0.8522 - val_loss: 2.0986 - val_accuracy: 0.8684 - loss: 2.4683 - accuracy: 0.84 - ETA: 0s - loss: 0.2106 - accuracy: 0.91\n",
      "379/379 [==============================] - 0s 278us/step - loss: 0.1895 - accuracy: 0.9261 - val_loss: 0.0853 - val_accuracy: 0.9684\n",
      "Epoch 9/10000\n",
      "Epoch 7/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.8958 - ETA: 0s - loss: 3.9856 - accuracy: 0. - ETA: 0s - loss: 3.1562 - accuracy: 0.8021 - 0s 178us/step - loss: 0.2034 - accuracy: 0.9103 - val_loss: 0.0659 - val_accuracy: 0.9842\n",
      "Epoch 8/10000\n",
      " - ETA: 0s - loss: 0.2812 - accuracy: 0.8958336/379 [=========================>....] - ETA: 0s - loss: 2.9897 - accuracy: 0.8288/379 [=====================>........]379/379 [==============================] - 0s 455us/step - loss: 2.9029 - accuracy: 0.8179 - val_loss: 2.2664 - val_accuracy: 0.8579\n",
      "Epoch 10/10000\n",
      "379/379 [==============================] - 0s 233us/step - loss: 0.2673 - accuracy: 0.9024 - val_loss: 0.0972 - val_accuracy: 0.9526\n",
      " 48/379 [==>...........................]\n",
      "379/379 [==============================]8125 - ETA: 0s - loss: 0.2852 - accuracy: 0.89192/379 [==============>...............]336/379 [=========================>....] - ETA: 0s - loss: 2.8240 - accuracy: 0.8229 - ETA: 0s - loss: 0.1802 - accuracy: 0.94 - 0s 275us/step - loss: 0.1860 - accuracy: 0.9393 - val_loss: 0.0692 - val_accuracy: 0.9789\n",
      "Epoch 10/100\n",
      "379/379 [==============================] - 0s 410us/step - loss: 2.5678 - accuracy: 0.8391 - val_loss: 2.0986 - val_accuracy: 0.8684\n",
      "Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9375 - ETA: 0s - loss: 1.3285 - accuracy: 0.91 - 0s 152us/step - loss: 0.1941 - accuracy: 0.9156 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3304 - accuracy: 0.9167 - ETA: 0s - loss: 0.1482 - accuracy: 0.8336/379 [=========================>....] - ETA: 0s - loss: 1.9959 - accuracy: 0.8750 - 0s 161us/step - loss: 0.1759 - accuracy: 0.9288 - val_loss: 0.0775 - val_accuracy: 0.9737\n",
      "Epoch 12/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.89 - 0s 430us/step - loss: 2.0223 - accuracy: 0.8734 - val_loss: 1.8469 - val_accuracy: 0.8842\n",
      "379/379 [==============================] - 0s 171us/step - loss: 0.1784 - accuracy: 0.9235 - val_loss: 0.0741 - val_accuracy: 0.9737\n",
      "Epoch 13/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.93 - 0s 103us/step - loss: 0.1996 - accuracy: 0.9446 - val_loss: 0.0774 - val_accuracy: 0.9632\n",
      "Epoch 14/10000\n",
      "model type is NNClassifier.............] - ETA: 0s - loss: 0.2161 - accuracy: 0.93379/379 [==============================]\n",
      "None - 0s 110us/step - loss: 0.1368 - accuracy: 0.9551 - val_loss: 0.0813 - val_accuracy: 0.9632\n",
      "\n",
      "Epoch 15/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.97 - 0s 107us/step - loss: 0.2270 - accuracy: 0.9340 - val_loss: 0.0852 - val_accuracy: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.95 - 0s 96us/step - loss: 0.1475 - accuracy: 0.9446 - val_loss: 0.0877 - val_accuracy: 0.9526\n",
      "Epoch 17/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.93 - 0s 99us/step - loss: 0.1794 - accuracy: 0.9208 - val_loss: 0.0788 - val_accuracy: 0.9684\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 380 samples, validate on 189 samples\n",
      "Epoch 1/10000\n",
      "Train on 380 samples, validate on 189 samples\n",
      "Epoch 1/10000..........................] - ETA: 2s - loss: 0.8423 - accuracy: 0.58288/380 [=====================>........]\n",
      "380/380 [==============================]69 - 1s 2ms/step - loss: 2.9047 - accuracy: 0.7342 - val_loss: 1.0175 - val_accuracy: 0.9312\n",
      "Epoch 2/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.3323 - accuracy: 0.85 - ETA: 0s - loss: 1.8304 - accuracy: 0.88 - 0s 309us/step - loss: 1.8916 - accuracy: 0.8816 - val_loss: 0.9540 - val_accuracy: 0.9365\n",
      "Epoch 3/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3325 - accuracy: 0.91 - ETA: 0s - loss: 2.0513 - accuracy: 0.87 - 0s 307us/step - loss: 2.0581 - accuracy: 0.8711 - val_loss: 0.9107 - val_accuracy: 0.9365\n",
      "Epoch 4/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.6644 - accuracy: 0.83 - ETA: 0s - loss: 2.7919 - accuracy: 0.82 - 0s 318us/step - loss: 2.5189 - accuracy: 0.8421 - val_loss: 1.0150 - val_accuracy: 0.9365\n",
      "Epoch 5/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.3286 - accuracy: 0.85 - ETA: 0s - loss: 2.1300 - accuracy: 0.86 - 0s 312us/step - loss: 1.9755 - accuracy: 0.8763 - val_loss: 1.0150 - val_accuracy: 0.9365\n",
      "Epoch 6/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.6686 - accuracy: 0.89 - ETA: 0s - loss: 2.0329 - accuracy: 0.87 - 0s 334us/step - loss: 2.2092 - accuracy: 0.8605 - val_loss: 1.1474 - val_accuracy: 0.9259\n",
      "Epoch 7/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.9865 - accuracy: 0.93 - ETA: 0s - loss: 1.7332 - accuracy: 0.8917 - ETA: 6s - loss: 0.6956 - accuracy: 0.66 - 0s 333us/step - loss: 1.7075 - accuracy: 0.8921 - val_loss: 1.1040 - val_accuracy: 0.9312\n",
      "Epoch 8/10000\n",
      "380/380 [==============================]9167336/380 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.87 - ETA: 0s - loss: 1.1680 - accuracy: 0.92 - 0s 356us/step - loss: 1.4524 - accuracy: 0.9079 - val_loss: 1.1040 - val_accuracy: 0.9312\n",
      "Epoch 9/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.0038 - accuracy: 0.87 - ETA: 0s - loss: 2.0709 - accuracy: 0.87 - 0s 337us/step - loss: 1.9829 - accuracy: 0.8763 - val_loss: 1.1031 - val_accuracy: 0.9312\n",
      "Epoch 10/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.95 - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8789 - val_loss: 0.1529 - val_accuracy: 0.9577\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.91 - 0s 349us/step - loss: 1.5163 - accuracy: 0.9053 - val_loss: 1.1031 - val_accuracy: 0.9312\n",
      "Epoch 11/10000\n",
      " 48/380 [==>...........................] - ETA: 0s - loss: 1.6643 - accuracy: 0.8958Epoch 2/10000\n",
      " - 0s 400us/step - loss: 1.5960 - accuracy: 0.9000 - val_loss: 1.1031 - val_accuracy: 0.9312 - loss: 1.5269 - accuracy: 0.90 - ETA: 0s - loss: 0.2673 - accuracy: 0.9380/380 [==============================]\n",
      "380/380 [==============================] - 0s 263us/step - loss: 0.3067 - accuracy: 0.9184 - val_loss: 0.1311 - val_accuracy: 0.9577\n",
      "Epoch 12/10000\n",
      "Epoch 3/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.9167 - ETA: 0s - loss: 0.2689 - accuracy: 0.91 - ETA: 0s - loss: 1.9180 - accuracy: 0.88 - ETA: 0s - loss: 0.3191 - accuracy: 0. - 0s 270us/step - loss: 0.3183 - accuracy: 0.9079 - val_loss: 0.0967 - val_accuracy: 0.9577\n",
      "336/380 [=========================>....] - ETA: 0s - loss: 1.8614 - accuracy: 0.8839Epoch 4/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.81 - 0s 449us/step - loss: 1.9045 - accuracy: 0.8789 - val_loss: 1.1031 - val_accuracy: 0.9312\n",
      "Epoch 13/10000\n",
      "336/380 [=========================>....] - ETA: 0s - loss: 2.3359 - accuracy: 0.85 - ETA: 0s - loss: 0.1759 - accuracy: 0.92240/380 [=================>............]380/380 [==============================] - ETA: 0s - loss: 1.7381 - accuracy: 0.8917 - 0s 329us/step - loss: 0.1748 - accuracy: 0.9289 - val_loss: 0.1017 - val_accuracy: 0.9683\n",
      "Epoch 5/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.89 - 0s 378us/step - loss: 1.7704 - accuracy: 0.8895 - val_loss: 1.1874 - val_accuracy: 0.9259\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.94 - 0s 238us/step - loss: 0.1374 - accuracy: 0.9447 - val_loss: 0.0894 - val_accuracy: 0.9630\n",
      "Epoch 6/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.89 - 0s 84us/step - loss: 0.1468 - accuracy: 0.9526 - val_loss: 0.0769 - val_accuracy: 0.9788\n",
      "Epoch 7/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.91 - 0s 102us/step - loss: 0.1960 - accuracy: 0.9342 - val_loss: 0.0735 - val_accuracy: 0.9735\n",
      "Epoch 8/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.93 - 0s 98us/step - loss: 0.1951 - accuracy: 0.9211 - val_loss: 0.0828 - val_accuracy: 0.9630\n",
      "Epoch 9/10000\n",
      " 48/380 [==>...........................]\n",
      "None - ETA: 0s - loss: 0.1798 - accuracy: 0.8958\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1796 - accuracy: 0.9263 - val_loss: 0.0823 - val_accuracy: 0.9630\n",
      "Epoch 10/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.93 - 0s 104us/step - loss: 0.1277 - accuracy: 0.9632 - val_loss: 0.0771 - val_accuracy: 0.9683\n",
      "Epoch 11/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.91 - 0s 101us/step - loss: 0.2122 - accuracy: 0.9105 - val_loss: 0.0868 - val_accuracy: 0.9735\n",
      "Epoch 12/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 1.00 - 0s 111us/step - loss: 0.1840 - accuracy: 0.9211 - val_loss: 0.0841 - val_accuracy: 0.9683\n",
      "Epoch 13/10000\n",
      "144/380 [==========>...................] - ETA: 0s - loss: 0.1392 - accuracy: 0.91 - ETA: 0s - loss: 0.1014 - accuracy: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-30 16:04:46,752] Finished trial#0 with value: 0.8047021689104478 with parameters: {'input_dropout': 0.5488135039273248, 'hidden_layers': 2, 'hidden_units': 896.0, 'hidden_dropout': 0.8579456176227568, 'batch_norm': 'non', 'batch_size': 48.0}. Best is trial#0 with value: 0.8047021689104478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 400us/step - loss: 0.1599 - accuracy: 0.9474 - val_loss: 0.0844 - val_accuracy: 0.9630\n",
      "Epoch 14/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.91 - 0s 66us/step - loss: 0.1946 - accuracy: 0.9237 - val_loss: 0.0781 - val_accuracy: 0.9683\n",
      "Epoch 15/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.89 - 0s 89us/step - loss: 0.1685 - accuracy: 0.9263 - val_loss: 0.0841 - val_accuracy: 0.9630\n",
      "Epoch 16/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.91 - 0s 98us/step - loss: 0.1839 - accuracy: 0.9237 - val_loss: 0.0849 - val_accuracy: 0.9735\n",
      "Epoch 17/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.97 - 0s 90us/step - loss: 0.1828 - accuracy: 0.9289 - val_loss: 0.0878 - val_accuracy: 0.9683\n",
      "model type is NNClassifier\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-30 16:04:47,267] Finished trial#1 with value: 0.08951741930276812 with parameters: {'input_dropout': 0.6458941130666561, 'hidden_layers': 1, 'hidden_units': 320.0, 'hidden_dropout': 0.05671297731744318, 'batch_norm': 'before_act', 'batch_size': 48.0}. Best is trial#1 with value: 0.08951741930276812.\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from utils import Paramset\n",
    "from neuralnetwork import NNClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "brest_c = load_breast_cancer()\n",
    "x = brest_c['data']\n",
    "y = brest_c['target']\n",
    "\n",
    "\n",
    "n_trials = 2\n",
    "n_jobs=-1\n",
    "random_state=0\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=random_state))\n",
    "study.optimize(obj, n_trials=n_trials, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
