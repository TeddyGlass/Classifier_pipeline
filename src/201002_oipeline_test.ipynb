{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "Using TensorFlow backend.\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "This dataset is inbalanced data. Run under sampling....\n",
      "n_datasets = 2\n",
      "positive samples = 168\n",
      "Total 2 datasets were generated.\n",
      "Run Optimizer. Just a moment.......\n",
      " Data type of X is list type.\n",
      " Running optimization for all data sets. Just a moment....\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Train on 208 samples, validate on 104 samplesEpoch 1/10000\n",
      "\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "208/208 [==============================] - ETA: 5s - loss: 1.5907 - accuracy: 0.3750 - ETA: 4s - loss: 1.8678 - accuracy: 0.4375 - ETA: 5s - loss: 1.6213 - accuracy: 0.50 - 1s 3ms/step - loss: 1.5264 - accuracy: 0.5913 - val_loss: 0.4939 - val_accuracy: 0.7692\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 1.6687 - accuracy: 0.5048 - val_loss: 0.5212 - val_accuracy: 0.7596\n",
      "Epoch 2/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.5313 - accuracy: 0.6875Epoch 2/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4969 - accuracy: 0.68 - 0s 214us/step - loss: 1.0917 - accuracy: 0.5625 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 3/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 1.5802 - accuracy: 0.6208/208 [==============================] - 0s 276us/step - loss: 0.9639 - accuracy: 0.5865 - val_loss: 0.6417 - val_accuracy: 0.5962\n",
      "208/208 [==============================]Epoch 3/10000 - 1s 3ms/step - loss: 1.1551 - accuracy: 0.5144 - val_loss: 0.5495 - val_accuracy: 0.7788\n",
      "\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.43 - 0s 250us/step - loss: 0.9308 - accuracy: 0.5625 - val_loss: 0.6458 - val_accuracy: 0.6923\n",
      "Epoch 2/10000Epoch 4/10000\n",
      "\n",
      "208/208 [==============================]5625 16/208 [=>............................] - ETA: 0s - loss: 0.7335 - accuracy: 0.50 - 0s 305us/step - loss: 0.9061 - accuracy: 0.5192 - val_loss: 0.6336 - val_accuracy: 0.6635\n",
      "Epoch 4/10000\n",
      "208/208 [==============================] - 0s 298us/step - loss: 1.0658 - accuracy: 0.5529 - val_loss: 0.6442 - val_accuracy: 0.6346\n",
      " - 0s 288us/step - loss: 0.7420 - accuracy: 0.5817 - val_loss: 0.5890 - val_accuracy: 0.7404\n",
      "Epoch 3/10000Epoch 5/10000\n",
      "\n",
      "208/208 [==============================]6250 16/208 [=>............................] - ETA: 0s - loss: 0.6127 - accuracy: 0.56 - 0s 278us/step - loss: 0.7001 - accuracy: 0.5337 - val_loss: 0.6228 - val_accuracy: 0.7019\n",
      "Epoch 5/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7353 - accuracy: 0. - 0s 323us/step - loss: 1.2107 - accuracy: 0.5385 - val_loss: 0.5924 - val_accuracy: 0.7500\n",
      "208/208 [==============================] - 0s 330us/step - loss: 0.8158 - accuracy: 0.6106 - val_loss: 0.6455 - val_accuracy: 0.6250\n",
      "Epoch 4/10000\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7406 - accuracy: 0.5000 16/208 [=>............................] - ETA: 0s - loss: 0.8685 - accuracy: 0.56 - 0s 294us/step - loss: 0.7985 - accuracy: 0.5577 - val_loss: 0.6858 - val_accuracy: 0.5481\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] ETA: 0s - loss: 0.6916 - accuracy: 0.6250 - 0s 267us/step - loss: 0.8025 - accuracy: 0.5529 - val_loss: 0.6084 - val_accuracy: 0.7404\n",
      "Epoch 7/10000208/208 [==============================]\n",
      " - 0s 336us/step - loss: 0.7438 - accuracy: 0.5817 - val_loss: 0.5798 - val_accuracy: 0.7692\n",
      "Epoch 5/10000\n",
      "208/208 [==============================]6250 16/208 [=>............................] - ETA: 0s - loss: 0.6846 - accuracy: 0.62 - 0s 321us/step - loss: 0.7065 - accuracy: 0.5433 - val_loss: 0.5773 - val_accuracy: 0.7212\n",
      "Epoch 7/10000\n",
      " - 0s 344us/step - loss: 0.8761 - accuracy: 0.6250 - val_loss: 0.5567 - val_accuracy: 0.7500 loss: 0.7080 - accuracy: 0.6198 - ETA: 0s - loss: 0.5626 - accuracy: 0.75\n",
      "208/208 [==============================] - 0s 413us/step - loss: 0.7103 - accuracy: 0.6106 - val_loss: 0.5932 - val_accuracy: 0.7308\n",
      "Epoch 6/10000\n",
      "Epoch 8/10000 16/208 [=>............................]\n",
      "208/208 [==============================]68 - ETA: 0s - loss: 0.5713 - accuracy: 0.6875 - 0s 289us/step - loss: 0.7337 - accuracy: 0.6154 - val_loss: 0.6547 - val_accuracy: 0.6250\n",
      "Epoch 8/10000\n",
      " - 0s 355us/step - loss: 0.7306 - accuracy: 0.5769 - val_loss: 0.5106 - val_accuracy: 0.7596\n",
      "208/208 [==============================] - 0s 339us/step - loss: 0.7995 - accuracy: 0.5577 - val_loss: 0.5975 - val_accuracy: 0.7308\n",
      "Epoch 7/10000\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0542 - accuracy: 0.562 16/208 [=>............................] - ETA: 0s - loss: 0.6253 - accuracy: 0.8125 - 0s 298us/step - loss: 0.6853 - accuracy: 0.5817 - val_loss: 0.6472 - val_accuracy: 0.6731\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.81 - 0s 291us/step - loss: 0.7591 - accuracy: 0.6250 - val_loss: 0.5246 - val_accuracy: 0.7596\n",
      "Epoch 8/10000208/208 [==============================]\n",
      " - 0s 300us/step - loss: 0.6475 - accuracy: 0.6202 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      " 16/208 [=>............................]Epoch 10/100\n",
      "208/208 [==============================]5625 - 0s 284us/step - loss: 0.6954 - accuracy: 0.5817 - val_loss: 0.6039 - val_accuracy: 0.7212\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.5213 - accuracy: 0.6250Epoch 10/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7981 - accuracy: 0.37 - 0s 242us/step - loss: 0.6529 - accuracy: 0.6635 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - 0s 264us/step - loss: 0.7935 - accuracy: 0.6058 - val_loss: 0.6134 - val_accuracy: 0.7212\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7888 - accuracy: 0.3750Epoch 11/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6323 - accuracy: 0.6875208/208 [==============================] - 0s 308us/step - loss: 0.7037 - accuracy: 0.5673 - val_loss: 0.7742 - val_accuracy: 0.5385\n",
      "Epoch 11/10000\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 242us/step - loss: 0.7063 - accuracy: 0.6298 - val_loss: 0.5610 - val_accuracy: 0.7500\n",
      " - ETA: 0s - loss: 0.9245 - accuracy: 0.8125Epoch 10/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.8125 - 0s 273us/step - loss: 0.6616 - accuracy: 0.6106 - val_loss: 0.6207 - val_accuracy: 0.7308\n",
      "Epoch 12/10000\n",
      "208/208 [==============================] ETA: 0s - loss: 0.6692 - accuracy: 0.5000 - 0s 271us/step - loss: 0.6532 - accuracy: 0.6346 - val_loss: 0.5759 - val_accuracy: 0.7404\n",
      "Epoch 12/10000\n",
      " - 0s 244us/step - loss: 0.7001 - accuracy: 0.6250 - val_loss: 0.5233 - val_accuracy: 0.7404\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.4795 - accuracy: 0.8750Epoch 11/10000\n",
      "208/208 [==============================] ETA: 0s - loss: 0.5795 - accuracy: 0.6875 - 0s 281us/step - loss: 0.6730 - accuracy: 0.6442 - val_loss: 0.5660 - val_accuracy: 0.7404\n",
      "Epoch 13/100\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.8000 - accuracy: 0.5625 - ETA: 0s - loss: 0.6065 - accuracy: 0.68208/208 [==============================]208/208 [==============================] - 0s 324us/step - loss: 0.7014 - accuracy: 0.6635 - val_loss: 0.6337 - val_accuracy: 0.6250\n",
      " - 0s 424us/step - loss: 0.7971 - accuracy: 0.5529 - val_loss: 0.6486 - val_accuracy: 0.6442\n",
      "Epoch 12/10000Epoch 13/10000\n",
      "\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7299 - accuracy: 0.5000 - ETA: 0s - loss: 0.5958 - accuracy: 0.75 - 0s 320us/step - loss: 0.6684 - accuracy: 0.6250 - val_loss: 0.6810 - val_accuracy: 0.5481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0. - 0s 297us/step - loss: 0.6831 - accuracy: 0.6346 - val_loss: 0.5348 - val_accuracy: 0.7019\n",
      "208/208 [==============================]Epoch 13/10000\n",
      " - 0s 301us/step - loss: 0.7587 - accuracy: 0.6010 - val_loss: 0.6194 - val_accuracy: 0.6827\n",
      " 16/208 [=>............................]Epoch 14/10000 - ETA: 0s - loss: 0.6675 - accuracy: 0.7500\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.68 - 0s 351us/step - loss: 0.8344 - accuracy: 0.5769 - val_loss: 0.5750 - val_accuracy: 0.7115\n",
      "Epoch 15/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - 0s 305us/step - loss: 0.6994 - accuracy: 0.6298 - val_loss: 0.5179 - val_accuracy: 0.7404\n",
      "208/208 [==============================]Epoch 14/10000 - 0s 310us/step - loss: 0.6798 - accuracy: 0.5625 - val_loss: 0.6144 - val_accuracy: 0.6827\n",
      "\n",
      "Epoch 15/10000 16/208 [=>............................]\n",
      "208/208 [==============================]6250 - ETA: 0s - loss: 0.6750 - accuracy: 0.50 - 0s 317us/step - loss: 0.7229 - accuracy: 0.5817 - val_loss: 0.5986 - val_accuracy: 0.7019\n",
      "Epoch 16/10000\n",
      " 16/208 [=>............................] - 0s 297us/step - loss: 0.8730 - accuracy: 0.6010 - val_loss: 0.5381 - val_accuracy: 0.7308\n",
      "Epoch 15/10000oss: 0.6359 - accuracy: 0.56\n",
      "208/208 [==============================] - 0s 311us/step - loss: 0.6989 - accuracy: 0.6058 - val_loss: 0.6678 - val_accuracy: 0.5769\n",
      " 16/208 [=>............................]Epoch 16/10000 - ETA: 0s - loss: 0.4410 - accuracy: 0.7500\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0. - 0s 302us/step - loss: 0.7466 - accuracy: 0.5865 - val_loss: 0.5844 - val_accuracy: 0.7115\n",
      "208/208 [==============================]Epoch 17/10000 - 0s 279us/step - loss: 0.9025 - accuracy: 0.6442 - val_loss: 0.5364 - val_accuracy: 0.7308\n",
      "\n",
      " 16/208 [=>............................]208/208 [==============================]Epoch 16/10000 - ETA: 0s - loss: 0.6172 - accuracy: 0.5000\n",
      " - 0s 294us/step - loss: 0.7086 - accuracy: 0.5865 - val_loss: 0.5569 - val_accuracy: 0.7404\n",
      "Epoch 17/10000\n",
      "208/208 [==============================]4375 16/208 [=>............................] - ETA: 0s - loss: 0.6321 - accuracy: 0.62 - 0s 243us/step - loss: 0.7027 - accuracy: 0.5769 - val_loss: 0.6443 - val_accuracy: 0.6731\n",
      "208/208 [==============================] - 0s 271us/step - loss: 0.7301 - accuracy: 0.6058 - val_loss: 0.6151 - val_accuracy: 0.6731\n",
      "\n",
      "208/208 [==============================]\n",
      " 16/208 [=>............................] - 0s 284us/step - loss: 0.6390 - accuracy: 0.6250 - val_loss: 0.5245 - val_accuracy: 0.7404\n",
      " 16/208 [=>............................]5000Epoch 18/10000\n",
      " 16/208 [=>............................]5000 - ETA: 0s - loss: 0.6232 - accuracy: 0.6208/208 [==============================] - 0s 266us/step - loss: 0.7378 - accuracy: 0.5529 - val_loss: 0.6492 - val_accuracy: 0.6827\n",
      "208/208 [============================= - 0s 271us/step - loss: 0.7271 - accuracy: 0.6106 - val_loss: 0.6057 - val_accuracy: 0.7212\n",
      "208/208 [==============================]\n",
      "Epoch 18/10000 - 0s 277us/step - loss: 0.8078 - accuracy: 0.5913 - val_loss: 0.5611 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 19/10000.........................] - ETA: 0s - loss: 0.6115 - accuracy: 0.7500\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7025 - accuracy: 0.5625 - ETA: 0s - loss: 0.5701 - accuracy: 0.6208/208 [==============================] - 0s 283us/step - loss: 0.6891 - accuracy: 0.6058 - val_loss: 0.5976 - val_accuracy: 0.7308\n",
      "208/208 [==============================] - 0s 294us/step - loss: 0.6321 - accuracy: 0.6346 - val_loss: 0.6184 - val_accuracy: 0.6635\n",
      "Epoch 20/10000\n",
      "208/208 [==============================]Epoch 19/10000\n",
      " - 0s 305us/step - loss: 0.6941 - accuracy: 0.6202 - val_loss: 0.5664 - val_accuracy: 0.7115\n",
      "Epoch 20/10000.........................] - ETA: 0s - loss: 0.7077 - accuracy: 0.5625 16/208 [=>............................] - ETA: 0s - loss: 0.8480 - accuracy: 0.6250\n",
      "144/208 [===================>..........] - ETA: 0s - loss: 0.5984 - accuracy: 0. - ETA: 0s - loss: 0.7769 - accuracy: 0.5694208/208 [==============================]208/208 [==============================] - 0s 311us/step - loss: 0.6447 - accuracy: 0.6394 - val_loss: 0.5311 - val_accuracy: 0.7308\n",
      " - 0s 328us/step - loss: 0.7060 - accuracy: 0.6106 - val_loss: 0.5571 - val_accuracy: 0.7404\n",
      "Epoch 21/10000Epoch 20/10000\n",
      "\n",
      "208/208 [==============================]5625 16/208 [=>........................... - ETA: 0s - loss: 0.5288 - accuracy: 0.6875 - 0s 395us/step - loss: 0.7712 - accuracy: 0.5625 - val_loss: 0.6968 - val_accuracy: 0.5385\n",
      "Epoch 21/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.5858 - accuracy: 0.75208/208 [==============================]208/208 [==============================] - 0s 346us/step - loss: 0.6860 - accuracy: 0.6394 - val_loss: 0.6417 - val_accuracy: 0.6442\n",
      " - 0s 357us/step - loss: 0.7292 - accuracy: 0.6442 - val_loss: 0.5505 - val_accuracy: 0.7308\n",
      "Epoch 21/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.81 - 0s 307us/step - loss: 0.7462 - accuracy: 0.5625 - val_loss: 0.6865 - val_accuracy: 0.5577\n",
      "208/208 [==============================] - 0s 316us/step - loss: 0.6524 - accuracy: 0.6058 - val_loss: 0.6371 - val_accuracy: 0.6538\n",
      "Epoch 22/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8079 - accuracy: 0.62 - 0s 193us/step - loss: 0.6647 - accuracy: 0.6490 - val_loss: 0.7170 - val_accuracy: 0.5385\n",
      "Epoch 23/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.3560 - accuracy: 0.50 - ETA: 0s - loss: 0.7196 - accuracy: 0.58 - 0s 417us/step - loss: 0.7073 - accuracy: 0.6058 - val_loss: 0.6253 - val_accuracy: 0.6635\n",
      "Epoch 24/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.75 - 0s 169us/step - loss: 0.6339 - accuracy: 0.6058 - val_loss: 0.6474 - val_accuracy: 0.6154\n",
      "Epoch 25/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.68 - 0s 252us/step - loss: 0.6555 - accuracy: 0.5962 - val_loss: 0.6530 - val_accuracy: 0.6154\n",
      "Epoch 26/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.56 - 0s 268us/step - loss: 0.7542 - accuracy: 0.5673 - val_loss: 0.6889 - val_accuracy: 0.5577\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Train on 208 samples, validate on 104 samplesEpoch 1/10000\n",
      "\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "208/208 [==============================] - ETA: 4s - loss: 2.3520 - accuracy: 0.4375 - ETA: 4s - loss: 1.5896 - accuracy: 0.5000 - ETA: 5s - loss: 1.6855 - accuracy: 0.56 - 1s 3ms/step - loss: 1.4096 - accuracy: 0.5096 - val_loss: 0.5797 - val_accuracy: 0.5577\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 1.3499 - accuracy: 0.5481 - val_loss: 0.7045 - val_accuracy: 0.6346\n",
      "Epoch 2/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 2.0036 - accuracy: 0.6250Epoch 2/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 1.1511 - accuracy: 0.208/208 [==============================]208/208 [==============================] - 0s 267us/step - loss: 0.9517 - accuracy: 0.5721 - val_loss: 0.6225 - val_accuracy: 0.7115\n",
      " - 1s 3ms/step - loss: 1.3629 - accuracy: 0.5913 - val_loss: 0.6768 - val_accuracy: 0.7115\n",
      "Epoch 3/10000\n",
      "208/208 [==============================]] - ETA: 0s - loss: 0.7742 - accuracy: 0.2500 - 0s 291us/step - loss: 1.0047 - accuracy: 0.5817 - val_loss: 0.5637 - val_accuracy: 0.7596\n",
      "Epoch 3/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.8583 - accuracy: 0.3750Epoch 2/10000\n",
      "208/208 [==============================] - 0s 243us/step - loss: 0.7563 - accuracy: 0.5625 - val_loss: 0.5977 - val_accuracy: 0.7115\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.5920 - accuracy: 0.6875Epoch 4/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.56 - 0s 283us/step - loss: 0.7938 - accuracy: 0.5913 - val_loss: 0.5573 - val_accuracy: 0.7115\n",
      "Epoch 4/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7034 - accuracy: 0.43192/208 [==========================>...]208/208 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.6510 - 0s 335us/step - loss: 0.8724 - accuracy: 0.5817 - val_loss: 0.5502 - val_accuracy: 0.7308\n",
      "Epoch 3/10000\n",
      " - ETA: 0s - loss: 0.9283 - accuracy: 0.6250208/208 [==============================] - 0s 429us/step - loss: 0.6097 - accuracy: 0.6683 - val_loss: 0.6978 - val_accuracy: 0.7308\n",
      "Epoch 5/10000\n",
      "208/208 [==============================] - 0s 316us/step - loss: 0.7712 - accuracy: 0.5913 - val_loss: 0.6243 - val_accuracy: 0.6827\n",
      " 16/208 [=>............................]Epoch 5/10000 - ETA: 0s - loss: 0.4938 - accuracy: 0.7500\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.68 - 0s 331us/step - loss: 0.9504 - accuracy: 0.6442 - val_loss: 0.6126 - val_accuracy: 0.6923\n",
      "Epoch 4/100\n",
      " - ETA: 0s - loss: 0.6762 - accuracy: 0.5990208 [==============================] 16/208 [=>............................] - 0s 336us/step - loss: 0.7844 - accuracy: 0.6346 - val_loss: 0.6071 - val_accuracy: 0.7115\n",
      " - ETA: 0s - loss: 0.3916 - accuracy: 0.8125Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.6181 - accuracy: 0.5625 - 0s 396us/step - loss: 0.6752 - accuracy: 0.5913 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.50 - 0s 278us/step - loss: 0.9001 - accuracy: 0.6538 - val_loss: 0.5481 - val_accuracy: 0.7596\n",
      "Epoch 5/10000\n",
      "208/208 [==============================] - 0s 289us/step - loss: 1.0323 - accuracy: 0.5577 - val_loss: 0.7640 - val_accuracy: 0.6154\n",
      "Epoch 7/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.3701 - accuracy: 0.5000 - ETA: 0s - loss: 0.9428 - accuracy: 0.56 - 0s 297us/step - loss: 0.6917 - accuracy: 0.6346 - val_loss: 0.5470 - val_accuracy: 0.7308\n",
      "Epoch 7/10000\n",
      " - 0s 339us/step - loss: 0.7163 - accuracy: 0.5913 - val_loss: 0.5742 - val_accuracy: 0.7308\n",
      "208/208 [==============================] - 0s 295us/step - loss: 0.7310 - accuracy: 0.6346 - val_loss: 0.6261 - val_accuracy: 0.6827\n",
      "Epoch 6/10000\n",
      "Epoch 8/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8376 - accuracy: 0.750 16/208 [=>............................] - ETA: 0s - loss: 0.3966 - accuracy: 0.9375 - 0s 264us/step - loss: 0.5980 - accuracy: 0.7019 - val_loss: 0.5712 - val_accuracy: 0.7019\n",
      "Epoch 8/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.75 - 0s 287us/step - loss: 0.8698 - accuracy: 0.5817 - val_loss: 0.5464 - val_accuracy: 0.7404\n",
      "Epoch 7/10000\n",
      " 16/208 [=>............................]208/208 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.6250 - 0s 357us/step - loss: 0.7497 - accuracy: 0.7163 - val_loss: 0.5714 - val_accuracy: 0.7308\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - 0s 326us/step - loss: 0.8789 - accuracy: 0.6635 - val_loss: 0.9516 - val_accuracy: 0.7115\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6418 - accuracy: 0.5000Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4910 - accuracy: 0.68 - 0s 357us/step - loss: 0.7500 - accuracy: 0.6490 - val_loss: 0.5420 - val_accuracy: 0.7308\n",
      "192/208 [==========================>...]208/208 [==============================]Epoch 8/10000 - ETA: 0s - loss: 0.9565 - accuracy: 0.6354 - 0s 329us/step - loss: 0.7541 - accuracy: 0.6442 - val_loss: 0.5433 - val_accuracy: 0.7404\n",
      "\n",
      " 16/208 [=>............................]Epoch 10/10000 - ETA: 0s - loss: 1.1240 - accuracy: 0.6250\n",
      "208/208 [==============================] ETA: 0s - loss: 0.7091 - accuracy: 0.5000 - 0s 395us/step - loss: 0.9810 - accuracy: 0.6442 - val_loss: 1.0444 - val_accuracy: 0.7404\n",
      "Epoch 10/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7516 - accuracy: 0. - 0s 362us/step - loss: 0.7606 - accuracy: 0.6394 - val_loss: 0.5947 - val_accuracy: 0.7212\n",
      "208/208 [==============================]Epoch 9/10000 - 0s 346us/step - loss: 0.6938 - accuracy: 0.6923 - val_loss: 0.5616 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 11/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.93 16/208 [=>............................]192/208 [==========================>...] - ETA: 0s - loss: 0.4929 - accuracy: 0.7500 - ETA: 0s - loss: 1.0599 - accuracy: 0. - 0s 495us/step - loss: 1.0730 - accuracy: 0.5577 - val_loss: 0.5890 - val_accuracy: 0.7212\n",
      "208/208 [==============================]Epoch 11/10000 - 0s 321us/step - loss: 0.6670 - accuracy: 0.6346 - val_loss: 0.5545 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 10/10000208/208 [==============================]\n",
      " - 0s 321us/step - loss: 0.6406 - accuracy: 0.6635 - val_loss: 0.5844 - val_accuracy: 0.7308\n",
      "Epoch 12/10000.........................] - ETA: 0s - loss: 0.8298 - accuracy: 0.5000 16/208 [=>............................]\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.63548192/208 [==========================>.. - 0s 315us/step - loss: 0.7380 - accuracy: 0.6202 - val_loss: 0.5682 - val_accuracy: 0.7212\n",
      "208/208 [==============================] - 0s 323us/step - loss: 0.7473 - accuracy: 0.6010 - val_loss: 0.5630 - val_accuracy: 0.7308\n",
      "Epoch 12/10000\n",
      "Epoch 11/10000\n",
      " 16/208 [=>............................]5625208/208 [==============================] - 0s 385us/step - loss: 0.6555 - accuracy: 0.6490 - val_loss: 0.5581 - val_accuracy: 0.7212\n",
      " - ETA: 0s - loss: 0.6449 - accuracy: 0.7500Epoch 13/10000\n",
      " - 0s 361us/step - loss: 0.7094 - accuracy: 0.6250 - val_loss: 0.5571 - val_accuracy: 0.7212===========================]208/208 [==============================]\n",
      "192/208 [==========================>...] - 0s 331us/step - loss: 0.7283 - accuracy: 0.6442 - val_loss: 0.5468 - val_accuracy: 0.7308\n",
      " - ETA: 0s - loss: 0.6580 - accuracy: 0.6042Epoch 13/10000Epoch 12/10000\n",
      "\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.6250 - ETA: 0s - loss: 0.6965 - accuracy: 0.56 - 0s 367us/step - loss: 0.6562 - accuracy: 0.6058 - val_loss: 0.5829 - val_accuracy: 0.6923\n",
      "Epoch 14/10000\n",
      " - 0s 308us/step - loss: 0.7957 - accuracy: 0.6346 - val_loss: 0.5490 - val_accuracy: 0.7308============================]\n",
      "208/208 [==============================] - 0s 344us/step - loss: 0.7497 - accuracy: 0.6202 - val_loss: 0.6608 - val_accuracy: 0.6154\n",
      "Epoch 13/10000\n",
      "Epoch 14/10000\n",
      "208/208 [==============================]5000 16/208 [=>............................] - ETA: 0s - loss: 0.7647 - accuracy: 0.43 - 0s 320us/step - loss: 0.6854 - accuracy: 0.6154 - val_loss: 0.6973 - val_accuracy: 0.5385\n",
      "Epoch 15/10000\n",
      " - 0s 322us/step - loss: 0.7378 - accuracy: 0.6202 - val_loss: 0.5578 - val_accuracy: 0.7212\n",
      "208/208 [==============================] - 0s 307us/step - loss: 0.7417 - accuracy: 0.5817 - val_loss: 0.5483 - val_accuracy: 0.7404\n",
      "Epoch 14/10000\n",
      "Epoch 15/10000\n",
      "208/208 [==============================]4375 16/208 [=>............................] - ETA: 0s - loss: 0.7263 - accuracy: 0.50 - ETA: 0s - loss: 0.7671 - accuracy: 0.59 - 0s 425us/step - loss: 0.7516 - accuracy: 0.6058 - val_loss: 0.5685 - val_accuracy: 0.7308\n",
      "Epoch 16/10000\n",
      " - 0s 302us/step - loss: 0.7747 - accuracy: 0.6587 - val_loss: 0.5515 - val_accuracy: 0.7500\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 341us/step - loss: 0.7786 - accuracy: 0.5673 - val_loss: 0.5630 - val_accuracy: 0.7404\n",
      " - ETA: 0s - loss: 0.6884 - accuracy: 0.5000Epoch 16/10000\n",
      "Epoch 15/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.5666 - accuracy: 0.6250 - ETA: 0s - loss: 0.9837 - accuracy: 0.62208/208 [==============================]192/208 [==========================>...] - 0s 325us/step - loss: 0.6671 - accuracy: 0.6394 - val_loss: 0.5421 - val_accuracy: 0.7212\n",
      "208/208 [==============================]60 - 0s 321us/step - loss: 0.6907 - accuracy: 0.6346 - val_loss: 0.5403 - val_accuracy: 0.7308\n",
      "Epoch 17/10000\n",
      "Epoch 17/10000\n",
      "208/208 [==============================]6250 16/208 [=>............................] - 0s 384us/step - loss: 0.7508 - accuracy: 0.6010 - val_loss: 0.5784 - val_accuracy: 0.7019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s - loss: 1.4688 - accuracy: 0.8125Epoch 16/10000\n",
      " - 0s 335us/step - loss: 0.6806 - accuracy: 0.6346 - val_loss: 0.5517 - val_accuracy: 0.7308============================]\n",
      "Epoch 18/10000 - 0s 344us/step - loss: 0.8661 - accuracy: 0.6298 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "208/208 [==============================]\n",
      " - 0s 296us/step - loss: 0.7927 - accuracy: 0.5962 - val_loss: 0.7287 - val_accuracy: 0.5385\n",
      "Epoch 18/10000 16/208 [=>............................]\n",
      "Epoch 17/10000 - ETA: 0s - loss: 0.6313 - accuracy: 0.5000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.7500 - ETA: 0s - loss: 0.7918 - accuracy: 0 - 0s 330us/step - loss: 0.8164 - accuracy: 0.5962 - val_loss: 0.6932 - val_accuracy: 0.5385\n",
      " - 0s 304us/step - loss: 0.6741 - accuracy: 0.6298 - val_loss: 0.5389 - val_accuracy: 0.7404\n",
      "208/208 [==============================]Epoch 19/10000 - 0s 307us/step - loss: 0.7775 - accuracy: 0.5817 - val_loss: 0.5940 - val_accuracy: 0.6827\n",
      "\n",
      "Epoch 19/10000Epoch 18/10000\n",
      "\n",
      "208/208 [==============================] - 0s 342us/step - loss: 0.6916 - accuracy: 0.6010 - val_loss: 0.6675 - val_accuracy: 0.6250[=>............................] - ETA: 0s - loss: 0.6330 - accuracy: 0.68 - ETA: 0s - loss: 0.8552 - accuracy: 0.5208/208 [==============================]\n",
      " - 0s 350us/step - loss: 0.5998 - accuracy: 0.6683 - val_loss: 0.5359 - val_accuracy: 0.7308\n",
      "Epoch 20/10000\n",
      "\n",
      "208/208 [==============================] - 0s 385us/step - loss: 0.8424 - accuracy: 0.5865 - val_loss: 0.5894 - val_accuracy: 0.7019\n",
      " 16/208 [=>............................] 16/208 [=>............................] - ETA: 0s - loss: 0.6127 - accuracy: 0.5625Epoch 19/10000 - ETA: 0s - loss: 0.5080 - accuracy: 0.8125\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0981 - accuracy: 0 - ETA: 0s - loss: 0.8592 - accuracy: 0.5521208/208 [==============================] - 0s 314us/step - loss: 0.6991 - accuracy: 0.6154 - val_loss: 0.5905 - val_accuracy: 0.7212\n",
      " - 0s 312us/step - loss: 0.6368 - accuracy: 0.6731 - val_loss: 0.5431 - val_accuracy: 0.7308\n",
      "Epoch 21/10000\n",
      "Epoch 21/10000\n",
      "208/208 [==============================] 16/208 [=>........................... - ETA: 0s - loss: 0.6635 - accuracy: 0.5625 - ETA: 0s - loss: 0.5675 - accuracy: 0.6875 - 0s 380us/step - loss: 0.8493 - accuracy: 0.5529 - val_loss: 0.7158 - val_accuracy: 0.5673\n",
      "Epoch 20/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6557 - accuracy: 0.5208/208 [==============================] - 0s 305us/step - loss: 0.6592 - accuracy: 0.6010 - val_loss: 0.5453 - val_accuracy: 0.7404\n",
      "208/208 [==============================] - 0s 298us/step - loss: 0.5872 - accuracy: 0.6683 - val_loss: 0.5575 - val_accuracy: 0.7404\n",
      "Epoch 22/10000\n",
      "Epoch 22/10000\n",
      "208/208 [==============================]5625 16/208 [=>............................] - ETA: 0s - loss: 1.4488 - accuracy: 0.68 - 0s 331us/step - loss: 0.7135 - accuracy: 0.5865 - val_loss: 0.6468 - val_accuracy: 0.6827\n",
      "Epoch 21/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.56 - 0s 340us/step - loss: 0.7000 - accuracy: 0.6202 - val_loss: 0.5815 - val_accuracy: 0.7404\n",
      "Epoch 23/10000\n",
      " - 0s 371us/step - loss: 0.8610 - accuracy: 0.6010 - val_loss: 0.5507 - val_accuracy: 0.7308\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.4319 - accuracy: 0.8125Epoch 23/10000\n",
      " 16/208 [=>............................]208/208 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.6250 - 0s 309us/step - loss: 0.7436 - accuracy: 0.5817 - val_loss: 0.5801 - val_accuracy: 0.7019\n",
      "Epoch 22/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7806 - accuracy: 0.62 - 0s 302us/step - loss: 0.8185 - accuracy: 0.6442 - val_loss: 0.5556 - val_accuracy: 0.7212\n",
      "Epoch 24/10000\n",
      "208/208 [==============================] - 0s 302us/step - loss: 0.6311 - accuracy: 0.6298 - val_loss: 0.5482 - val_accuracy: 0.7308\n",
      " 16/208 [=>............................]Epoch 24/100 - ETA: 0s - loss: 0.5470 - accuracy: 0.6875\n",
      "208/208 [==============================]5885 16/208 [=>............................] - ETA: 0s - loss: 0.8482 - accuracy: 0.62 - 0s 423us/step - loss: 0.6752 - accuracy: 0.5913 - val_loss: 0.6165 - val_accuracy: 0.6635\n",
      "Epoch 23/100\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 297us/step - loss: 0.7521 - accuracy: 0.5577 - val_loss: 0.5733 - val_accuracy: 0.7115\n",
      " - ETA: 0s - loss: 0.8005 - accuracy: 0.62Epoch 25/10000\n",
      " - 0s 302us/step - loss: 0.7471 - accuracy: 0.6346 - val_loss: 0.5770 - val_accuracy: 0.7019\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.8264 - accuracy: 0.3750Epoch 25/10000\n",
      "192/208 [==========================>...] - ETA: 0s - loss: 0.6382 - accuracy: 0. - 0s 311us/step - loss: 0.7648 - accuracy: 0.5625 - val_loss: 0.5681 - val_accuracy: 0.6923\n",
      " - ETA: 0s - loss: 0.7720 - accuracy: 0.6354Epoch 24/10000\n",
      " - 0s 399us/step - loss: 0.7983 - accuracy: 0.6202 - val_loss: 0.6195 - val_accuracy: 0.6731\n",
      "208/208 [==============================] - 0s 347us/step - loss: 0.6948 - accuracy: 0.6394 - val_loss: 0.5752 - val_accuracy: 0.7019\n",
      "Epoch 26/10000\n",
      "Epoch 26/10000\n",
      "208/208 [==============================]5625 16/208 [=>............................] - ETA: 0s - loss: 0.6559 - accuracy: 0.62 - 0s 333us/step - loss: 0.6714 - accuracy: 0.5913 - val_loss: 0.5713 - val_accuracy: 0.6923\n",
      "Epoch 25/100\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.6146 - ETA: 0s - loss: 0.6535 - accuracy: 0.62 - 0s 339us/step - loss: 0.6255 - accuracy: 0.6298 - val_loss: 0.5643 - val_accuracy: 0.7212\n",
      "208/208 [==============================]Epoch 27/10000 - 0s 441us/step - loss: 0.6373 - accuracy: 0.6202 - val_loss: 0.6260 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 27/10000 16/208 [=>............................]\n",
      "208/208 [==============================]6875 - ETA: 0s - loss: 0.6743 - accuracy: 0.50 - 0s 354us/step - loss: 0.7173 - accuracy: 0.5865 - val_loss: 0.5721 - val_accuracy: 0.6923\n",
      "Epoch 26/10000\n",
      "\b 16/208 [=>............................] - ETA: 0s - loss: 0.6336 - accuracy: 0.6250208/208 [==============================]192/208 [==========================>...] - ETA: 0s - loss: 0.6821 - accuracy: 0.5833 - 0s 299us/step - loss: 0.6590 - accuracy: 0.6538 - val_loss: 0.5744 - val_accuracy: 0.7115\n",
      "Epoch 28/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.75 - 0s 398us/step - loss: 0.6874 - accuracy: 0.5817 - val_loss: 0.5841 - val_accuracy: 0.7308\n",
      "Epoch 28/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6753 - accuracy: 0.6250208/208 [==============================] - 0s 284us/step - loss: 0.7649 - accuracy: 0.5673 - val_loss: 0.6109 - val_accuracy: 0.6827\n",
      "Epoch 27/10000\n",
      " - ETA: 0s - loss: 0.6424 - accuracy: 0.6875208/208 [==============================] - 0s 326us/step - loss: 0.6464 - accuracy: 0.6442 - val_loss: 0.5548 - val_accuracy: 0.7308\n",
      "Epoch 29/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6164 - accuracy: 0.68 - 0s 312us/step - loss: 0.6521 - accuracy: 0.6202 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 29/10000\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.6843 - accuracy: 0.5625 - 0s 323us/step - loss: 0.6799 - accuracy: 0.5865 - val_loss: 0.6269 - val_accuracy: 0.6538\n",
      "208/208 [==============================] - 0s 334us/step - loss: 0.7170 - accuracy: 0.5817 - val_loss: 0.6135 - val_accuracy: 0.6635\n",
      "Epoch 30/10000\n",
      "208/208 [==============================] ETA: 0s - loss: 0.7076 - accuracy: 0.4375 - 0s 300us/step - loss: 0.7255 - accuracy: 0.6106 - val_loss: 0.6089 - val_accuracy: 0.6923\n",
      "Epoch 30/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0686 - accuracy: 0.37 - 0s 294us/step - loss: 0.6616 - accuracy: 0.6298 - val_loss: 0.6209 - val_accuracy: 0.6923\n",
      "Epoch 31/10000\n",
      " 16/208 [=>............................] - 0s 247us/step - loss: 0.7733 - accuracy: 0.6154 - val_loss: 0.5928 - val_accuracy: 0.7308\n",
      " - ETA: 0s - loss: 0.5113 - accuracy: 0.9375Epoch 31/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 353us/step - loss: 0.6655 - accuracy: 0.6202 - val_loss: 0.6546 - val_accuracy: 0.6442============================]\n",
      "208/208 [==============================] - 0s 330us/step - loss: 0.6466 - accuracy: 0.6538 - val_loss: 0.6727 - val_accuracy: 0.5577\n",
      "Epoch 32/10000\n",
      "Epoch 32/10000\n",
      "208/208 [=============================0.2500 16/208 [=>............................] - ETA: 0s - loss: 0.5587 - accuracy: 0.75 - 0s 275us/step - loss: 0.6903 - accuracy: 0.5962 - val_loss: 0.6924 - val_accuracy: 0.5385\n",
      "208/208 [==============================] - 0s 269us/step - loss: 0.7301 - accuracy: 0.6298 - val_loss: 0.5761 - val_accuracy: 0.7019\n",
      "Epoch 33/10000\n",
      "Epoch 33/10000\n",
      "208/208 [==============================]6875 16/208 [=>............................] - ETA: 0s - loss: 0.5990 - accuracy: 0. - 0s 263us/step - loss: 0.6837 - accuracy: 0.5865 - val_loss: 0.6564 - val_accuracy: 0.6154\n",
      "208/208 [==============================] - 0s 270us/step - loss: 0.8744 - accuracy: 0.6250 - val_loss: 0.5822 - val_accuracy: 0.6923\n",
      "Epoch 34/10000\n",
      "Epoch 34/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.6250 - ETA: 0s - loss: 0.5651 - accuracy: 0. - 0s 253us/step - loss: 0.6988 - accuracy: 0.5962 - val_loss: 0.6549 - val_accuracy: 0.6250\n",
      "208/208 [==============================] - 0s 260us/step - loss: 0.7000 - accuracy: 0.6442 - val_loss: 0.5668 - val_accuracy: 0.6923\n",
      "Epoch 35/10000\n",
      "Epoch 35/10000\n",
      " - 0s 262us/step - loss: 0.6763 - accuracy: 0.6346 - val_loss: 0.5685 - val_accuracy: 0.72120s - loss: 0.5901 - accuracy: 0.6208/208 [==============================]\n",
      "208/208 [==============================] - 0s 262us/step - loss: 0.8028 - accuracy: 0.6202 - val_loss: 0.5455 - val_accuracy: 0.7404\n",
      "Epoch 36/10000\n",
      "Epoch 36/10000\n",
      "208/208 [==============================]6875 16/208 [=>............................] - ETA: 0s - loss: 0.9731 - accuracy: 0.62 - 0s 302us/step - loss: 0.6808 - accuracy: 0.6442 - val_loss: 0.5787 - val_accuracy: 0.7019\n",
      "208/208 [==============================] - 0s 317us/step - loss: 0.7559 - accuracy: 0.5769 - val_loss: 0.6565 - val_accuracy: 0.7308\n",
      "Epoch 37/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6048 - accuracy: 0.68 - 0s 243us/step - loss: 0.6220 - accuracy: 0.6346 - val_loss: 0.5379 - val_accuracy: 0.7308\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "208/208 [==============================] - ETA: 5s - loss: 1.6723 - accuracy: 0.43 - 1s 3ms/step - loss: 1.5490 - accuracy: 0.4856 - val_loss: 0.5314 - val_accuracy: 0.6923\n",
      "Epoch 2/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0157 - accuracy: 0.43 - 0s 180us/step - loss: 1.1024 - accuracy: 0.6202 - val_loss: 0.6594 - val_accuracy: 0.5288\n",
      "Epoch 3/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.7891 - accuracy: 0.43 - 0s 201us/step - loss: 0.8668 - accuracy: 0.5288 - val_loss: 0.5475 - val_accuracy: 0.7596\n",
      "Epoch 4/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8004 - accuracy: 0.43 - 0s 211us/step - loss: 0.7790 - accuracy: 0.5673 - val_loss: 0.5086 - val_accuracy: 0.7885\n",
      "Epoch 5/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7557 - accuracy: 0.5625 - ETA: 6s - loss: 1.8953 - accuracy: 0.43 - 0s 251us/step - loss: 0.9294 - accuracy: 0.6106 - val_loss: 0.5420 - val_accuracy: 0.8269\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.5625 - ETA: 6s - loss: 2.5144 - accuracy: 0.37 - 0s 270us/step - loss: 0.7041 - accuracy: 0.6250 - val_loss: 0.6683 - val_accuracy: 0.5769\n",
      "Epoch 7/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.56 - 0s 209us/step - loss: 0.7009 - accuracy: 0.5721 - val_loss: 0.4931 - val_accuracy: 0.8269\n",
      "Epoch 8/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0. - 0s 214us/step - loss: 0.7496 - accuracy: 0.6490 - val_loss: 0.5109 - val_accuracy: 0.8173\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 1.3628 - accuracy: 0.5962 - val_loss: 0.6078 - val_accuracy: 0.6154\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.75 - 1s 4ms/step - loss: 1.4410 - accuracy: 0.5048 - val_loss: 0.5485 - val_accuracy: 0.8077\n",
      "208/208 [==============================] - 0s 263us/step - loss: 0.9702 - accuracy: 0.5240 - val_loss: 0.6153 - val_accuracy: 0.7019\n",
      "Epoch 10/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6767 - accuracy: 0.5000Epoch 2/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 1.3342 - accuracy: 0.62Epoch 2/10000\n",
      "208/208 [==============================] - 0s 318us/step - loss: 0.7067 - accuracy: 0.5433 - val_loss: 0.6531 - val_accuracy: 0.5962\n",
      "208/208 [==============================] ETA: 0s - loss: 0.8669 - accuracy: 0.5625Epoch 11/10000\n",
      " - 0s 325us/step - loss: 1.2383 - accuracy: 0.5673 - val_loss: 0.5808 - val_accuracy: 0.5481\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7029 - accuracy: 0.5000Epoch 3/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8776 - accuracy: 0.50 - 0s 298us/step - loss: 0.6815 - accuracy: 0.6298 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 3/10000208/208 [==============================]\n",
      " - 0s 328us/step - loss: 0.7063 - accuracy: 0.5529 - val_loss: 0.5519 - val_accuracy: 0.8365\n",
      " 16/208 [=>...........................Epoch 12/10000 - ETA: 0s - loss: 0.6456 - accuracy: 0.5000\n",
      "208/208 [==============================] - 0s 326us/step - loss: 0.8871 - accuracy: 0.5817 - val_loss: 0.6528 - val_accuracy: 0.6442\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6716 - accuracy: 0.3750Epoch 4/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6745 - accuracy: 0208/208 [==============================]128/208 [=================>............]208/208 [==============================] - 0s 343us/step - loss: 0.8904 - accuracy: 0.6587 - val_loss: 0.4678 - val_accuracy: 0.8365\n",
      " - ETA: 0s - loss: 0.9154 - accuracy: 0.5078 - 0s 336us/step - loss: 0.6856 - accuracy: 0.6058 - val_loss: 0.6414 - val_accuracy: 0.6731\n",
      "Epoch 4/10000Epoch 13/10000\n",
      "\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6223 - accuracy: 0.6875 16/208 [=>............................] - ETA: 0s - loss: 0.7649 - accuracy: 0.50 - 0s 418us/step - loss: 0.9187 - accuracy: 0.5096 - val_loss: 0.6673 - val_accuracy: 0.6442\n",
      "Epoch 5/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6171 - accuracy: 0.208/208 [==============================]208/208 [==============================] - 0s 317us/step - loss: 0.6889 - accuracy: 0.5625 - val_loss: 0.6493 - val_accuracy: 0.6346\n",
      " - 0s 311us/step - loss: 0.6948 - accuracy: 0.5769 - val_loss: 0.5307 - val_accuracy: 0.8173\n",
      "Epoch 14/10000Epoch 5/10000\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.5539 - accuracy: 0.8750 - ETA: 0s - loss: 0.8079 - accuracy: 0.43 - 0s 325us/step - loss: 0.7683 - accuracy: 0.5144 - val_loss: 0.6658 - val_accuracy: 0.6442\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.208/208 [==============================] - 0s 298us/step - loss: 0.8541 - accuracy: 0.5721 - val_loss: 0.4803 - val_accuracy: 0.8365\n",
      " - 0s 321us/step - loss: 0.6618 - accuracy: 0.5913 - val_loss: 0.5887 - val_accuracy: 0.7885\n",
      "Epoch 6/10000\n",
      "Epoch 15/10000\n",
      "208/208 [==============================]7500 16/208 [=>............................] - ETA: 0s - loss: 0.6865 - accuracy: 0.50 - 0s 294us/step - loss: 0.8564 - accuracy: 0.5433 - val_loss: 0.6767 - val_accuracy: 0.5288\n",
      "Epoch 7/100\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 265us/step - loss: 0.7555 - accuracy: 0.6010 - val_loss: 0.6085 - val_accuracy: 0.6635\n",
      " - ETA: 0s - loss: 0.6476 - accuracy: 0.75Epoch 7/10000\n",
      "208/208 [==============================] - 0s 298us/step - loss: 0.6736 - accuracy: 0.6058 - val_loss: 0.5666 - val_accuracy: 0.8077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/208 [=>............................]Epoch 16/10000 - ETA: 0s - loss: 1.4329 - accuracy: 0.3750\n",
      " - 0s 339us/step - loss: 0.7791 - accuracy: 0.5385 - val_loss: 0.6168 - val_accuracy: 0.6827============================]\n",
      "192/208 [==========================>...] - ETA: 0s - loss: 0.8324 - accuracy: 0.56Epoch 8/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.6364 - ETA: 0s - loss: 0.7374 - accuracy: 0. - 0s 417us/step - loss: 0.8161 - accuracy: 0.5673 - val_loss: 0.6514 - val_accuracy: 0.6250\n",
      "208/208 [==============================]Epoch 8/10000\n",
      " - 0s 432us/step - loss: 0.6758 - accuracy: 0.6298 - val_loss: 0.5095 - val_accuracy: 0.8269\n",
      "Epoch 17/10000 16/208 [=>............................] - ETA: 0s - loss: 0.9934 - accuracy: 0.6875\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.62 - 0s 359us/step - loss: 0.7145 - accuracy: 0.6731 - val_loss: 0.5462 - val_accuracy: 0.7885\n",
      "Epoch 9/10000\n",
      " - 0s 336us/step - loss: 0.8751 - accuracy: 0.5817 - val_loss: 0.4736 - val_accuracy: 0.7885\n",
      "208/208 [==============================] - 0s 316us/step - loss: 0.7548 - accuracy: 0.6394 - val_loss: 0.5991 - val_accuracy: 0.7404\n",
      "Epoch 9/10000\n",
      "Epoch 18/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.5000 - ETA: 0s - loss: 1.1081 - accuracy: 0.56 - 0s 333us/step - loss: 0.7085 - accuracy: 0.5913 - val_loss: 0.5737 - val_accuracy: 0.7885\n",
      "Epoch 10/100\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7660 - accuracy: 0.60 - ETA: 0s - loss: 0.7413 - accuracy: 0.5625 - 0s 330us/step - loss: 0.7877 - accuracy: 0.5962 - val_loss: 0.5636 - val_accuracy: 0.7788\n",
      "Epoch 10/100\n",
      " - 0s 400us/step - loss: 0.7931 - accuracy: 0.6154 - val_loss: 0.5243 - val_accuracy: 0.8077\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.8522 - accuracy: 0.5000Epoch 19/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.62 - 0s 310us/step - loss: 0.7905 - accuracy: 0.5865 - val_loss: 0.6933 - val_accuracy: 0.5385\n",
      "Epoch 11/10000\n",
      " - ETA: 0s - loss: 0.7850 - accuracy: 0.4375208/208 [==============================] - 0s 332us/step - loss: 0.6901 - accuracy: 0.6635 - val_loss: 0.5006 - val_accuracy: 0.7981\n",
      "Epoch 11/10000\n",
      " - ETA: 0s - loss: 0.8434 - accuracy: 0.3750208/208 [==============================] - 0s 340us/step - loss: 0.7061 - accuracy: 0.5721 - val_loss: 0.5339 - val_accuracy: 0.8269\n",
      "Epoch 20/10000\n",
      " - 0s 347us/step - loss: 0.7476 - accuracy: 0.5144 - val_loss: 0.6438 - val_accuracy: 0.6442============================]\n",
      "192/208 [==========================>...] - ETA: 0s - loss: 0.8266 - accuracy: 0.5677Epoch 12/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7042 - accuracy: 0.208/208 [==============================]208/208 [==============================] - 0s 417us/step - loss: 0.8443 - accuracy: 0.5673 - val_loss: 0.4975 - val_accuracy: 0.8077\n",
      " - 0s 321us/step - loss: 0.6885 - accuracy: 0.6154 - val_loss: 0.5364 - val_accuracy: 0.8269\n",
      "Epoch 12/10000Epoch 21/10000\n",
      "\n",
      "208/208 [==============================]3750 16/208 [=>............................] - ETA: 0s - loss: 0.7145 - accuracy: 0.50 - 0s 315us/step - loss: 0.7203 - accuracy: 0.5817 - val_loss: 0.5703 - val_accuracy: 0.7885\n",
      "Epoch 13/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6174 - accuracy: 0.208/208 [==============================]208/208 [==============================] - 0s 294us/step - loss: 0.6628 - accuracy: 0.6058 - val_loss: 0.4684 - val_accuracy: 0.8173\n",
      " - 0s 314us/step - loss: 0.8426 - accuracy: 0.5913 - val_loss: 0.6071 - val_accuracy: 0.7115\n",
      "Epoch 13/10000Epoch 22/10000\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.7352 - accuracy: 0.4375 - ETA: 0s - loss: 1.0695 - accuracy: 0.43 - 0s 294us/step - loss: 0.7226 - accuracy: 0.6346 - val_loss: 0.5485 - val_accuracy: 0.7692\n",
      "Epoch 14/1\n",
      " - 0s 269us/step - loss: 0.7674 - accuracy: 0.5481 - val_loss: 0.6088 - val_accuracy: 0.7308\n",
      " - 0s 273us/step - loss: 0.6654 - accuracy: 0.6010 - val_loss: 0.4797 - val_accuracy: 0.8077\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.5948 - accuracy: 0.5625Epoch 23/10000Epoch 14/10000\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 1.1323 - accuracy: 0.4375 - ETA: 0s - loss: 0.6406 - accuracy: 0. - 0s 279us/step - loss: 0.7466 - accuracy: 0.6202 - val_loss: 0.6367 - val_accuracy: 0.6346\n",
      "208/208 [==============================] ETA: 0s - loss: 0.8415 - accuracy: 0.5795Epoch 15/10000 - 0s 292us/step - loss: 0.6365 - accuracy: 0.6202 - val_loss: 0.5102 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 15/10000 16/208 [=>............................] - ETA: 0s - loss: 0.6902 - accuracy: 0.5625\n",
      " 16/208 [=>............................]208/208 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.7500 - 0s 404us/step - loss: 0.8075 - accuracy: 0.5962 - val_loss: 0.6777 - val_accuracy: 0.5673\n",
      "Epoch 24/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 1.0635 - accuracy: 0.208/208 [==============================]208/208 [==============================] - 0s 315us/step - loss: 0.6784 - accuracy: 0.6010 - val_loss: 0.5244 - val_accuracy: 0.8077\n",
      " - 0s 362us/step - loss: 0.6613 - accuracy: 0.6250 - val_loss: 0.5879 - val_accuracy: 0.7500\n",
      "144/208 [===================>..........]Epoch 16/10000Epoch 16/10000\n",
      " - ETA: 0s - loss: 0.7112 - accuracy: 0.5764\n",
      "208/208 [==============================]5625 16/208 [=>............................] - ETA: 0s - loss: 1.7966 - accuracy: 0.50 - 0s 444us/step - loss: 0.7593 - accuracy: 0.5673 - val_loss: 0.5650 - val_accuracy: 0.7596\n",
      "Epoch 25/10000176/208 [========================>.....]\n",
      " - ETA: 0s - loss: 0.8058 - accuracy: 0.59208/208 [==============================] 16/208 [=>............................] - 0s 329us/step - loss: 0.6993 - accuracy: 0.6058 - val_loss: 0.5948 - val_accuracy: 0.7788\n",
      " - ETA: 0s - loss: 0.7653 - accuracy: 0.4375Epoch 17/10000\n",
      " 16/208 [=>............................]208/208 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.5625 - 0s 433us/step - loss: 0.7832 - accuracy: 0.5913 - val_loss: 0.5346 - val_accuracy: 0.8269\n",
      "Epoch 17/10000\n",
      "208/208 [==============================] - 0s 250us/step - loss: 0.6530 - accuracy: 0.5913 - val_loss: 0.5274 - val_accuracy: 0.7981\n",
      " 16/208 [=>............................]Epoch 26/10000 - ETA: 0s - loss: 0.9936 - accuracy: 0.6250\n",
      "208/208 [==============================]] - ETA: 0s - loss: 1.7340 - accuracy: 0.5625 - 0s 283us/step - loss: 0.6570 - accuracy: 0.6106 - val_loss: 0.6067 - val_accuracy: 0.7212\n",
      "Epoch 18/10000\n",
      "208/208 [==============================] ETA: 0s - loss: 0.7107 - accuracy: 0.562208/208 [==============================] - 0s 306us/step - loss: 0.7753 - accuracy: 0.5625 - val_loss: 0.5071 - val_accuracy: 0.8173\n",
      " - 0s 322us/step - loss: 0.9252 - accuracy: 0.6058 - val_loss: 0.4640 - val_accuracy: 0.8365\n",
      "Epoch 27/10000\n",
      "Epoch 18/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.5625 - ETA: 0s - loss: 0.9834 - accuracy: 0.43 - 0s 386us/step - loss: 0.7147 - accuracy: 0.5721 - val_loss: 0.6885 - val_accuracy: 0.5577\n",
      "Epoch 19/100160/208 [======================>.......]\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7260 - accuracy: 0.6000 - 0s 286us/step - loss: 0.7873 - accuracy: 0.5721 - val_loss: 0.6463 - val_accuracy: 0.6731\n",
      " 16/208 [=>............................]Epoch 28/10000 - ETA: 0s - loss: 0.7963 - accuracy: 0.4375\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.37 - 0s 458us/step - loss: 0.7168 - accuracy: 0.5817 - val_loss: 0.4919 - val_accuracy: 0.8173\n",
      "Epoch 19/10000208/208 [==============================]208/208 [==============================]\n",
      " - 0s 313us/step - loss: 0.7973 - accuracy: 0.5577 - val_loss: 0.6845 - val_accuracy: 0.5577\n",
      " - 0s 276us/step - loss: 0.6653 - accuracy: 0.5721 - val_loss: 0.6578 - val_accuracy: 0.6635\n",
      " 16/208 [=>............................]Epoch 20/10000Epoch 29/10000 - ETA: 0s - loss: 0.6173 - accuracy: 0.7500\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s - loss: 0.6808 - accuracy: 0.5625208 [=>............................] - ETA: 0s - loss: 0.6147 - accuracy: 0.7500 - ETA: 0s - loss: 0.6605 - accuracy: 0.5160/208 [======================>.......]208/208 [============================= - 0s 319us/step - loss: 0.7117 - accuracy: 0.6010 - val_loss: 0.5264 - val_accuracy: 0.8077\n",
      "208/208 [==============================]Epoch 20/10000\n",
      " - 0s 308us/step - loss: 0.7259 - accuracy: 0.5433 - val_loss: 0.6910 - val_accuracy: 0.5385\n",
      "Epoch 21/10000 16/208 [=>............................]\n",
      "208/208 [==============================]43 - ETA: 0s - loss: 0.8154 - accuracy: 0.5000 - 0s 422us/step - loss: 0.6786 - accuracy: 0.5913 - val_loss: 0.6317 - val_accuracy: 0.6923\n",
      "Epoch 30/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.43 - 0s 306us/step - loss: 0.8384 - accuracy: 0.5721 - val_loss: 0.5674 - val_accuracy: 0.7981\n",
      "Epoch 21/10000\n",
      "208/208 [==============================] - 0s 338us/step - loss: 0.7414 - accuracy: 0.5962 - val_loss: 0.6909 - val_accuracy: 0.5385\n",
      " 16/208 [=>............................]Epoch 22/10000 - ETA: 0s - loss: 0.7485 - accuracy: 0.56\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.7353 - accuracy: 0.3125 - ETA: 0s - loss: 0.6693 - accuracy: 0.58 - 0s 445us/step - loss: 0.6670 - accuracy: 0.5913 - val_loss: 0.6102 - val_accuracy: 0.7596\n",
      "Epoch 31/10000\n",
      " - 0s 348us/step - loss: 0.6816 - accuracy: 0.6154 - val_loss: 0.5351 - val_accuracy: 0.7885oss: 0.5961 - accuracy: 0.5625\n",
      "208/208 [==============================] - 0s 330us/step - loss: 0.7823 - accuracy: 0.5481 - val_loss: 0.6906 - val_accuracy: 0.5385\n",
      "Epoch 22/10000\n",
      "Epoch 23/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7839 - accuracy: 0.5000 - ETA: 0s - loss: 0.6970 - accuracy: 0.50176/208 [========================>.....]208/208 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.5795 - 0s 356us/step - loss: 0.7612 - accuracy: 0.5913 - val_loss: 0.5452 - val_accuracy: 0.8077\n",
      "Epoch 32/10000208/208 [==============================]\n",
      " - 0s 300us/step - loss: 0.7120 - accuracy: 0.5817 - val_loss: 0.6528 - val_accuracy: 0.6442\n",
      "208/208 [==============================] ETA: 0s - loss: 0.6138 - accuracy: 0.5625 - 0s 412us/step - loss: 0.7188 - accuracy: 0.5817 - val_loss: 0.5884 - val_accuracy: 0.7788\n",
      "Epoch 23/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.56 - 0s 340us/step - loss: 0.6859 - accuracy: 0.6106 - val_loss: 0.5425 - val_accuracy: 0.8269\n",
      "Epoch 33/100\n",
      "208/208 [==============================] - 0s 273us/step - loss: 0.7037 - accuracy: 0.5769 - val_loss: 0.5649 - val_accuracy: 0.7692\n",
      " 16/208 [=>............................]Epoch 24/10000 - ETA: 0s - loss: 0.8888 - accuracy: 0.3125\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.62 - 0s 253us/step - loss: 0.6910 - accuracy: 0.5962 - val_loss: 0.5581 - val_accuracy: 0.7981\n",
      "Epoch 34/10000\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 292us/step - loss: 0.7027 - accuracy: 0.5769 - val_loss: 0.5592 - val_accuracy: 0.7404\n",
      " - ETA: 0s - loss: 0.5948 - accuracy: 0.5625Epoch 25/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.56 - 0s 262us/step - loss: 0.6939 - accuracy: 0.5673 - val_loss: 0.5743 - val_accuracy: 0.7981\n",
      "Epoch 35/100\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 338us/step - loss: 0.7512 - accuracy: 0.5817 - val_loss: 0.5772 - val_accuracy: 0.7404\n",
      " - ETA: 0s - loss: 1.4615 - accuracy: 0.5000Epoch 26/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.56 - 0s 284us/step - loss: 0.8450 - accuracy: 0.5625 - val_loss: 0.8684 - val_accuracy: 0.5385\n",
      "Epoch 36/100\n",
      " - 0s 248us/step - loss: 0.7080 - accuracy: 0.5577 - val_loss: 0.6606 - val_accuracy: 0.6538\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.8859 - accuracy: 0.5000Epoch 27/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.62 - 0s 271us/step - loss: 0.7309 - accuracy: 0.5769 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
      "Epoch 37/10000208/208 [==============================]\n",
      " - 0s 269us/step - loss: 0.6938 - accuracy: 0.5577 - val_loss: 0.6785 - val_accuracy: 0.6058\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6982 - accuracy: 0.5000Epoch 28/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7165 - accuracy: 0.50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-06 15:58:34,210]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 812us/step - loss: 0.7651 - accuracy: 0.5481 - val_loss: 0.7485 - val_accuracy: 0.5577\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Finished trial#1 with value: 0.5103859855578495 with parameters: {'input_dropout': 0.7167152904533249, 'hidden_layers': 1, 'hidden_units': 24.0, 'hidden_dropout': 0.24537038185395454, 'batch_norm': 'before_act', 'batch_size': 32.0}. Best is trial#1 with value: 0.5103859855578495."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================]Epoch 38/10000\n",
      " - 0s 808us/step - loss: 0.6990 - accuracy: 0.5865 - val_loss: 0.5996 - val_accuracy: 0.8269\n",
      "Epoch 29/10000 16/208 [=>............................] - ETA: 0s - loss: 0.7105 - accuracy: 0.5625\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.56 - 0s 166us/step - loss: 0.8347 - accuracy: 0.5577 - val_loss: 0.6915 - val_accuracy: 0.5385\n",
      "208/208 [==============================]\n",
      " - 0s 198us/step - loss: 0.7702 - accuracy: 0.5721 - val_loss: 0.7549 - val_accuracy: 0.5481\n",
      " 16/208 [=>............................]Epoch 30/10000 - ETA: 0s - loss: 0.6853 - accuracy: 0.5625\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.9678 - accuracy: 0.56 - 0s 247us/step - loss: 0.7010 - accuracy: 0.5433 - val_loss: 0.6867 - val_accuracy: 0.5481\n",
      "208/208 [==============================]\n",
      " - 0s 267us/step - loss: 0.7191 - accuracy: 0.5529 - val_loss: 0.6896 - val_accuracy: 0.5481\n",
      "Epoch 31/10000 16/208 [=>............................]\n",
      "208/208 [==============================]4375 - ETA: 0s - loss: 0.6082 - accuracy: 0.75 - 0s 250us/step - loss: 0.6916 - accuracy: 0.5817 - val_loss: 0.6853 - val_accuracy: 0.5577\n",
      "208/208 [==============================]Epoch 41/10000 - 0s 254us/step - loss: 0.6876 - accuracy: 0.5529 - val_loss: 0.6869 - val_accuracy: 0.5577\n",
      "\n",
      "Epoch 32/10000 16/208 [=>............................]\n",
      "208/208 [==============================]3750 - ETA: 0s - loss: 0.6996 - accuracy: 0.50 - 0s 249us/step - loss: 0.7519 - accuracy: 0.5673 - val_loss: 0.6755 - val_accuracy: 0.5673\n",
      "208/208 [==============================] - 0s 325us/step - loss: 0.6875 - accuracy: 0.5481 - val_loss: 0.6778 - val_accuracy: 0.5865\n",
      "Epoch 33/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.50 - 0s 200us/step - loss: 0.6776 - accuracy: 0.5673 - val_loss: 0.6592 - val_accuracy: 0.6442\n",
      "Epoch 34/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.31 - 0s 196us/step - loss: 0.7059 - accuracy: 0.5673 - val_loss: 0.6171 - val_accuracy: 0.6923\n",
      "Epoch 35/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.68 - 0s 216us/step - loss: 0.7598 - accuracy: 0.5865 - val_loss: 0.5972 - val_accuracy: 0.7019\n",
      "Epoch 36/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.56 - 0s 269us/step - loss: 0.7123 - accuracy: 0.5625 - val_loss: 0.6249 - val_accuracy: 0.7019\n",
      "Epoch 37/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.9216 - accuracy: 0.31 - 0s 181us/step - loss: 0.7059 - accuracy: 0.5481 - val_loss: 0.7141 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-06 15:58:34,941] Finished trial#0 with value: 0.5069795877505572 with parameters: {'input_dropout': 0.6390508031418598, 'hidden_layers': 2, 'hidden_units': 56.0, 'hidden_dropout': 0.8863564940982054, 'batch_norm': 'non', 'batch_size': 32.0}. Best is trial#0 with value: 0.5069795877505572.\n",
      "[I 2020-10-06 15:58:35,176] Finished trial#2 with value: 0.4926520853470533 with parameters: {'input_dropout': 0.8333800304661316, 'hidden_layers': 2, 'hidden_units': 32.0, 'hidden_dropout': 0.5142278368806639, 'batch_norm': 'non', 'batch_size': 16.0}. Best is trial#2 with value: 0.4926520853470533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207 samples, validate on 104 samples\n",
      "Train on 207 samples, validate on 104 samples\n",
      "Train on 207 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "207/207 [==============================] - ETA: 5s - loss: 1.1371 - accuracy: 0.6250 - ETA: 5s - loss: 1.0500 - accuracy: 0.4375 - ETA: 5s - loss: 0.5529 - accuracy: 0.56 - 1s 3ms/step - loss: 1.4380 - accuracy: 0.5845 - val_loss: 0.6576 - val_accuracy: 0.6635\n",
      "207/207 [==============================] - 1s 3ms/step - loss: 1.3336 - accuracy: 0.4879 - val_loss: 0.5689 - val_accuracy: 0.7115\n",
      "Epoch 2/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.8268 - accuracy: 0.7500Epoch 2/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.0277 - accuracy: 0.37 - 1s 3ms/step - loss: 1.3281 - accuracy: 0.5942 - val_loss: 0.5418 - val_accuracy: 0.7308\n",
      "207/207 [==============================] - 0s 244us/step - loss: 1.0212 - accuracy: 0.5797 - val_loss: 0.6132 - val_accuracy: 0.6731\n",
      "Epoch 3/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 1.2366 - accuracy: 0.5000Epoch 2/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8125 - 0s 333us/step - loss: 0.8743 - accuracy: 0.5314 - val_loss: 0.6541 - val_accuracy: 0.6827\n",
      "Epoch 3/10000\n",
      "207/207 [==============================] ETA: 0s - loss: 0.7592 - accuracy: 0.6250 - 0s 294us/step - loss: 0.7829 - accuracy: 0.5894 - val_loss: 0.5766 - val_accuracy: 0.7212\n",
      "Epoch 4/10000\n",
      "207/207 [==============================] ETA: 0s - loss: 0.5666 - accuracy: 0.7500 - 0s 320us/step - loss: 1.0553 - accuracy: 0.5459 - val_loss: 0.6892 - val_accuracy: 0.5288\n",
      "Epoch 3/10000192/207 [==========================>...]\n",
      "207/207 [==============================]5729 - ETA: 0s - loss: 1.1243 - accuracy: 0.68 - 0s 418us/step - loss: 0.9381 - accuracy: 0.5700 - val_loss: 0.8079 - val_accuracy: 0.5385\n",
      "Epoch 4/10000207/207 [==============================]\n",
      " - 0s 319us/step - loss: 0.7864 - accuracy: 0.6232 - val_loss: 0.6470 - val_accuracy: 0.5962\n",
      " 16/207 [=>............................]Epoch 5/10000 - ETA: 0s - loss: 1.4269 - accuracy: 0.3750\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.6875 - 0s 298us/step - loss: 0.7553 - accuracy: 0.5990 - val_loss: 0.5894 - val_accuracy: 0.7404\n",
      "Epoch 4/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.5793 - accuracy: 0.207/207 [==============================]207/207 [==============================] - 0s 319us/step - loss: 0.6886 - accuracy: 0.6570 - val_loss: 0.5474 - val_accuracy: 0.7404\n",
      " - 0s 371us/step - loss: 0.8662 - accuracy: 0.5266 - val_loss: 0.5605 - val_accuracy: 0.7596\n",
      "Epoch 6/10000\n",
      "Epoch 5/10000\n",
      " - 0s 292us/step - loss: 0.6773 - accuracy: 0.6570 - val_loss: 0.5969 - val_accuracy: 0.7212\n",
      " 16/207 [=>............................] 16/207 [=>............................] - ETA: 0s - loss: 0.4636 - accuracy: 0.7500 - ETA: 0s - loss: 0.7343 - accuracy: 0.6250Epoch 5/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7624 - accuracy: 0.5207/207 [============================= - 0s 329us/step - loss: 0.7037 - accuracy: 0.6329 - val_loss: 0.5684 - val_accuracy: 0.7308\n",
      "207/207 [==============================]207/207 [==============================] - 0s 295us/step - loss: 0.7366 - accuracy: 0.5894 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 7/10000 - 0s 341us/step - loss: 0.7048 - accuracy: 0.6425 - val_loss: 0.5523 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 6/10000Epoch 6/10000\n",
      " 16/207 [=>............................]\n",
      " - ETA: 0s - loss: 1.2692 - accuracy: 0.5000 16/207 [=>............................] 16/207 [=>............................] - ETA: 0s - loss: 0.8508 - accuracy: 0.6875 - ETA: 0s - loss: 0.9222 - accuracy: 0.207/207 [=============================207/207 [==============================] - 0s 293us/step - loss: 0.7295 - accuracy: 0.6377 - val_loss: 0.6097 - val_accuracy: 0.7019\n",
      " - 0s 297us/step - loss: 0.7507 - accuracy: 0.6618 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "207/207 [==============================]Epoch 7/10000Epoch 7/10000\n",
      "\n",
      " - 0s 344us/step - loss: 0.9277 - accuracy: 0.5411 - val_loss: 0.5744 - val_accuracy: 0.7308\n",
      " 16/207 [=>............................]Epoch 8/10000 16/207 [=>............................]\n",
      " - 0s 272us/step - loss: 0.7373 - accuracy: 0.6425 - val_loss: 0.5391 - val_accuracy: 0.7500TA: 0s - loss: 0.5994 - accuracy: 0207/207 [==============================]\n",
      " - ETA: 0s - loss: 0.5783 - accuracy: 0.7321207/207 [==============================]Epoch 8/10000 - 0s 304us/step - loss: 0.9219 - accuracy: 0.6522 - val_loss: 0.5083 - val_accuracy: 0.7596\n",
      "\n",
      "Epoch 8/10000 16/207 [=>............................]\n",
      "207/207 [==============================]5625 - ETA: 0s - loss: 0.8114 - accuracy: 0.56 - 0s 489us/step - loss: 0.6242 - accuracy: 0.6908 - val_loss: 0.5197 - val_accuracy: 0.7404\n",
      "192/207 [==========================>...]\n",
      "207/207 [==============================]750016/207 [=>............................]176/207 [========================>.....] - ETA: 0s - loss: 0.8329 - accuracy: 0.65 - 0s 424us/step - loss: 0.7062 - accuracy: 0.6522 - val_loss: 0.5497 - val_accuracy: 0.7308\n",
      "207/207 [==============================]\n",
      " - 0s 459us/step - loss: 0.8402 - accuracy: 0.6425 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 9/10000 16/207 [=>............................] - ETA: 0s - loss: 0.6084 - accuracy: 0.6250\n",
      "207/207 [==============================] ETA: 0s - loss: 0.7608 - accuracy: 0.6250 - 0s 355us/step - loss: 0.6622 - accuracy: 0.6425 - val_loss: 0.5572 - val_accuracy: 0.7500\n",
      "Epoch 10/10000\n",
      "207/207 [==============================]7500192/207 [==========================>...] - ETA: 0s - loss: 0.6585 - accuracy: 0. - 0s 357us/step - loss: 0.7943 - accuracy: 0.6135 - val_loss: 0.6125 - val_accuracy: 0.6923\n",
      " - 0s 439us/step - loss: 0.6519 - accuracy: 0.6763 - val_loss: 0.5591 - val_accuracy: 0.7404\n",
      "Epoch 10/10000Epoch 10/10000\n",
      "\n",
      " - ETA: 0s - loss: 0.7721 - accuracy: 0.43757 [=>............................] - ETA: 0s - loss: 0.6899 - accuracy: 0.5625207/207 [==============================] - 0s 323us/step - loss: 0.6689 - accuracy: 0.6377 - val_loss: 0.5290 - val_accuracy: 0.7596\n",
      "Epoch 11/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0. - ETA: 0s - loss: 0.7381 - accuracy: 0.5885 - 0s 326us/step - loss: 0.7758 - accuracy: 0.6184 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 11/10000\n",
      "207/207 [==============================] 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.8766 - accuracy: 0.4375 - 0s 458us/step - loss: 0.7448 - accuracy: 0.5700 - val_loss: 0.6493 - val_accuracy: 0.6346\n",
      " - 0s 342us/step - loss: 0.6771 - accuracy: 0.6812 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 11/10000\n",
      "Epoch 12/10000\n",
      " - ETA: 0s - loss: 0.5849 - accuracy: 0.6875 16/207 [=>............................] - ETA: 0s - loss: 1.4466 - accuracy: 0.81207/207 [=============================192/207 [==========================>...] - 0s 341us/step - loss: 0.8406 - accuracy: 0.6135 - val_loss: 0.5342 - val_accuracy: 0.7404\n",
      " - ETA: 0s - loss: 0.6734 - accuracy: 0.6042192/207 [==========================>...] - ETA: 0s - loss: 0.8744 - accuracy: 0.6562Epoch 12/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7664 - accuracy: 0.6207/207 [==============================] - 0s 393us/step - loss: 0.7218 - accuracy: 0.5942 - val_loss: 0.6733 - val_accuracy: 0.5962\n",
      "207/207 [==============================] - 0s 402us/step - loss: 0.8624 - accuracy: 0.6522 - val_loss: 0.5677 - val_accuracy: 0.7212\n",
      "Epoch 12/10000\n",
      "Epoch 13/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.5625 - ETA: 0s - loss: 0.4744 - accuracy: 0.75 - 0s 361us/step - loss: 0.7784 - accuracy: 0.6232 - val_loss: 0.5488 - val_accuracy: 0.7308\n",
      "Epoch 13/10000\n",
      "207/207 [==============================]] - ETA: 0s - loss: 0.6643 - accuracy: 0.5625 - 0s 341us/step - loss: 0.6985 - accuracy: 0.5652 - val_loss: 0.6956 - val_accuracy: 0.5385\n",
      "207/207 [==============================]Epoch 13/10000 - 0s 349us/step - loss: 0.7198 - accuracy: 0.6280 - val_loss: 0.5400 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.6250 - ETA: 0s - loss: 1.3913 - accuracy: 0.56 - 0s 341us/step - loss: 0.8115 - accuracy: 0.5749 - val_loss: 0.5693 - val_accuracy: 0.7308\n",
      "Epoch 14/10000\n",
      "207/207 [============================== - 0s 306us/step - loss: 0.6854 - accuracy: 0.5700 - val_loss: 0.6812 - val_accuracy: 0.5673\n",
      " - ETA: 0s - loss: 0.6685 - accuracy: 0.5000207/207 [==============================]Epoch 14/10000 - 0s 310us/step - loss: 0.6969 - accuracy: 0.6570 - val_loss: 0.5240 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 15/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6682 - accuracy: 0.5625 - ETA: 0s - loss: 0.8752 - accuracy: 0.50 - 0s 275us/step - loss: 0.7176 - accuracy: 0.6377 - val_loss: 0.5516 - val_accuracy: 0.7404\n",
      "192/207 [==========================>...]\n",
      " - ETA: 0s - loss: 0.7414 - accuracy: 0.6406207/207 [==============================] - 0s 303us/step - loss: 0.6596 - accuracy: 0.5990 - val_loss: 0.6553 - val_accuracy: 0.6346\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.6223 - accuracy: 0.6875Epoch 15/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.6250 - 0s 371us/step - loss: 0.7284 - accuracy: 0.6473 - val_loss: 0.5959 - val_accuracy: 0.7019\n",
      "Epoch 16/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.8594 - accuracy: 0.68 - 0s 298us/step - loss: 0.7983 - accuracy: 0.6135 - val_loss: 0.5397 - val_accuracy: 0.7308\n",
      "Epoch 16/10000207/207 [==============================]\n",
      " - 0s 291us/step - loss: 0.7883 - accuracy: 0.5604 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      " 16/207 [=>............................]Epoch 16/10000 - ETA: 0s - loss: 0.7709 - accuracy: 0.5000\n",
      "207/207 [==============================] ETA: 0s - loss: 0.6589 - accuracy: 0.5625 - 0s 336us/step - loss: 0.7072 - accuracy: 0.6232 - val_loss: 0.6603 - val_accuracy: 0.5962\n",
      "Epoch 17/10000\n",
      " - 0s 309us/step - loss: 0.9422 - accuracy: 0.5942 - val_loss: 0.5247 - val_accuracy: 0.7404\n",
      "192/207 [==========================>...] - ETA: 0s - loss: 0.7611 - accuracy: 0.5781Epoch 17/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.5487 - accuracy: 0.68192/207 [==========================>...]207/207 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.6354 - 0s 437us/step - loss: 0.7465 - accuracy: 0.5942 - val_loss: 0.6231 - val_accuracy: 0.6827\n",
      "Epoch 17/10000\n",
      " - ETA: 0s - loss: 0.5685 - accuracy: 0.8750207/207 [==============================] - 0s 437us/step - loss: 0.6282 - accuracy: 0.6377 - val_loss: 0.5187 - val_accuracy: 0.7404\n",
      "Epoch 18/10000207/207 [==============================]\n",
      " - 0s 307us/step - loss: 0.7277 - accuracy: 0.6232 - val_loss: 0.5273 - val_accuracy: 0.7788\n",
      " 16/207 [=>............................]Epoch 18/10000 - ETA: 0s - loss: 0.6946 - accuracy: 0.5625\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.1410 - accuracy: 0.62 - 0s 299us/step - loss: 0.6732 - accuracy: 0.5990 - val_loss: 0.6098 - val_accuracy: 0.7212\n",
      "Epoch 18/10000\n",
      " - ETA: 0s - loss: 0.6085 - accuracy: 0.6875207/207 [==============================] - 0s 312us/step - loss: 0.8673 - accuracy: 0.6184 - val_loss: 0.6261 - val_accuracy: 0.6635\n",
      "207/207 [==============================]\n",
      " - 0s 323us/step - loss: 0.6864 - accuracy: 0.6329 - val_loss: 0.4994 - val_accuracy: 0.7692\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 1.4708 - accuracy: 0.4375Epoch 19/10000\n",
      "207/207 [==============================] ETA: 0s - loss: 0.7051 - accuracy: 0.5625 - 0s 263us/step - loss: 0.6948 - accuracy: 0.5845 - val_loss: 0.5853 - val_accuracy: 0.7500\n",
      "Epoch 19/10000\n",
      " - ETA: 0s - loss: 0.6185 - accuracy: 0.8125207/207 [==============================] - 0s 288us/step - loss: 0.8286 - accuracy: 0.6087 - val_loss: 0.6186 - val_accuracy: 0.6538\n",
      "Epoch 20/10000176/207 [========================>.....]\n",
      " - 0s 278us/step - loss: 0.7157 - accuracy: 0.6232 - val_loss: 0.5784 - val_accuracy: 0.71150s - loss: 1.6769 - accuracy: 0.\n",
      "207/207 [==============================] - 0s 481us/step - loss: 0.7396 - accuracy: 0.5700 - val_loss: 0.5473 - val_accuracy: 0.7308\n",
      "Epoch 20/10000\n",
      "Epoch 20/10000\n",
      " - ETA: 0s - loss: 0.7582 - accuracy: 0.3750TA: 0s - loss: 0.6712 - accuracy: 0.562 16/207 [=>............................]207/207 [==============================] - 0s 303us/step - loss: 0.8111 - accuracy: 0.6522 - val_loss: 0.5899 - val_accuracy: 0.6923\n",
      "Epoch 21/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.8207/207 [==============================] - 0s 303us/step - loss: 0.7218 - accuracy: 0.5894 - val_loss: 0.5998 - val_accuracy: 0.6827\n",
      " - 0s 311us/step - loss: 0.7725 - accuracy: 0.5411 - val_loss: 0.6593 - val_accuracy: 0.6154\n",
      "Epoch 21/10000\n",
      "Epoch 21/10000\n",
      " 16/207 [=>........................... - ETA: 0s - loss: 0.9172 - accuracy: 0.3750 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6875 - 0s 302us/step - loss: 0.8340 - accuracy: 0.6618 - val_loss: 0.5952 - val_accuracy: 0.6731\n",
      "Epoch 22/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.6918 - accuracy: 0.207/207 [==============================]207/207 [==============================] - 0s 268us/step - loss: 0.6976 - accuracy: 0.5604 - val_loss: 0.6845 - val_accuracy: 0.5577\n",
      " - 0s 279us/step - loss: 0.8043 - accuracy: 0.5411 - val_loss: 0.5748 - val_accuracy: 0.7308\n",
      "Epoch 22/10000Epoch 22/10000\n",
      "\n",
      "207/207 [==============================]6250 16/207 [=>............................] - ETA: 0s - loss: 0.6434 - accuracy: 0.56 - 0s 379us/step - loss: 0.8355 - accuracy: 0.6135 - val_loss: 0.6393 - val_accuracy: 0.6154\n",
      "Epoch 23/10000\n",
      "207/207 [==============================] 16/207 [=>............................] - 0s 297us/step - loss: 0.6756 - accuracy: 0.5604 - val_loss: 0.6795 - val_accuracy: 0.5769\n",
      " - ETA: 0s - loss: 0.4837 - accuracy: 0.7500207/207 [==============================] - 0s 293us/step - loss: 0.6664 - accuracy: 0.6377 - val_loss: 0.6113 - val_accuracy: 0.7019\n",
      "Epoch 23/10000\n",
      "Epoch 23/10000 16/207 [=>............................]\n",
      " 16/207 [=>............................]6875 - ETA: 0s - loss: 0.6865 - accuracy: 0.5207/207 [==============================] - 0s 304us/step - loss: 0.7310 - accuracy: 0.6135 - val_loss: 0.6200 - val_accuracy: 0.7019\n",
      "Epoch 24/10000207/207 [==============================]176/207 [========================>.....]\n",
      " - 0s 288us/step - loss: 0.6707 - accuracy: 0.6184 - val_loss: 0.6354 - val_accuracy: 0.6827\n",
      " 16/207 [=>............................]6136Epoch 24/10000 - ETA: 0s - loss: 0.5477 - accuracy: 0.7500\n",
      "207/207 [==============================]] - ETA: 0s - loss: 0.7978 - accuracy: 0.5000 - 0s 397us/step - loss: 0.6640 - accuracy: 0.6135 - val_loss: 0.6044 - val_accuracy: 0.7019\n",
      "Epoch 24/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.6216 - accuracy: 0.68 - 0s 295us/step - loss: 0.7523 - accuracy: 0.6280 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
      "176/207 [========================>.....] - ETA: 0s - loss: 0.6766 - accuracy: 0.5966Epoch 25/10000\n",
      "207/207 [==============================] ETA: 0s - loss: 0.6861 - accuracy: 0.75 - 0s 474us/step - loss: 0.6804 - accuracy: 0.5845 - val_loss: 0.5961 - val_accuracy: 0.7212\n",
      "207/207 [==============================]Epoch 25/10000 - 0s 291us/step - loss: 0.6709 - accuracy: 0.5700 - val_loss: 0.6051 - val_accuracy: 0.7212\n",
      "\n",
      "Epoch 25/10000\n",
      "207/207 [==============================] 16/207 [=>............................] - ETA: 0s - loss: 0.8074 - accuracy: 0.6319 - ETA: 0s - loss: 0.5567 - accuracy: 0.6875 - ETA: 0s - loss: 0.4736 - accuracy: 0. - 0s 457us/step - loss: 0.7403 - accuracy: 0.6425 - val_loss: 0.5589 - val_accuracy: 0.7596\n",
      "Epoch 26/10000 - ETA: 0s - loss: 0.7040 - accuracy: 0.5833192/207 [==========================>...]\n",
      "207/207 [==============================]6458 - ETA: 0s - loss: 0.6431 - accuracy: 0. - 0s 393us/step - loss: 0.7006 - accuracy: 0.5845 - val_loss: 0.6038 - val_accuracy: 0.7308\n",
      "207/207 [==============================]Epoch 26/10000 - 0s 420us/step - loss: 0.6483 - accuracy: 0.6329 - val_loss: 0.5380 - val_accuracy: 0.7404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/10000\n",
      "207/207 [==============================]68756/207 [=>............................]192/207 [==========================>...] - ETA: 0s - loss: 0.6732 - accuracy: 0.63 - 0s 448us/step - loss: 0.6657 - accuracy: 0.6473 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
      "207/207 [==============================]\n",
      " - 0s 324us/step - loss: 0.6265 - accuracy: 0.6329 - val_loss: 0.6365 - val_accuracy: 0.6635\n",
      "207/207 [==============================] - 0s 302us/step - loss: 0.7343 - accuracy: 0.6329 - val_loss: 0.5704 - val_accuracy: 0.7212\n",
      " 16/207 [=>............................]Epoch 27/10000 - ETA: 0s - loss: 0.7250 - accuracy: 0.6250\n",
      "Epoch 27/10000\n",
      "192/207 [==========================>...] 16/207 [=>............................] - ETA: 0s - loss: 0.6451 - accuracy: 0.6250 - ETA: 0s - loss: 0.6101 - accuracy: 0. - ETA: 0s - loss: 0.6579 - accuracy: 0.6094207/207 [==============================] - 0s 296us/step - loss: 0.7764 - accuracy: 0.6329 - val_loss: 0.5936 - val_accuracy: 0.7115\n",
      "Epoch 28/10000207/207 [==============================]\n",
      " - 0s 298us/step - loss: 0.9415 - accuracy: 0.5797 - val_loss: 0.5466 - val_accuracy: 0.7308\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.6250 - 0s 377us/step - loss: 0.6568 - accuracy: 0.6087 - val_loss: 0.5796 - val_accuracy: 0.7308\n",
      "Epoch 28/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.56 - 0s 284us/step - loss: 0.7727 - accuracy: 0.5797 - val_loss: 0.6684 - val_accuracy: 0.6058\n",
      "Epoch 29/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.68 - 0s 293us/step - loss: 0.6906 - accuracy: 0.5797 - val_loss: 0.5802 - val_accuracy: 0.7404\n",
      "Epoch 29/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0. - 0s 327us/step - loss: 0.7007 - accuracy: 0.6329 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "160/207 [======================>.......]Epoch 30/10000 - ETA: 0s - loss: 0.7843 - accuracy: 0.5813\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.62 - 0s 439us/step - loss: 0.7649 - accuracy: 0.5894 - val_loss: 0.6502 - val_accuracy: 0.6250\n",
      "Epoch 30/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7380 - accuracy: 0.56 - 0s 247us/step - loss: 0.6730 - accuracy: 0.6087 - val_loss: 0.5219 - val_accuracy: 0.7404\n",
      "Epoch 31/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.56 - 0s 298us/step - loss: 0.7151 - accuracy: 0.5749 - val_loss: 0.6097 - val_accuracy: 0.7019\n",
      "Epoch 31/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - 0s 302us/step - loss: 0.8416 - accuracy: 0.6184 - val_loss: 0.5224 - val_accuracy: 0.7404\n",
      "207/207 [==============================] - 0s 309us/step - loss: 0.7038 - accuracy: 0.5894 - val_loss: 0.6265 - val_accuracy: 0.6827\n",
      "Epoch 32/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.56 - 0s 326us/step - loss: 0.7000 - accuracy: 0.5894 - val_loss: 0.5568 - val_accuracy: 0.7308\n",
      "Epoch 33/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.81 - 0s 268us/step - loss: 0.7530 - accuracy: 0.5845 - val_loss: 0.5672 - val_accuracy: 0.7212\n",
      "Epoch 34/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.56 - 0s 292us/step - loss: 0.6919 - accuracy: 0.6184 - val_loss: 0.6346 - val_accuracy: 0.6731\n",
      "Epoch 35/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.62 - 0s 320us/step - loss: 0.6854 - accuracy: 0.5749 - val_loss: 0.6006 - val_accuracy: 0.7212\n",
      "Epoch 36/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.75 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - 0s 428us/step - loss: 0.6750 - accuracy: 0.5797 - val_loss: 0.5661 - val_accuracy: 0.7404\n",
      "Epoch 37/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.68 - 0s 287us/step - loss: 0.6903 - accuracy: 0.6184 - val_loss: 0.5787 - val_accuracy: 0.7212\n",
      "Epoch 38/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.56 - 0s 310us/step - loss: 0.6936 - accuracy: 0.6039 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Train on 207 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "Train on 207 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "Train on 207 samples, validate on 104 samples\n",
      "Epoch 1/10000\n",
      "207/207 [==============================] - ETA: 6s - loss: 1.3887 - accuracy: 0.43 - 1s 3ms/step - loss: 1.3166 - accuracy: 0.5749 - val_loss: 0.6740 - val_accuracy: 0.5962\n",
      "Epoch 2/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.2021 - accuracy: 0.25 - 0s 197us/step - loss: 0.9337 - accuracy: 0.5700 - val_loss: 0.6417 - val_accuracy: 0.6635\n",
      "Epoch 3/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7828 - accuracy: 0.6250 - ETA: 6s - loss: 1.2850 - accuracy: 0.56 - 0s 261us/step - loss: 0.7131 - accuracy: 0.5942 - val_loss: 0.5789 - val_accuracy: 0.7115\n",
      "Epoch 4/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.75 - 0s 226us/step - loss: 0.6707 - accuracy: 0.6860 - val_loss: 0.5765 - val_accuracy: 0.7212\n",
      "Epoch 5/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.8826 - accuracy: 0.37 - 0s 215us/step - loss: 0.8557 - accuracy: 0.6570 - val_loss: 0.6795 - val_accuracy: 0.5769\n",
      "Epoch 6/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.3828 - accuracy: 0.5000 - ETA: 6s - loss: 1.5878 - accuracy: 0.43 - 1s 4ms/step - loss: 1.4512 - accuracy: 0.5604 - val_loss: 0.5749 - val_accuracy: 0.6635\n",
      "207/207 [==============================] - 0s 304us/step - loss: 0.7261 - accuracy: 0.6232 - val_loss: 0.5908 - val_accuracy: 0.6923\n",
      "Epoch 7/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.1751 - accuracy: 0.56 - 0s 214us/step - loss: 0.7259 - accuracy: 0.6618 - val_loss: 0.6148 - val_accuracy: 0.6538\n",
      "Epoch 8/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.5501 - accuracy: 0.6875Epoch 2/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.1465 - accuracy: 0.68 - 0s 266us/step - loss: 0.7600 - accuracy: 0.6039 - val_loss: 0.6078 - val_accuracy: 0.7019\n",
      "Epoch 9/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.9418 - accuracy: 0.5000 - 0s 293us/step - loss: 0.9968 - accuracy: 0.5797 - val_loss: 0.6385 - val_accuracy: 0.6827\n",
      "Epoch 3/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 1.2459 - accuracy: 0.4375 - 1s 4ms/step - loss: 1.2790 - accuracy: 0.5845 - val_loss: 0.6053 - val_accuracy: 0.6827\n",
      "207/207 [==============================] - 0s 310us/step - loss: 0.7257 - accuracy: 0.5990 - val_loss: 0.6561 - val_accuracy: 0.6250\n",
      "Epoch 10/10000Epoch 2/100\n",
      "\n",
      " - 0s 298us/step - loss: 0.7874 - accuracy: 0.5894 - val_loss: 0.5529 - val_accuracy: 0.7212\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.6148 - accuracy: 0.6250 16/207 [=>............................] - ETA: 0s - loss: 1.0941 - accuracy: 0.5000Epoch 4/10000\n",
      "176/207 [========================>.....] - ETA: 0s - loss: 0.7699 - accuracy: 0.192/207 [==========================>...]176/207 [========================>.....] - ETA: 0s - loss: 0.7510 - accuracy: 0.6094 - ETA: 0s - loss: 1.1992 - accuracy: 0.56 - ETA: 0s - loss: 0.7913 - accuracy: 0.207/207 [==============================]207/207 [==============================] - 0s 421us/step - loss: 0.7451 - accuracy: 0.6087 - val_loss: 0.6334 - val_accuracy: 0.6635\n",
      " - 0s 426us/step - loss: 1.1611 - accuracy: 0.5700 - val_loss: 0.6730 - val_accuracy: 0.5769\n",
      "Epoch 11/10000\n",
      "Epoch 3/100\n",
      " - ETA: 0s - loss: 0.6065 - accuracy: 0.6875207 [=>............................] - 0s 472us/step - loss: 0.7684 - accuracy: 0.6329 - val_loss: 0.5707 - val_accuracy: 0.7308\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7858 - accuracy: 0.3750Epoch 5/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0. - ETA: 0s - loss: 0.9516 - accuracy: 0.5625 - 0s 324us/step - loss: 0.7702 - accuracy: 0.5990 - val_loss: 0.6177 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.556 16/207 [=>............................] - ETA: 0s - loss: 0.7833 - accuracy: 0.4375 - 0s 421us/step - loss: 0.9461 - accuracy: 0.5604 - val_loss: 0.6034 - val_accuracy: 0.6827\n",
      "Epoch 4/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.6875 - 0s 468us/step - loss: 0.7798 - accuracy: 0.5556 - val_loss: 0.5790 - val_accuracy: 0.7404\n",
      "Epoch 6/10000\n",
      " - ETA: 0s - loss: 0.4988 - accuracy: 0.7500207/207 [==============================] - 0s 303us/step - loss: 0.6726 - accuracy: 0.6039 - val_loss: 0.5668 - val_accuracy: 0.7308\n",
      "Epoch 13/10000\n",
      " - ETA: 0s - loss: 1.4797 - accuracy: 0.5000207/207 [==============================] - 0s 323us/step - loss: 0.8098 - accuracy: 0.5894 - val_loss: 0.6044 - val_accuracy: 0.7019\n",
      "Epoch 5/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - 0s 334us/step - loss: 0.6939 - accuracy: 0.6473 - val_loss: 0.5952 - val_accuracy: 0.7115\n",
      " - ETA: 0s - loss: 0.8737 - accuracy: 0.4375Epoch 7/10000\n",
      " - ETA: 0s - loss: 0.6732 - accuracy: 0.5000207/207 [==============================] - 0s 327us/step - loss: 0.7703 - accuracy: 0.5797 - val_loss: 0.6359 - val_accuracy: 0.6827\n",
      "Epoch 14/100\n",
      "207/207 [==============================] 16/207 [=>............................] - 0s 270us/step - loss: 0.6834 - accuracy: 0.6425 - val_loss: 0.5780 - val_accuracy: 0.7115\n",
      " - ETA: 0s - loss: 0.6453 - accuracy: 0.6875Epoch 6/10000\n",
      " - ETA: 0s - loss: 0.6251 - accuracy: 0.6875207/207 [==============================] - 0s 259us/step - loss: 0.6806 - accuracy: 0.6425 - val_loss: 0.5524 - val_accuracy: 0.7115\n",
      "Epoch 8/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.68 - 0s 306us/step - loss: 0.6788 - accuracy: 0.6473 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
      "Epoch 15/10000\n",
      " - 0s 317us/step - loss: 0.8278 - accuracy: 0.6473 - val_loss: 0.6028 - val_accuracy: 0.6827\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.5860 - accuracy: 0.7500Epoch 7/100\n",
      "207/207 [==============================] 16/207 [=>............................] - 0s 274us/step - loss: 0.6775 - accuracy: 0.6522 - val_loss: 0.5493 - val_accuracy: 0.7308\n",
      " - ETA: 0s - loss: 0.5061 - accuracy: 0.8125Epoch 9/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.87 - 0s 307us/step - loss: 0.7416 - accuracy: 0.6667 - val_loss: 0.5624 - val_accuracy: 0.7212\n",
      "Epoch 16/10000\n",
      " - 0s 322us/step - loss: 0.6939 - accuracy: 0.6667 - val_loss: 0.5905 - val_accuracy: 0.7115\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7398 - accuracy: 0.5000Epoch 8/100\n",
      " - 0s 301us/step - loss: 0.8630 - accuracy: 0.6667 - val_loss: 0.5333 - val_accuracy: 0.7308\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 1.0010 - accuracy: 0.5625Epoch 10/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7908 - accuracy: 0.75 - 0s 329us/step - loss: 0.8491 - accuracy: 0.6184 - val_loss: 0.6257 - val_accuracy: 0.6731\n",
      "Epoch 17/10000207/207 [==============================]160/207 [======================>.......]\n",
      " - 0s 348us/step - loss: 0.7207 - accuracy: 0.5894 - val_loss: 0.6426 - val_accuracy: 0.6250\n",
      "Epoch 9/10000 16/207 [=>............................] - ETA: 0s - loss: 0.7273 - accuracy: 0.4375\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.56 - 0s 425us/step - loss: 0.7413 - accuracy: 0.6280 - val_loss: 0.5458 - val_accuracy: 0.7115\n",
      "Epoch 11/10000\n",
      "207/207 [==============================]6875160/207 [======================>...... - ETA: 0s - loss: 0.7047 - accuracy: 0.5938 - 0s 332us/step - loss: 0.7012 - accuracy: 0.5749 - val_loss: 0.6611 - val_accuracy: 0.6154\n",
      "Epoch 18/10000\n",
      " - 0s 465us/step - loss: 0.6852 - accuracy: 0.6135 - val_loss: 0.5648 - val_accuracy: 0.7115oss: 0.8006 - accuracy: 0.5625\n",
      "207/207 [==============================] - 0s 262us/step - loss: 0.6586 - accuracy: 0.6184 - val_loss: 0.5752 - val_accuracy: 0.7308\n",
      "Epoch 10/10000Epoch 12/10000\n",
      "\n",
      " - ETA: 0s - loss: 0.5849 - accuracy: 0.6875 16/207 [=>............................] - ETA: 0s - loss: 0.5805 - accuracy: 0. 96/207 [============>.................]207/207 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.6354 - 0s 347us/step - loss: 0.7343 - accuracy: 0.5894 - val_loss: 0.5951 - val_accuracy: 0.7019\n",
      "Epoch 19/10000207/207 [==============================]\n",
      " - 0s 327us/step - loss: 0.6500 - accuracy: 0.6618 - val_loss: 0.5699 - val_accuracy: 0.7115\n",
      "Epoch 11/10000 16/207 [=>............................] - ETA: 0s - loss: 0.5977 - accuracy: 0.6250\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7771 - accuracy: 0.56 - 0s 509us/step - loss: 0.6337 - accuracy: 0.6329 - val_loss: 0.5589 - val_accuracy: 0.7308\n",
      "Epoch 13/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7105 - accuracy: 0.144/207 [===================>..........]207/207 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.6528 - 0s 347us/step - loss: 0.7185 - accuracy: 0.6039 - val_loss: 0.6578 - val_accuracy: 0.6154\n",
      "Epoch 20/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.68 - 0s 465us/step - loss: 0.6708 - accuracy: 0.6570 - val_loss: 0.5773 - val_accuracy: 0.7115\n",
      "Epoch 12/100\n",
      " 16/207 [=>............................] - 0s 373us/step - loss: 0.6603 - accuracy: 0.6135 - val_loss: 0.5523 - val_accuracy: 0.7115\n",
      " - ETA: 0s - loss: 0.6363 - accuracy: 0.6250Epoch 14/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8125 - 0s 329us/step - loss: 0.6713 - accuracy: 0.5749 - val_loss: 0.6551 - val_accuracy: 0.6250\n",
      "Epoch 21/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.62 - 0s 342us/step - loss: 0.7014 - accuracy: 0.6184 - val_loss: 0.6162 - val_accuracy: 0.6635\n",
      "Epoch 13/10000\n",
      "207/207 [============================= - 0s 337us/step - loss: 0.8085 - accuracy: 0.5990 - val_loss: 0.6678 - val_accuracy: 0.6058\n",
      " 16/207 [=>............................]160/207 [======================>.......]Epoch 15/10000 - ETA: 0s - loss: 0.7368 - accuracy: 0.5625 - ETA: 0s - loss: 0.6869 - accuracy: 0.5625\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.56 - 0s 444us/step - loss: 0.6699 - accuracy: 0.5894 - val_loss: 0.6327 - val_accuracy: 0.6731\n",
      "192/207 [==========================>...]\n",
      "207/207 [==============================]59 16/207 [=>............................]176/207 [========================>.....] - ETA: 0s - loss: 0.6036 - accuracy: 0.7500 - ETA: 0s - loss: 0.7092 - accuracy: 0.66 - 0s 423us/step - loss: 0.7777 - accuracy: 0.5990 - val_loss: 0.5783 - val_accuracy: 0.6827\n",
      "Epoch 14/10000207/207 [==============================]\n",
      " - 0s 470us/step - loss: 0.7108 - accuracy: 0.6570 - val_loss: 0.5825 - val_accuracy: 0.7212\n",
      " 16/207 [=>............................]Epoch 16/10000 - ETA: 0s - loss: 0.5890 - accuracy: 0.6250\n",
      "207/207 [==============================] 16/207 [=>............................] - ETA: 0s - loss: 0.8583 - accuracy: 0.6875 - 0s 324us/step - loss: 0.9485 - accuracy: 0.5797 - val_loss: 0.6050 - val_accuracy: 0.7019\n",
      "Epoch 23/10000\n",
      " - 0s 322us/step - loss: 0.9182 - accuracy: 0.6135 - val_loss: 0.5865 - val_accuracy: 0.7404\n",
      "192/207 [==========================>...] - ETA: 0s - loss: 0.8450 - accuracy: 0.5833Epoch 15/10000\n",
      "207/207 [==============================] - 0s 407us/step - loss: 0.8209 - accuracy: 0.6039 - val_loss: 0.6261 - val_accuracy: 0.6827\n",
      " - 0s 331us/step - loss: 0.7136 - accuracy: 0.5700 - val_loss: 0.6579 - val_accuracy: 0.6538\n",
      "Epoch 17/10000Epoch 24/10000\n",
      "\n",
      "207/207 [==============================] 16/207 [=>............................] - ETA: 0s - loss: 0.6407 - accuracy: 0.6875 - ETA: 0s - loss: 0.6534 - accuracy: 0.68 - 0s 306us/step - loss: 0.9868 - accuracy: 0.6087 - val_loss: 0.6064 - val_accuracy: 0.6923\n",
      "Epoch 16/100\n",
      " - 0s 298us/step - loss: 0.6755 - accuracy: 0.6280 - val_loss: 0.5763 - val_accuracy: 0.7212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.7500 - 0s 299us/step - loss: 0.7473 - accuracy: 0.5990 - val_loss: 0.6061 - val_accuracy: 0.7019\n",
      "Epoch 18/10000\n",
      "Epoch 25/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 1.0585 - accuracy: 0.6875 - ETA: 0s - loss: 0.6856 - accuracy: 0.56 - 0s 258us/step - loss: 0.7209 - accuracy: 0.6522 - val_loss: 0.6057 - val_accuracy: 0.7019\n",
      "Epoch 17/10000\n",
      " - 0s 287us/step - loss: 0.7599 - accuracy: 0.6280 - val_loss: 0.5647 - val_accuracy: 0.6923\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.9055 - accuracy: 0.5909Epoch 19/10000 - ETA: 0s - loss: 0.5993 - accuracy: 0.7500\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5793 - accuracy: 0.68 - 0s 432us/step - loss: 0.9641 - accuracy: 0.5894 - val_loss: 0.5739 - val_accuracy: 0.7115\n",
      "Epoch 26/1000\n",
      " - 0s 319us/step - loss: 0.6360 - accuracy: 0.6473 - val_loss: 0.5614 - val_accuracy: 0.7212\n",
      " - 0s 309us/step - loss: 0.7422 - accuracy: 0.6522 - val_loss: 0.5668 - val_accuracy: 0.7115\n",
      " 16/207 [=>............................]Epoch 18/10000 - ETA: 0s - loss: 0.5954 - accuracy: 0.6875\n",
      "Epoch 20/10000\n",
      " - ETA: 0s - loss: 0.6336 - accuracy: 0.6875 16/207 [=>............................] - ETA: 0s - loss: 0.6694 - accuracy: 0.4112/207 [===============>..............] - ETA: 0s - loss: 0.7197 - accuracy: 0.6964144/207 [===================>..........]207/207 [==============================] - ETA: 0s - loss: 0.8365 - accuracy: 0.5625 - 0s 338us/step - loss: 0.7076 - accuracy: 0.6039 - val_loss: 0.5954 - val_accuracy: 0.7115\n",
      "Epoch 27/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0. - 0s 443us/step - loss: 0.7790 - accuracy: 0.5894 - val_loss: 0.5785 - val_accuracy: 0.7115\n",
      " - 0s 487us/step - loss: 0.7296 - accuracy: 0.6667 - val_loss: 0.5519 - val_accuracy: 0.7308\n",
      "Epoch 21/10000\n",
      "Epoch 19/10000\n",
      "207/207 [==============================]6875 16/207 [=>............................] - ETA: 0s - loss: 0.7646 - accuracy: 0.56 - 0s 408us/step - loss: 0.7214 - accuracy: 0.6039 - val_loss: 0.6264 - val_accuracy: 0.6923\n",
      "176/207 [========================>.....]Epoch 28/100 - ETA: 0s - loss: 0.6402 - accuracy: 0.6705\n",
      "207/207 [==============================] - 0s 311us/step - loss: 0.8166 - accuracy: 0.6377 - val_loss: 0.6214 - val_accuracy: 0.6827\n",
      " 16/207 [=>............................]Epoch 22/10000 - ETA: 0s - loss: 0.5501 - accuracy: 0.7500\n",
      "207/207 [==============================] ETA: 0s - loss: 0.6175 - accuracy: 0.6250 - 0s 436us/step - loss: 0.6371 - accuracy: 0.6715 - val_loss: 0.6082 - val_accuracy: 0.6923\n",
      "Epoch 20/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.6250 - 0s 304us/step - loss: 0.6943 - accuracy: 0.6377 - val_loss: 0.5595 - val_accuracy: 0.7212\n",
      "Epoch 29/10000\n",
      "207/207 [==============================] 16/207 [=>............................] - 0s 321us/step - loss: 0.7022 - accuracy: 0.6329 - val_loss: 0.5633 - val_accuracy: 0.7308\n",
      " - ETA: 0s - loss: 0.6348 - accuracy: 0.6875Epoch 23/10000\n",
      " - 0s 358us/step - loss: 0.6238 - accuracy: 0.6957 - val_loss: 0.5771 - val_accuracy: 0.7115\n",
      "207/207 [==============================] - 0s 276us/step - loss: 0.7700 - accuracy: 0.6280 - val_loss: 0.5417 - val_accuracy: 0.7404\n",
      "Epoch 21/10000\n",
      "Epoch 30/10000\n",
      "207/207 [==============================]7500192/207 [==========================>...] - ETA: 0s - loss: 0.5207 - accuracy: 0.7500 - ETA: 0s - loss: 0.9654 - accuracy: 0. - 0s 475us/step - loss: 0.9423 - accuracy: 0.5942 - val_loss: 0.7351 - val_accuracy: 0.5385\n",
      "207/207 [==============================]207/207 [==============================] - 0s 283us/step - loss: 0.8222 - accuracy: 0.5990 - val_loss: 0.5422 - val_accuracy: 0.7019\n",
      "Epoch 24/10000 - 0s 312us/step - loss: 0.6636 - accuracy: 0.5894 - val_loss: 0.5906 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 22/10000\n",
      " 16/207 [=>............................]\n",
      "192/207 [==========================>...]5000 16/207 [=>............................] 16/207 [=>............................] - ETA: 0s - loss: 0.6943 - accuracy: 0.6875 - ETA: 0s - loss: 0.6904 - accuracy: 0. - ETA: 0s - loss: 0.7011 - accuracy: 0.6042207/207 [==============================]207/207 [==============================] - 0s 329us/step - loss: 0.8867 - accuracy: 0.5845 - val_loss: 0.5595 - val_accuracy: 0.7212\n",
      " - 0s 353us/step - loss: 0.7599 - accuracy: 0.6280 - val_loss: 0.5748 - val_accuracy: 0.7115\n",
      "Epoch 25/10000Epoch 32/10000\n",
      "\n",
      "207/207 [==============================] 16/207 [=>............................] 16/207 [=>............................] - 0s 422us/step - loss: 0.6899 - accuracy: 0.6135 - val_loss: 0.6072 - val_accuracy: 0.6827\n",
      " - ETA: 0s - loss: 0.7653 - accuracy: 0.6250 - ETA: 0s - loss: 0.6878 - accuracy: 0.5625Epoch 23/10000\n",
      "192/207 [==========================>...] - ETA: 0s - loss: 0.6396 - accuracy: 0.6 - ETA: 0s - loss: 0.8565 - accuracy: 0.5781207/207 [==============================] - 0s 281us/step - loss: 0.8078 - accuracy: 0.6135 - val_loss: 0.5709 - val_accuracy: 0.7115\n",
      "Epoch 26/10000\n",
      " 16/207 [=>............................] - 0s 406us/step - loss: 0.8553 - accuracy: 0.5845 - val_loss: 0.5675 - val_accuracy: 0.7404\n",
      "160/207 [======================>.......] - ETA: 0s - loss: 0.6883 - accuracy: 0.5000 - ETA: 0s - loss: 0.6548 - accuracy: 0.6250Epoch 33/10000\n",
      "207/207 [==============================] ETA: 0s - loss: 1.5120 - accuracy: 0.5000 - 0s 426us/step - loss: 0.6676 - accuracy: 0.6039 - val_loss: 0.5803 - val_accuracy: 0.7212\n",
      "Epoch 24/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.4375 - 0s 272us/step - loss: 0.6820 - accuracy: 0.5942 - val_loss: 0.6722 - val_accuracy: 0.5962\n",
      "Epoch 27/10000\n",
      "207/207 [==============================]] - ETA: 0s - loss: 0.7010 - accuracy: 0.6250 - 0s 323us/step - loss: 0.7846 - accuracy: 0.5797 - val_loss: 0.6438 - val_accuracy: 0.6154\n",
      "Epoch 34/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7027 - accuracy: 0.5000207/207 [==============================] - 0s 319us/step - loss: 0.7059 - accuracy: 0.6618 - val_loss: 0.5772 - val_accuracy: 0.7308\n",
      "Epoch 25/10000\n",
      " 16/207 [=>............................]207/207 [==============================] - 0s 316us/step - loss: 0.7114 - accuracy: 0.6135 - val_loss: 0.5896 - val_accuracy: 0.6827\n",
      " - ETA: 0s - loss: 0.4981 - accuracy: 0.8125Epoch 28/10000\n",
      "207/207 [==============================]192/207 [==========================>...] - ETA: 0s - loss: 0.4921 - accuracy: 0.8125 - ETA: 0s - loss: 0.7862 - accuracy: 0. - 0s 341us/step - loss: 0.7774 - accuracy: 0.6377 - val_loss: 0.5805 - val_accuracy: 0.7115\n",
      "207/207 [==============================]Epoch 26/10000192/207 [==========================>...] - 0s 517us/step - loss: 0.7809 - accuracy: 0.5700 - val_loss: 0.6716 - val_accuracy: 0.5962\n",
      " - ETA: 0s - loss: 0.6791 - accuracy: 0.6667\n",
      "Epoch 35/10000\n",
      "207/207 [==============================] 16/207 [=>............................] - ETA: 0s - loss: 0.6719 - accuracy: 0.5625 - ETA: 0s - loss: 0.6387 - accuracy: 0.62 - 0s 371us/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.5851 - val_accuracy: 0.6827\n",
      "Epoch 29/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.50 - ETA: 0s - loss: 0.7137 - accuracy: 0.54 - 0s 352us/step - loss: 0.7064 - accuracy: 0.5700 - val_loss: 0.6786 - val_accuracy: 0.5865\n",
      "Epoch 36/10000==================>.......] - ETA: 0s - loss: 0.6815 - accuracy: 0.6187\n",
      "207/207 [==============================] - 0s 473us/step - loss: 0.7077 - accuracy: 0.5556 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
      " 16/207 [=>............................]Epoch 27/10000 - ETA: 0s - loss: 0.5776 - accuracy: 0.6875\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7844 - accuracy: 0.50 - 0s 463us/step - loss: 0.6538 - accuracy: 0.6377 - val_loss: 0.5864 - val_accuracy: 0.6923\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.63 - ETA: 0s - loss: 0.6471 - accuracy: 0.62 - 0s 459us/step - loss: 0.6588 - accuracy: 0.6232 - val_loss: 0.5956 - val_accuracy: 0.6635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/10000207/207 [==============================]\n",
      " - 0s 475us/step - loss: 0.6628 - accuracy: 0.5942 - val_loss: 0.5603 - val_accuracy: 0.7308\n",
      "Epoch 28/10000 16/207 [=>............................]\n",
      "207/207 [==============================]6250 - ETA: 0s - loss: 0.7135 - accuracy: 0. - 0s 313us/step - loss: 0.7310 - accuracy: 0.5845 - val_loss: 0.7029 - val_accuracy: 0.5865\n",
      "207/207 [==============================] - 0s 302us/step - loss: 0.6827 - accuracy: 0.6135 - val_loss: 0.6415 - val_accuracy: 0.6538\n",
      "Epoch 38/10000\n",
      "Epoch 29/10000\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.7873 - accuracy: 0.5000 - ETA: 0s - loss: 0.6214 - accuracy: 0.207/207 [==============================]207/207 [==============================] - 0s 331us/step - loss: 0.6841 - accuracy: 0.6280 - val_loss: 0.5635 - val_accuracy: 0.7308\n",
      " - 0s 328us/step - loss: 0.7369 - accuracy: 0.6087 - val_loss: 0.5748 - val_accuracy: 0.7115\n",
      "Epoch 39/10000Epoch 30/10000\n",
      "\n",
      " - 0s 276us/step - loss: 0.6678 - accuracy: 0.6184 - val_loss: 0.5822 - val_accuracy: 0.6731 loss: 0.8298 - accuracy: 0.3750 - ETA: 0s - loss: 0.7803 - accuracy: 0.4207/207 [==============================]\n",
      "207/207 [==============================] - 0s 270us/step - loss: 0.7406 - accuracy: 0.6135 - val_loss: 0.5796 - val_accuracy: 0.7115\n",
      "Epoch 40/10000Epoch 31/10000\n",
      "\n",
      "207/207 [==============================] 16/207 [=>............................] - ETA: 0s - loss: 0.4891 - accuracy: 0.8125 - ETA: 0s - loss: 1.7129 - accuracy: 0.5207/207 [==============================] - 0s 310us/step - loss: 0.6826 - accuracy: 0.5797 - val_loss: 0.6424 - val_accuracy: 0.6250\n",
      " - 0s 309us/step - loss: 0.8430 - accuracy: 0.5459 - val_loss: 0.6506 - val_accuracy: 0.6346\n",
      "Epoch 41/10000Epoch 32/10000\n",
      "\n",
      " 16/207 [=>............................] 16/207 [=>............................] - ETA: 0s - loss: 0.6848 - accuracy: 0.5000 - ETA: 0s - loss: 0.7017 - accuracy: 0.4207/207 [==============================] - 0s 301us/step - loss: 0.6777 - accuracy: 0.5894 - val_loss: 0.6473 - val_accuracy: 0.6154\n",
      "207/207 [==============================] - 0s 331us/step - loss: 0.7618 - accuracy: 0.5990 - val_loss: 0.6030 - val_accuracy: 0.6731\n",
      "Epoch 42/10000\n",
      "Epoch 33/10000\n",
      " - 0s 536us/step - loss: 0.6853 - accuracy: 0.5845 - val_loss: 0.6816 - val_accuracy: 0.55770s - loss: 0.5247 - accuracy: 0. - ETA: 0s - loss: 0.6998 - accuracy: 0.5682 - ETA: 0s - loss: 0.7357 - accuracy: 0.6207/207 [==============================]\n",
      "207/207 [==============================] - 0s 509us/step - loss: 0.7339 - accuracy: 0.6377 - val_loss: 0.6013 - val_accuracy: 0.6731\n",
      "Epoch 43/10000\n",
      "Epoch 34/10000\n",
      "207/207 [==============================]6875 16/207 [=>............................] - ETA: 0s - loss: 0.6127 - accuracy: 0.62 - ETA: 0s - loss: 0.6864 - accuracy: 0.56 - 0s 337us/step - loss: 0.6896 - accuracy: 0.5797 - val_loss: 0.6291 - val_accuracy: 0.6346\n",
      "Epoch 35/10000207/207 [==============================]\n",
      " - 0s 446us/step - loss: 0.6856 - accuracy: 0.5700 - val_loss: 0.6854 - val_accuracy: 0.5481\n",
      "Epoch 44/10000 16/207 [=>............................] - ETA: 0s - loss: 1.3063 - accuracy: 0.5000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.62 - 0s 323us/step - loss: 0.8388 - accuracy: 0.5314 - val_loss: 0.6904 - val_accuracy: 0.5385\n",
      "Epoch 36/10000207/207 [==============================]\n",
      " - 0s 334us/step - loss: 0.6808 - accuracy: 0.5700 - val_loss: 0.6855 - val_accuracy: 0.5481\n",
      " 16/207 [=>............................]Epoch 45/10000 - ETA: 0s - loss: 0.6606 - accuracy: 0.6875\n",
      " 16/207 [=>............................] - ETA: 0s - loss: 0.6984 - accuracy: 0.5207/207 [==============================] - 0s 330us/step - loss: 0.6889 - accuracy: 0.5556 - val_loss: 0.6906 - val_accuracy: 0.5385\n",
      "207/207 [==============================] - 0s 318us/step - loss: 0.6834 - accuracy: 0.5507 - val_loss: 0.6885 - val_accuracy: 0.5481\n",
      "Epoch 37/10000\n",
      "Epoch 46/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.37 - 0s 255us/step - loss: 0.6834 - accuracy: 0.5556 - val_loss: 0.6903 - val_accuracy: 0.5385\n",
      "Epoch 38/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.50 - 0s 248us/step - loss: 0.6750 - accuracy: 0.5604 - val_loss: 0.6903 - val_accuracy: 0.5385\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.50 - 0s 282us/step - loss: 0.6781 - accuracy: 0.5604 - val_loss: 0.6894 - val_accuracy: 0.5481\n",
      "Epoch 47/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.62 - 0s 340us/step - loss: 0.7013 - accuracy: 0.5604 - val_loss: 0.6835 - val_accuracy: 0.5673\n",
      "Epoch 48/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.50 - 0s 316us/step - loss: 0.6754 - accuracy: 0.5652 - val_loss: 0.6886 - val_accuracy: 0.5481\n",
      "Epoch 49/10000\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.68 - 0s 336us/step - loss: 0.6634 - accuracy: 0.5797 - val_loss: 0.6910 - val_accuracy: 0.5385\n",
      "Train on 208 samples, validate on 103 samples\n",
      "Epoch 1/10000\n",
      " 16/208 [=>............................] - ETA: 4s - loss: 1.0070 - accuracy: 0.4375Train on 208 samples, validate on 103 samples\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 1.4981 - accuracy: 0.4423 - val_loss: 0.6537 - val_accuracy: 0.6214\n",
      "Epoch 2/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8769 - accuracy: 0.68 - 0s 200us/step - loss: 0.9335 - accuracy: 0.5240 - val_loss: 0.6129 - val_accuracy: 0.6990\n",
      "Epoch 3/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.8490 - accuracy: 0.4375Epoch 1/10000\n",
      "208/208 [==============================] - 0s 237us/step - loss: 0.8070 - accuracy: 0.5481 - val_loss: 0.5957 - val_accuracy: 0.7476\n",
      "Epoch 4/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6411 - accuracy: 0.6250Train on 208 samples, validate on 103 samples\n",
      "208/208 [==============================] - 0s 268us/step - loss: 0.7855 - accuracy: 0.5673 - val_loss: 0.5462 - val_accuracy: 0.8058\n",
      "Epoch 5/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0765 - accuracy: 0.56 - 0s 223us/step - loss: 0.7240 - accuracy: 0.5913 - val_loss: 0.5179 - val_accuracy: 0.8058\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.75 - 0s 223us/step - loss: 0.6988 - accuracy: 0.6106 - val_loss: 0.4875 - val_accuracy: 0.8252\n",
      "Epoch 7/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.43 - 0s 217us/step - loss: 0.7493 - accuracy: 0.6202 - val_loss: 0.4443 - val_accuracy: 0.8350\n",
      "Epoch 8/10000\n",
      "Epoch 1/10000 16/208 [=>............................]\n",
      "208/208 [==============================]43 - 0s 226us/step - loss: 0.8531 - accuracy: 0.6202 - val_loss: 0.6987 - val_accuracy: 0.5534\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7274 - accuracy: 0.56 - 0s 223us/step - loss: 0.8679 - accuracy: 0.5577 - val_loss: 0.4618 - val_accuracy: 0.8447\n",
      "Epoch 10/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.62 - 0s 224us/step - loss: 0.8037 - accuracy: 0.5865 - val_loss: 0.5233 - val_accuracy: 0.8058\n",
      "Epoch 11/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.75 - 0s 222us/step - loss: 0.7636 - accuracy: 0.6250 - val_loss: 0.5608 - val_accuracy: 0.7864\n",
      "Epoch 12/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.75 - 0s 222us/step - loss: 0.8903 - accuracy: 0.5865 - val_loss: 0.6538 - val_accuracy: 0.6214\n",
      "Epoch 13/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7049 - accuracy: 0.37 - 0s 225us/step - loss: 0.6941 - accuracy: 0.5721 - val_loss: 0.5860 - val_accuracy: 0.8155\n",
      "Epoch 14/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.37 - 0s 224us/step - loss: 0.7491 - accuracy: 0.5913 - val_loss: 0.6056 - val_accuracy: 0.7573\n",
      "Epoch 15/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.5000 - ETA: 7s - loss: 1.3144 - accuracy: 0.50 - 0s 274us/step - loss: 0.7483 - accuracy: 0.5721 - val_loss: 0.5833 - val_accuracy: 0.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.56 - 0s 207us/step - loss: 0.7322 - accuracy: 0.5721 - val_loss: 0.5728 - val_accuracy: 0.8155\n",
      "Epoch 17/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.62 - 0s 217us/step - loss: 0.6868 - accuracy: 0.5817 - val_loss: 0.6768 - val_accuracy: 0.5728\n",
      "Epoch 18/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7399 - accuracy: 0.56 - 0s 218us/step - loss: 0.7035 - accuracy: 0.5385 - val_loss: 0.6251 - val_accuracy: 0.7573\n",
      "Epoch 19/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.50 - 1s 4ms/step - loss: 1.3709 - accuracy: 0.5481 - val_loss: 0.5238 - val_accuracy: 0.6893\n",
      "208/208 [==============================] - 0s 226us/step - loss: 0.6837 - accuracy: 0.5337 - val_loss: 0.6694 - val_accuracy: 0.6019\n",
      "Epoch 20/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.5000 - ETA: 7s - loss: 1.6699 - accuracy: 0.37 - 0s 240us/step - loss: 0.6917 - accuracy: 0.5481 - val_loss: 0.6894 - val_accuracy: 0.5437\n",
      "Epoch 21/10000\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7179 - accuracy: 0.3750Epoch 2/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.50 - 0s 307us/step - loss: 0.6710 - accuracy: 0.5769 - val_loss: 0.6865 - val_accuracy: 0.5534\n",
      "Epoch 22/10000208/208 [==============================]\n",
      " - 0s 255us/step - loss: 1.3861 - accuracy: 0.5625 - val_loss: 0.5283 - val_accuracy: 0.6990\n",
      "Epoch 3/10000\n",
      " - ETA: 0s - loss: 0.6724 - accuracy: 0.4375 16/208 [=>............................] - ETA: 0s - loss: 0.8937 - accuracy: 0208/208 [==============================]208/208 [==============================]208/208 [==============================] - 0s 282us/step - loss: 0.6946 - accuracy: 0.5817 - val_loss: 0.6399 - val_accuracy: 0.7184\n",
      " - 1s 4ms/step - loss: 1.2641 - accuracy: 0.5337 - val_loss: 0.6421 - val_accuracy: 0.5825\n",
      " - 0s 286us/step - loss: 0.9841 - accuracy: 0.5962 - val_loss: 0.5251 - val_accuracy: 0.7476\n",
      "Epoch 23/10000Epoch 4/10000\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.9388 - accuracy: 0.4375 - ETA: 0s - loss: 0.5265 - accuracy: 0.\n",
      "208/208 [==============================] - 0s 271us/step - loss: 0.9660 - accuracy: 0.5817 - val_loss: 0.5326 - val_accuracy: 0.7961\n",
      " - 0s 294us/step - loss: 0.7284 - accuracy: 0.5962 - val_loss: 0.5695 - val_accuracy: 0.8058\n",
      " 16/208 [=>............................]Epoch 5/10000Epoch 24/10000 - ETA: 0s - loss: 1.1101 - accuracy: 0.6250\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.7572 - accuracy: 0.5000 - ETA: 0s - loss: 0.6330 - accuracy: 0160/208 [======================>.......]160/208 [======================>.......] - ETA: 0s - loss: 1.3017 - accuracy: 0.5562160/208 [======================>.......] - ETA: 0s - loss: 0.7360 - accuracy: 0.5938 - ETA: 0s - loss: 0.7312 - accuracy: 0208/208 [==============================] - 0s 475us/step - loss: 0.7512 - accuracy: 0.5721 - val_loss: 0.5059 - val_accuracy: 0.8058\n",
      "208/208 [==============================] - 0s 530us/step - loss: 1.1775 - accuracy: 0.5673 - val_loss: 0.5878 - val_accuracy: 0.7282\n",
      " - 0s 502us/step - loss: 0.7317 - accuracy: 0.5577 - val_loss: 0.7478 - val_accuracy: 0.5437\n",
      "Epoch 6/10000\n",
      "Epoch 3/10000Epoch 25/10000\n",
      "\n",
      "208/208 [==============================]6250 16/208 [=>............................] 16/208 [=>............................] - ETA: 0s - loss: 0.7423 - accuracy: 0.6250 - ETA: 0s - loss: 0.6615 - accuracy: 0.128/208 [=================>............] - ETA: 0s - loss: 0.7746 - accuracy: 0.6250 - ETA: 0s - loss: 0.8687 - accuracy: 0.57 - 0s 306us/step - loss: 0.7582 - accuracy: 0.5577 - val_loss: 0.6796 - val_accuracy: 0.5534\n",
      "Epoch 26/10000\n",
      " 16/208 [=>........................... - ETA: 0s - loss: 0.7043 - accuracy: 0.5625208/208 [==============================]208/208 [==============================] - 0s 526us/step - loss: 0.7847 - accuracy: 0.5769 - val_loss: 0.6349 - val_accuracy: 0.6311\n",
      " - 0s 514us/step - loss: 0.8318 - accuracy: 0.5577 - val_loss: 0.6212 - val_accuracy: 0.7282\n",
      "Epoch 7/10000Epoch 4/10000\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.5152 - accuracy: 0.6875 - ETA: 0s - loss: 1.0398 - accuracy: 0.37 - 0s 378us/step - loss: 0.6960 - accuracy: 0.5769 - val_loss: 0.6467 - val_accuracy: 0.6990\n",
      "Epoch 27/10000\n",
      " 16/208 [=>............................]5437160/208 [======================>.......] - ETA: 0s - loss: 0.8419 - accuracy: 0.5688 - ETA: 0s - loss: 0.6727 - accuracy: 0.62208/208 [==============================]208/208 [==============================] - 0s 518us/step - loss: 0.6781 - accuracy: 0.5577 - val_loss: 0.6603 - val_accuracy: 0.6019\n",
      " - 0s 507us/step - loss: 0.8214 - accuracy: 0.5721 - val_loss: 0.5829 - val_accuracy: 0.7573\n",
      "Epoch 8/10000176/208 [========================>.....]Epoch 5/10000 - ETA: 0s - loss: 0.6793 - accuracy: 0.5625\n",
      "\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.7175 - accuracy: 0.5625 - ETA: 0s - loss: 0.6023 - accuracy: 0.75 - 0s 425us/step - loss: 0.6900 - accuracy: 0.5721 - val_loss: 0.6343 - val_accuracy: 0.6796\n",
      "208/208 [==============================] ETA: 0s - loss: 0.8359 - accuracy: 0.5750 - 0s 325us/step - loss: 0.7493 - accuracy: 0.5673 - val_loss: 0.6556 - val_accuracy: 0.6408\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.37 - 0s 520us/step - loss: 0.8360 - accuracy: 0.5673 - val_loss: 0.5170 - val_accuracy: 0.7184\n",
      "Epoch 6/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.81 - 0s 306us/step - loss: 0.7093 - accuracy: 0.6058 - val_loss: 0.6008 - val_accuracy: 0.8350\n",
      "Epoch 10/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.8184 - accuracy: 0.60 - 0s 340us/step - loss: 0.8077 - accuracy: 0.5673 - val_loss: 0.6492 - val_accuracy: 0.7282\n",
      "Epoch 11/10000208/208 [==============================]\n",
      " - 0s 527us/step - loss: 0.8352 - accuracy: 0.5865 - val_loss: 0.5064 - val_accuracy: 0.8155\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6983 - accuracy: 0.5000Epoch 7/10000\n",
      " - ETA: 0s - loss: 0.9197 - accuracy: 0.5437TA: 0s - loss: 1.1358 - accuracy: 0.4160/208 [======================>.......]208/208 [==============================] - 0s 353us/step - loss: 0.6664 - accuracy: 0.6490 - val_loss: 0.5031 - val_accuracy: 0.7767\n",
      "Epoch 12/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.75 - 0s 510us/step - loss: 0.8538 - accuracy: 0.5673 - val_loss: 0.5754 - val_accuracy: 0.7767\n",
      "Epoch 8/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8722 - accuracy: 0.50 - 0s 306us/step - loss: 0.7174 - accuracy: 0.5817 - val_loss: 0.4824 - val_accuracy: 0.7864\n",
      "Epoch 13/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 1.1745 - accuracy: 0.43 - 0s 350us/step - loss: 0.6777 - accuracy: 0.6202 - val_loss: 0.5407 - val_accuracy: 0.8252\n",
      "Epoch 9/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.50 - 0s 344us/step - loss: 0.7222 - accuracy: 0.5913 - val_loss: 0.4987 - val_accuracy: 0.7670\n",
      "Epoch 14/10000\n",
      " 16/208 [=>............................]208/208 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.5000 - 0s 306us/step - loss: 0.6555 - accuracy: 0.6298 - val_loss: 0.5274 - val_accuracy: 0.8252\n",
      "Epoch 10/10000\n",
      " - ETA: 0s - loss: 0.6674 - accuracy: 0.6094 16/208 [=>............................]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-06 15:58:54,160]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s - loss: 0.6169 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Finished trial#0 with value: 0.4928889275450359 with parameters: {'input_dropout': 0.6390508031418598, 'hidden_layers': 2, 'hidden_units': 56.0, 'hidden_dropout': 0.8863564940982054, 'batch_norm': 'non', 'batch_size': 32.0}. Best is trial#0 with value: 0.4928889275450359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.5481 - val_loss: 0.6352 - val_accuracy: 0.6699\n",
      "Epoch 15/10000\n",
      " - 0s 249us/step - loss: 0.6683 - accuracy: 0.6154 - val_loss: 0.5586 - val_accuracy: 0.8350\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.7461 - accuracy: 0.6250Epoch 11/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0. - 0s 301us/step - loss: 0.6733 - accuracy: 0.5865 - val_loss: 0.5305 - val_accuracy: 0.7573\n",
      "208/208 [==============================]Epoch 16/10000 - 0s 277us/step - loss: 0.7019 - accuracy: 0.6106 - val_loss: 0.5037 - val_accuracy: 0.8155\n",
      "\n",
      "Epoch 12/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.8125 - ETA: 0s - loss: 0.5321 - accuracy: 0.75 - 0s 252us/step - loss: 0.7059 - accuracy: 0.6154 - val_loss: 0.5796 - val_accuracy: 0.7573\n",
      "Epoch 17/10000208/208 [==============================]\n",
      " - 0s 265us/step - loss: 0.6212 - accuracy: 0.6298 - val_loss: 0.4872 - val_accuracy: 0.7670\n",
      "Epoch 13/10000 16/208 [=>............................]\n",
      "208/208 [==============================]6875 - ETA: 0s - loss: 0.6318 - accuracy: 0.68 - 0s 232us/step - loss: 0.6704 - accuracy: 0.6010 - val_loss: 0.5202 - val_accuracy: 0.7864\n",
      "Epoch 18/10000\n",
      "208/208 [==============================] 16/208 [=>............................] - ETA: 0s - loss: 0.7162 - accuracy: 0.5000 - 0s 268us/step - loss: 0.7876 - accuracy: 0.6154 - val_loss: 0.7372 - val_accuracy: 0.5631\n",
      "Epoch 14/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8013 - accuracy: 0.37 - 0s 231us/step - loss: 0.8384 - accuracy: 0.5529 - val_loss: 0.6040 - val_accuracy: 0.7087\n",
      "Epoch 19/10000\n",
      "208/208 [==============================] 16/208 [=>............................] - 0s 248us/step - loss: 0.7580 - accuracy: 0.5337 - val_loss: 0.6182 - val_accuracy: 0.7184\n",
      " - ETA: 0s - loss: 0.7587 - accuracy: 0.5625Epoch 15/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7682 - accuracy: 0.37 - 0s 250us/step - loss: 0.7357 - accuracy: 0.5337 - val_loss: 0.6214 - val_accuracy: 0.7184\n",
      "Epoch 20/10000\n",
      " - 0s 238us/step - loss: 0.7263 - accuracy: 0.5913 - val_loss: 0.5573 - val_accuracy: 0.8155\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6783 - accuracy: 0.5625Epoch 16/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8103 - accuracy: 0.56 - 0s 257us/step - loss: 0.6853 - accuracy: 0.5577 - val_loss: 0.6492 - val_accuracy: 0.6408\n",
      "Epoch 21/10000\n",
      "208/208 [==============================] ETA: 0s - loss: 0.7027 - accuracy: 0.5000 - 0s 319us/step - loss: 0.6846 - accuracy: 0.6010 - val_loss: 0.5709 - val_accuracy: 0.7961\n",
      "Epoch 17/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.62 - 0s 296us/step - loss: 0.7323 - accuracy: 0.5769 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
      "Epoch 22/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.75 - 0s 296us/step - loss: 0.7128 - accuracy: 0.5913 - val_loss: 0.5137 - val_accuracy: 0.8058\n",
      "Epoch 18/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.9774 - accuracy: 0.62 - 0s 255us/step - loss: 0.6987 - accuracy: 0.5577 - val_loss: 0.6900 - val_accuracy: 0.5437\n",
      "Epoch 23/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.87 - 0s 266us/step - loss: 0.7419 - accuracy: 0.5817 - val_loss: 0.6665 - val_accuracy: 0.5728\n",
      "Epoch 19/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.56 - 0s 250us/step - loss: 0.7266 - accuracy: 0.5673 - val_loss: 0.6693 - val_accuracy: 0.6117\n",
      "Epoch 24/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.56 - 0s 279us/step - loss: 0.7070 - accuracy: 0.6394 - val_loss: 0.5057 - val_accuracy: 0.8058\n",
      "Epoch 20/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.50 - 0s 261us/step - loss: 0.7144 - accuracy: 0.5769 - val_loss: 0.6925 - val_accuracy: 0.5437\n",
      "Epoch 25/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.56 - 0s 260us/step - loss: 0.7177 - accuracy: 0.5721 - val_loss: 0.5468 - val_accuracy: 0.7573\n",
      "Epoch 21/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5848 - accuracy: 0.68 - 0s 300us/step - loss: 0.6970 - accuracy: 0.5529 - val_loss: 0.6656 - val_accuracy: 0.6311\n",
      "Epoch 26/10000\n",
      " 16/208 [=>............................]208/208 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.7500 - 0s 240us/step - loss: 0.7034 - accuracy: 0.6010 - val_loss: 0.5542 - val_accuracy: 0.7961\n",
      "Epoch 22/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.56 - 0s 303us/step - loss: 0.6530 - accuracy: 0.6058 - val_loss: 0.6161 - val_accuracy: 0.6602\n",
      "Epoch 27/100\n",
      " - 0s 289us/step - loss: 0.6953 - accuracy: 0.5817 - val_loss: 0.4701 - val_accuracy: 0.8155\n",
      " 16/208 [=>............................] - ETA: 0s - loss: 0.6540 - accuracy: 0.6875Epoch 23/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.75 - 0s 298us/step - loss: 0.7894 - accuracy: 0.5433 - val_loss: 0.6505 - val_accuracy: 0.6505\n",
      "208/208 [==============================]Epoch 28/10000 - 0s 272us/step - loss: 0.8644 - accuracy: 0.5721 - val_loss: 0.5616 - val_accuracy: 0.7573\n",
      "\n",
      "Epoch 24/10000 16/208 [=>............................]\n",
      " 16/208 [=>............................]5000 - ETA: 0s - loss: 0.7583 - accuracy: 0.208/208 [==============================]208/208 [==============================] - 0s 289us/step - loss: 0.8664 - accuracy: 0.5865 - val_loss: 0.5469 - val_accuracy: 0.7476\n",
      " - 0s 320us/step - loss: 0.8050 - accuracy: 0.5288 - val_loss: 0.6858 - val_accuracy: 0.5534\n",
      "Epoch 25/10000\n",
      "Epoch 29/10000\n",
      " - 0s 291us/step - loss: 0.9424 - accuracy: 0.5577 - val_loss: 0.6835 - val_accuracy: 0.56310s - loss: 0.7385 - accuracy: 0.2208/208 [==============================]\n",
      "208/208 [==============================] - 0s 291us/step - loss: 0.6993 - accuracy: 0.5385 - val_loss: 0.6894 - val_accuracy: 0.5437\n",
      "Epoch 26/10000\n",
      "Epoch 30/10000\n",
      "208/208 [==============================]3125 16/208 [=>............................] - ETA: 0s - loss: 0.7154 - accuracy: 0. - 0s 281us/step - loss: 0.7434 - accuracy: 0.5625 - val_loss: 0.6893 - val_accuracy: 0.5437\n",
      "208/208 [==============================]Epoch 27/10000 - 0s 283us/step - loss: 0.7109 - accuracy: 0.5433 - val_loss: 0.6895 - val_accuracy: 0.5437\n",
      "\n",
      "Epoch 31/10000\n",
      " - 0s 263us/step - loss: 0.7037 - accuracy: 0.5288 - val_loss: 0.6897 - val_accuracy: 0.54370s - loss: 0.6810 - accuracy: 0.\n",
      "208/208 [==============================] - 0s 296us/step - loss: 0.7466 - accuracy: 0.5433 - val_loss: 0.6856 - val_accuracy: 0.5534\n",
      "Epoch 32/10000\n",
      "Epoch 28/10000\n",
      " 16/208 [=>............................] 16/208 [=>............................] - ETA: 0s - loss: 0.7133 - accuracy: 0.3125 - ETA: 0s - loss: 0.7163 - accuracy: 0.5208/208 [==============================] - 0s 294us/step - loss: 0.6798 - accuracy: 0.5577 - val_loss: 0.6901 - val_accuracy: 0.5437\n",
      "208/208 [==============================] - 0s 303us/step - loss: 0.7359 - accuracy: 0.5865 - val_loss: 0.6850 - val_accuracy: 0.5534\n",
      "Epoch 29/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6428 - accuracy: 0.43 - 0s 241us/step - loss: 0.8430 - accuracy: 0.5673 - val_loss: 0.6857 - val_accuracy: 0.5534\n",
      "Epoch 30/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - 0s 248us/step - loss: 0.8440 - accuracy: 0.5625 - val_loss: 0.6278 - val_accuracy: 0.6311\n",
      "Epoch 31/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7818 - accuracy: 0.56 - 0s 255us/step - loss: 0.7881 - accuracy: 0.5385 - val_loss: 0.6760 - val_accuracy: 0.5728\n",
      "Epoch 32/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.56 - ETA: 0s - loss: 0.7143 - accuracy: 0.56 - 0s 392us/step - loss: 0.7134 - accuracy: 0.5481 - val_loss: 0.6899 - val_accuracy: 0.5437\n",
      "Epoch 33/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6550 - accuracy: 0.68 - 0s 252us/step - loss: 0.7005 - accuracy: 0.5481 - val_loss: 0.6897 - val_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7697 - accuracy: 0.31 - 0s 203us/step - loss: 0.7570 - accuracy: 0.5673 - val_loss: 0.6901 - val_accuracy: 0.5437\n",
      "Epoch 35/10000\n",
      "144/208 [===================>..........] - ETA: 0s - loss: 0.6397 - accuracy: 0.68 - ETA: 0s - loss: 0.8385 - accuracy: 0.5556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-06 15:58:56,079] Finished trial#2 with value: 0.5112406199091787 with parameters: {'input_dropout': 0.8333800304661316, 'hidden_layers': 2, 'hidden_units': 32.0, 'hidden_dropout': 0.5142278368806639, 'batch_norm': 'non', 'batch_size': 16.0}. Best is trial#0 with value: 0.4928889275450359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.5433 - val_loss: 0.6897 - val_accuracy: 0.5437\n",
      "Epoch 36/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.62 - 0s 140us/step - loss: 0.6794 - accuracy: 0.5673 - val_loss: 0.6790 - val_accuracy: 0.5728\n",
      "Epoch 37/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.8480 - accuracy: 0.56 - 0s 177us/step - loss: 0.7206 - accuracy: 0.5433 - val_loss: 0.6857 - val_accuracy: 0.5534\n",
      "Epoch 38/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.43 - 0s 173us/step - loss: 0.7156 - accuracy: 0.5433 - val_loss: 0.6901 - val_accuracy: 0.5437\n",
      "Epoch 39/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7641 - accuracy: 0.25 - 0s 161us/step - loss: 0.7179 - accuracy: 0.5385 - val_loss: 0.6898 - val_accuracy: 0.5437\n",
      "Epoch 40/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.25 - 0s 158us/step - loss: 0.6885 - accuracy: 0.5769 - val_loss: 0.6440 - val_accuracy: 0.7087\n",
      "Epoch 41/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.75 - 0s 162us/step - loss: 0.7046 - accuracy: 0.5577 - val_loss: 0.6855 - val_accuracy: 0.5534\n",
      "Epoch 42/10000\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.68 - 0s 166us/step - loss: 0.6751 - accuracy: 0.5673 - val_loss: 0.6898 - val_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-06 15:58:56,770] Finished trial#1 with value: 0.5066768052211768 with parameters: {'input_dropout': 0.7167152904533249, 'hidden_layers': 1, 'hidden_units': 24.0, 'hidden_dropout': 0.24537038185395454, 'batch_norm': 'before_act', 'batch_size': 32.0}. Best is trial#0 with value: 0.4928889275450359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN has optimized parameters\n",
      "NN: {'learning_rate': 0.001, 'input_shape': 30, 'input_dropout': 0.8333800304661316, 'hidden_layers': 2, 'hidden_units': 32, 'hidden_dropout': 0.5142278368806639, 'batch_norm': 'non', 'batch_size': 16, 'epochs': 10000}\n",
      "------------------------------------------------------------------------------------------------\n",
      "Train on 249 samples, validate on 63 samples\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - ETA: 3s - loss: 1.0143 - accuracy: 0.62 - 0s 1ms/step - loss: 1.3616 - accuracy: 0.5181 - val_loss: 0.6694 - val_accuracy: 0.5238\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.43 - 0s 110us/step - loss: 1.1987 - accuracy: 0.4940 - val_loss: 0.6447 - val_accuracy: 0.6667\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5540 - accuracy: 0.37 - 0s 122us/step - loss: 1.3605 - accuracy: 0.4578 - val_loss: 0.6287 - val_accuracy: 0.7460\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8491 - accuracy: 0.56 - 0s 138us/step - loss: 0.9654 - accuracy: 0.5382 - val_loss: 0.6153 - val_accuracy: 0.7143\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.2839 - accuracy: 0.50 - 0s 140us/step - loss: 0.9927 - accuracy: 0.4859 - val_loss: 0.6117 - val_accuracy: 0.7460\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9978 - accuracy: 0.62 - 0s 141us/step - loss: 0.9625 - accuracy: 0.5663 - val_loss: 0.6086 - val_accuracy: 0.7302\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9872 - accuracy: 0.62 - 0s 141us/step - loss: 0.8486 - accuracy: 0.5221 - val_loss: 0.6039 - val_accuracy: 0.7143\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.1462 - accuracy: 0.62 - 0s 169us/step - loss: 0.9318 - accuracy: 0.5462 - val_loss: 0.6011 - val_accuracy: 0.7143\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.1342 - accuracy: 0.31 - 0s 172us/step - loss: 0.8235 - accuracy: 0.5863 - val_loss: 0.6012 - val_accuracy: 0.7143\n",
      "Epoch 10/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8140 - accuracy: 0.68 - 0s 188us/step - loss: 0.8270 - accuracy: 0.5422 - val_loss: 0.6023 - val_accuracy: 0.7460\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.37 - 0s 154us/step - loss: 0.8780 - accuracy: 0.5181 - val_loss: 0.6003 - val_accuracy: 0.7619\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.50 - 0s 146us/step - loss: 0.7869 - accuracy: 0.5422 - val_loss: 0.6006 - val_accuracy: 0.7460\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.1004 - accuracy: 0.37 - 0s 148us/step - loss: 0.8496 - accuracy: 0.5301 - val_loss: 0.6010 - val_accuracy: 0.7460\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8608 - accuracy: 0.50 - 0s 137us/step - loss: 0.8603 - accuracy: 0.5341 - val_loss: 0.6005 - val_accuracy: 0.7460\n",
      "Epoch 15/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.56 - 0s 140us/step - loss: 0.8375 - accuracy: 0.5382 - val_loss: 0.6005 - val_accuracy: 0.7460\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.68 - 0s 138us/step - loss: 0.7487 - accuracy: 0.5663 - val_loss: 0.6006 - val_accuracy: 0.7460\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.62 - 0s 141us/step - loss: 0.7624 - accuracy: 0.5783 - val_loss: 0.5992 - val_accuracy: 0.7619\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.1493 - accuracy: 0.43 - 0s 142us/step - loss: 0.8290 - accuracy: 0.5382 - val_loss: 0.6006 - val_accuracy: 0.7302\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.68 - 0s 141us/step - loss: 0.7747 - accuracy: 0.5904 - val_loss: 0.6006 - val_accuracy: 0.7302\n",
      "Epoch 20/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.1604 - accuracy: 0.37 - 0s 145us/step - loss: 0.7634 - accuracy: 0.5703 - val_loss: 0.6025 - val_accuracy: 0.7302\n",
      "Epoch 21/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7421 - accuracy: 0.62 - 0s 138us/step - loss: 0.8311 - accuracy: 0.5341 - val_loss: 0.6051 - val_accuracy: 0.7302\n",
      "Epoch 22/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.75 - 0s 143us/step - loss: 0.7606 - accuracy: 0.5542 - val_loss: 0.6053 - val_accuracy: 0.6984\n",
      "Epoch 23/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.75 - 0s 132us/step - loss: 0.7231 - accuracy: 0.5944 - val_loss: 0.6053 - val_accuracy: 0.6825\n",
      "Epoch 24/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.68 - 0s 132us/step - loss: 0.7164 - accuracy: 0.6225 - val_loss: 0.6060 - val_accuracy: 0.6984\n",
      "Epoch 25/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.56 - 0s 144us/step - loss: 0.7095 - accuracy: 0.6024 - val_loss: 0.6055 - val_accuracy: 0.6984\n",
      "Epoch 26/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.56 - 0s 156us/step - loss: 0.7359 - accuracy: 0.5783 - val_loss: 0.6059 - val_accuracy: 0.6984\n",
      "Epoch 27/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8031 - accuracy: 0.68 - 0s 159us/step - loss: 0.7459 - accuracy: 0.5823 - val_loss: 0.6067 - val_accuracy: 0.7143\n",
      "Train on 249 samples, validate on 63 samples\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - ETA: 3s - loss: 1.1694 - accuracy: 0.62 - 0s 1ms/step - loss: 1.5521 - accuracy: 0.5261 - val_loss: 0.7762 - val_accuracy: 0.4286\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.1207 - accuracy: 0.31 - 0s 111us/step - loss: 1.3877 - accuracy: 0.4980 - val_loss: 0.7258 - val_accuracy: 0.4603\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.68 - 0s 125us/step - loss: 1.1056 - accuracy: 0.5462 - val_loss: 0.6986 - val_accuracy: 0.5238\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.31 - 0s 141us/step - loss: 1.1093 - accuracy: 0.4980 - val_loss: 0.6750 - val_accuracy: 0.6190\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.68 - 0s 146us/step - loss: 0.8954 - accuracy: 0.5542 - val_loss: 0.6627 - val_accuracy: 0.6667\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4576 - accuracy: 0.37 - 0s 143us/step - loss: 1.0435 - accuracy: 0.5141 - val_loss: 0.6546 - val_accuracy: 0.6032\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.50 - 0s 137us/step - loss: 0.9366 - accuracy: 0.4980 - val_loss: 0.6437 - val_accuracy: 0.6032\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 0.43 - 0s 136us/step - loss: 0.9871 - accuracy: 0.5622 - val_loss: 0.6354 - val_accuracy: 0.6190\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0723 - accuracy: 0.37 - 0s 146us/step - loss: 0.9662 - accuracy: 0.4618 - val_loss: 0.6277 - val_accuracy: 0.6349\n",
      "Epoch 10/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9103 - accuracy: 0.43 - 0s 141us/step - loss: 0.9537 - accuracy: 0.5382 - val_loss: 0.6212 - val_accuracy: 0.6349\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.62 - 0s 146us/step - loss: 0.7409 - accuracy: 0.6225 - val_loss: 0.6153 - val_accuracy: 0.6984\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9352 - accuracy: 0.50 - 0s 141us/step - loss: 0.9924 - accuracy: 0.4859 - val_loss: 0.6095 - val_accuracy: 0.7460\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0033 - accuracy: 0.43 - 0s 154us/step - loss: 0.7819 - accuracy: 0.5141 - val_loss: 0.6037 - val_accuracy: 0.7460\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0961 - accuracy: 0.37 - 0s 148us/step - loss: 0.7971 - accuracy: 0.5221 - val_loss: 0.6007 - val_accuracy: 0.7302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.43 - 0s 152us/step - loss: 0.8151 - accuracy: 0.5663 - val_loss: 0.5956 - val_accuracy: 0.7937\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7871 - accuracy: 0.43 - 0s 144us/step - loss: 0.7604 - accuracy: 0.5582 - val_loss: 0.5940 - val_accuracy: 0.7778\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7868 - accuracy: 0.50 - 0s 136us/step - loss: 0.8399 - accuracy: 0.5100 - val_loss: 0.5912 - val_accuracy: 0.7937\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.62 - 0s 136us/step - loss: 0.7586 - accuracy: 0.5542 - val_loss: 0.5922 - val_accuracy: 0.7937\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.87 - 0s 147us/step - loss: 0.6768 - accuracy: 0.6265 - val_loss: 0.5926 - val_accuracy: 0.7937\n",
      "Epoch 20/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.56 - 0s 146us/step - loss: 0.7687 - accuracy: 0.5261 - val_loss: 0.5903 - val_accuracy: 0.7778\n",
      "Epoch 21/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.62 - 0s 146us/step - loss: 0.7646 - accuracy: 0.5663 - val_loss: 0.5886 - val_accuracy: 0.7937\n",
      "Epoch 22/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7730 - accuracy: 0.56 - 0s 145us/step - loss: 0.8307 - accuracy: 0.5301 - val_loss: 0.5924 - val_accuracy: 0.7937\n",
      "Epoch 23/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7594 - accuracy: 0.68 - 0s 149us/step - loss: 0.7160 - accuracy: 0.6185 - val_loss: 0.5917 - val_accuracy: 0.7937\n",
      "Epoch 24/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.68 - 0s 144us/step - loss: 0.7638 - accuracy: 0.5502 - val_loss: 0.5889 - val_accuracy: 0.8095\n",
      "Epoch 25/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.75 - 0s 150us/step - loss: 0.7069 - accuracy: 0.6024 - val_loss: 0.5875 - val_accuracy: 0.8095\n",
      "Epoch 26/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.56 - 0s 152us/step - loss: 0.6973 - accuracy: 0.5663 - val_loss: 0.5853 - val_accuracy: 0.8095\n",
      "Epoch 27/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.62 - 0s 156us/step - loss: 0.7252 - accuracy: 0.5863 - val_loss: 0.5847 - val_accuracy: 0.8095\n",
      "Epoch 28/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.75 - 0s 150us/step - loss: 0.6883 - accuracy: 0.6185 - val_loss: 0.5851 - val_accuracy: 0.8095\n",
      "Epoch 29/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.56 - 0s 145us/step - loss: 0.8094 - accuracy: 0.5502 - val_loss: 0.5875 - val_accuracy: 0.7937\n",
      "Epoch 30/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.81 - 0s 148us/step - loss: 0.6572 - accuracy: 0.6787 - val_loss: 0.5870 - val_accuracy: 0.7778\n",
      "Epoch 31/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0814 - accuracy: 0.62 - 0s 143us/step - loss: 0.7392 - accuracy: 0.5582 - val_loss: 0.5872 - val_accuracy: 0.7619\n",
      "Epoch 32/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7224 - accuracy: 0.56 - 0s 147us/step - loss: 0.6781 - accuracy: 0.6265 - val_loss: 0.5878 - val_accuracy: 0.7619\n",
      "Epoch 33/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.56 - 0s 150us/step - loss: 0.6826 - accuracy: 0.5823 - val_loss: 0.5863 - val_accuracy: 0.7619\n",
      "Epoch 34/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.62 - 0s 150us/step - loss: 0.6932 - accuracy: 0.6064 - val_loss: 0.5852 - val_accuracy: 0.7619\n",
      "Epoch 35/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.68 - 0s 149us/step - loss: 0.6725 - accuracy: 0.6104 - val_loss: 0.5835 - val_accuracy: 0.7619\n",
      "Epoch 36/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.75 - 0s 146us/step - loss: 0.6685 - accuracy: 0.6265 - val_loss: 0.5803 - val_accuracy: 0.7619\n",
      "Epoch 37/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8397 - accuracy: 0.50 - 0s 145us/step - loss: 0.6711 - accuracy: 0.6225 - val_loss: 0.5780 - val_accuracy: 0.7619\n",
      "Epoch 38/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.62 - 0s 142us/step - loss: 0.6231 - accuracy: 0.6426 - val_loss: 0.5755 - val_accuracy: 0.7778\n",
      "Epoch 39/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8053 - accuracy: 0.81 - 0s 144us/step - loss: 0.6708 - accuracy: 0.6064 - val_loss: 0.5738 - val_accuracy: 0.7937\n",
      "Epoch 40/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.62 - 0s 143us/step - loss: 0.7032 - accuracy: 0.5783 - val_loss: 0.5742 - val_accuracy: 0.8095\n",
      "Epoch 41/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.62 - 0s 149us/step - loss: 0.6620 - accuracy: 0.6024 - val_loss: 0.5751 - val_accuracy: 0.8095\n",
      "Epoch 42/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9203 - accuracy: 0.37 - 0s 154us/step - loss: 0.6799 - accuracy: 0.6185 - val_loss: 0.5740 - val_accuracy: 0.7937\n",
      "Epoch 43/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.50 - 0s 152us/step - loss: 0.7399 - accuracy: 0.5141 - val_loss: 0.5732 - val_accuracy: 0.7937\n",
      "Epoch 44/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7021 - accuracy: 0.50 - 0s 146us/step - loss: 0.6998 - accuracy: 0.5703 - val_loss: 0.5729 - val_accuracy: 0.8095\n",
      "Epoch 45/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.62 - 0s 144us/step - loss: 0.6548 - accuracy: 0.6145 - val_loss: 0.5716 - val_accuracy: 0.8095\n",
      "Epoch 46/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.50 - 0s 147us/step - loss: 0.6542 - accuracy: 0.6225 - val_loss: 0.5742 - val_accuracy: 0.7937\n",
      "Epoch 47/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.62 - 0s 149us/step - loss: 0.6458 - accuracy: 0.6265 - val_loss: 0.5711 - val_accuracy: 0.7937\n",
      "Epoch 48/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.56 - 0s 153us/step - loss: 0.6181 - accuracy: 0.6185 - val_loss: 0.5668 - val_accuracy: 0.7937\n",
      "Epoch 49/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.50 - 0s 153us/step - loss: 0.6448 - accuracy: 0.6145 - val_loss: 0.5660 - val_accuracy: 0.7937\n",
      "Epoch 50/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.93 - 0s 145us/step - loss: 0.6322 - accuracy: 0.6667 - val_loss: 0.5630 - val_accuracy: 0.7937\n",
      "Epoch 51/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.62 - 0s 148us/step - loss: 0.6570 - accuracy: 0.6305 - val_loss: 0.5604 - val_accuracy: 0.7937\n",
      "Epoch 52/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.81 - 0s 151us/step - loss: 0.6420 - accuracy: 0.6546 - val_loss: 0.5573 - val_accuracy: 0.7937\n",
      "Epoch 53/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.56 - 0s 146us/step - loss: 0.6527 - accuracy: 0.6145 - val_loss: 0.5569 - val_accuracy: 0.7937\n",
      "Epoch 54/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.68 - 0s 143us/step - loss: 0.6464 - accuracy: 0.6345 - val_loss: 0.5565 - val_accuracy: 0.7937\n",
      "Epoch 55/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.50 - 0s 146us/step - loss: 0.6727 - accuracy: 0.6145 - val_loss: 0.5575 - val_accuracy: 0.7937\n",
      "Epoch 56/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.68 - 0s 149us/step - loss: 0.6624 - accuracy: 0.5863 - val_loss: 0.5573 - val_accuracy: 0.7937\n",
      "Epoch 57/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.68 - 0s 148us/step - loss: 0.6500 - accuracy: 0.6265 - val_loss: 0.5566 - val_accuracy: 0.7937\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.50 - 0s 151us/step - loss: 0.6492 - accuracy: 0.6305 - val_loss: 0.5561 - val_accuracy: 0.7937\n",
      "Epoch 59/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.62 - 0s 142us/step - loss: 0.6369 - accuracy: 0.6546 - val_loss: 0.5557 - val_accuracy: 0.7937\n",
      "Epoch 60/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.62 - 0s 140us/step - loss: 0.6620 - accuracy: 0.6667 - val_loss: 0.5544 - val_accuracy: 0.7937\n",
      "Epoch 61/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.43 - 0s 137us/step - loss: 0.6053 - accuracy: 0.6546 - val_loss: 0.5519 - val_accuracy: 0.7937\n",
      "Epoch 62/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.68 - 0s 141us/step - loss: 0.6640 - accuracy: 0.5944 - val_loss: 0.5507 - val_accuracy: 0.7937\n",
      "Epoch 63/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.62 - 0s 144us/step - loss: 0.6159 - accuracy: 0.6546 - val_loss: 0.5476 - val_accuracy: 0.7937\n",
      "Epoch 64/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.75 - 0s 145us/step - loss: 0.6643 - accuracy: 0.6627 - val_loss: 0.5437 - val_accuracy: 0.7937\n",
      "Epoch 65/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6664 - accuracy: 0.62 - 0s 148us/step - loss: 0.6038 - accuracy: 0.6787 - val_loss: 0.5405 - val_accuracy: 0.7937\n",
      "Epoch 66/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.50 - 0s 145us/step - loss: 0.5972 - accuracy: 0.6747 - val_loss: 0.5367 - val_accuracy: 0.7937\n",
      "Epoch 67/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.62 - 0s 147us/step - loss: 0.6189 - accuracy: 0.6667 - val_loss: 0.5346 - val_accuracy: 0.7937\n",
      "Epoch 68/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.68 - 0s 142us/step - loss: 0.6632 - accuracy: 0.6345 - val_loss: 0.5313 - val_accuracy: 0.7937\n",
      "Epoch 69/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.68 - 0s 146us/step - loss: 0.5708 - accuracy: 0.7068 - val_loss: 0.5277 - val_accuracy: 0.7937\n",
      "Epoch 70/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.68 - 0s 147us/step - loss: 0.5907 - accuracy: 0.6506 - val_loss: 0.5215 - val_accuracy: 0.7937\n",
      "Epoch 71/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.62 - 0s 142us/step - loss: 0.6319 - accuracy: 0.6185 - val_loss: 0.5197 - val_accuracy: 0.8095\n",
      "Epoch 72/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.50 - 0s 146us/step - loss: 0.6216 - accuracy: 0.6586 - val_loss: 0.5214 - val_accuracy: 0.8095\n",
      "Epoch 73/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.75 - 0s 155us/step - loss: 0.5982 - accuracy: 0.6827 - val_loss: 0.5207 - val_accuracy: 0.8095\n",
      "Epoch 74/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6578 - accuracy: 0.75 - 0s 145us/step - loss: 0.6431 - accuracy: 0.6506 - val_loss: 0.5216 - val_accuracy: 0.8095\n",
      "Epoch 75/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7968 - accuracy: 0.50 - 0s 144us/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 0.5215 - val_accuracy: 0.8095\n",
      "Epoch 76/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.75 - 0s 148us/step - loss: 0.6312 - accuracy: 0.6867 - val_loss: 0.5189 - val_accuracy: 0.8095\n",
      "Epoch 77/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.68 - 0s 147us/step - loss: 0.5854 - accuracy: 0.7028 - val_loss: 0.5142 - val_accuracy: 0.8095\n",
      "Epoch 78/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.56 - 0s 144us/step - loss: 0.6599 - accuracy: 0.6185 - val_loss: 0.5146 - val_accuracy: 0.8095\n",
      "Epoch 79/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.81 - 0s 140us/step - loss: 0.6448 - accuracy: 0.6707 - val_loss: 0.5161 - val_accuracy: 0.8095\n",
      "Epoch 80/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.62 - 0s 140us/step - loss: 0.6337 - accuracy: 0.6747 - val_loss: 0.5149 - val_accuracy: 0.8095\n",
      "Epoch 81/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.75 - 0s 141us/step - loss: 0.6316 - accuracy: 0.6627 - val_loss: 0.5130 - val_accuracy: 0.8095\n",
      "Epoch 82/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.62 - 0s 142us/step - loss: 0.6126 - accuracy: 0.6586 - val_loss: 0.5125 - val_accuracy: 0.8095\n",
      "Epoch 83/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.9476 - accuracy: 0.56 - 0s 149us/step - loss: 0.6452 - accuracy: 0.6546 - val_loss: 0.5138 - val_accuracy: 0.8095\n",
      "Epoch 84/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.87 - 0s 164us/step - loss: 0.6530 - accuracy: 0.6948 - val_loss: 0.5157 - val_accuracy: 0.8095\n",
      "Epoch 85/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7796 - accuracy: 0.68 - 0s 171us/step - loss: 0.6160 - accuracy: 0.7108 - val_loss: 0.5197 - val_accuracy: 0.8095\n",
      "Epoch 86/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.75 - 0s 178us/step - loss: 0.6475 - accuracy: 0.6867 - val_loss: 0.5175 - val_accuracy: 0.8095\n",
      "Epoch 87/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.56 - 0s 147us/step - loss: 0.6394 - accuracy: 0.6426 - val_loss: 0.5158 - val_accuracy: 0.8095\n",
      "Epoch 88/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.56 - 0s 147us/step - loss: 0.6041 - accuracy: 0.6667 - val_loss: 0.5166 - val_accuracy: 0.8095\n",
      "Epoch 89/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.62 - 0s 145us/step - loss: 0.6194 - accuracy: 0.6707 - val_loss: 0.5147 - val_accuracy: 0.8095\n",
      "Epoch 90/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.62 - 0s 153us/step - loss: 0.6330 - accuracy: 0.6305 - val_loss: 0.5168 - val_accuracy: 0.8095\n",
      "Epoch 91/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.62 - 0s 153us/step - loss: 0.6230 - accuracy: 0.6426 - val_loss: 0.5202 - val_accuracy: 0.8095\n",
      "Epoch 92/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.75 - 0s 152us/step - loss: 0.5809 - accuracy: 0.6948 - val_loss: 0.5174 - val_accuracy: 0.8095\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "250/250 [==============================] - ETA: 3s - loss: 1.2418 - accuracy: 0.62 - 0s 1ms/step - loss: 1.3550 - accuracy: 0.5600 - val_loss: 0.6645 - val_accuracy: 0.6129\n",
      "Epoch 2/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 2.8708 - accuracy: 0.31 - 0s 108us/step - loss: 1.4508 - accuracy: 0.5640 - val_loss: 0.6285 - val_accuracy: 0.7097\n",
      "Epoch 3/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.2104 - accuracy: 0.68 - 0s 123us/step - loss: 1.0666 - accuracy: 0.5760 - val_loss: 0.6062 - val_accuracy: 0.8065\n",
      "Epoch 4/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.1938 - accuracy: 0.56 - 0s 137us/step - loss: 1.1294 - accuracy: 0.5320 - val_loss: 0.6000 - val_accuracy: 0.7742\n",
      "Epoch 5/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.0981 - accuracy: 0.50 - 0s 155us/step - loss: 1.0538 - accuracy: 0.5440 - val_loss: 0.5955 - val_accuracy: 0.7581\n",
      "Epoch 6/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.7638 - accuracy: 0.56 - 0s 150us/step - loss: 1.2438 - accuracy: 0.5200 - val_loss: 0.5922 - val_accuracy: 0.7258\n",
      "Epoch 7/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.62 - 0s 146us/step - loss: 0.7569 - accuracy: 0.6200 - val_loss: 0.5883 - val_accuracy: 0.7097\n",
      "Epoch 8/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.56 - 0s 151us/step - loss: 0.8832 - accuracy: 0.5640 - val_loss: 0.5864 - val_accuracy: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7828 - accuracy: 0.68 - 0s 146us/step - loss: 0.9123 - accuracy: 0.5520 - val_loss: 0.5863 - val_accuracy: 0.7097\n",
      "Epoch 10/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.75 - 0s 145us/step - loss: 0.7799 - accuracy: 0.5880 - val_loss: 0.5863 - val_accuracy: 0.7097\n",
      "Epoch 11/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8152 - accuracy: 0.68 - 0s 142us/step - loss: 0.9277 - accuracy: 0.5360 - val_loss: 0.5838 - val_accuracy: 0.7097\n",
      "Epoch 12/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9184 - accuracy: 0.56 - 0s 146us/step - loss: 0.9023 - accuracy: 0.5440 - val_loss: 0.5831 - val_accuracy: 0.7097\n",
      "Epoch 13/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3775 - accuracy: 0.37 - 0s 140us/step - loss: 0.8659 - accuracy: 0.5320 - val_loss: 0.5846 - val_accuracy: 0.7097\n",
      "Epoch 14/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.0428 - accuracy: 0.43 - 0s 142us/step - loss: 0.8923 - accuracy: 0.5200 - val_loss: 0.5836 - val_accuracy: 0.7097\n",
      "Epoch 15/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.1154 - accuracy: 0.43 - 0s 147us/step - loss: 0.8373 - accuracy: 0.5480 - val_loss: 0.5844 - val_accuracy: 0.7097\n",
      "Epoch 16/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9236 - accuracy: 0.50 - 0s 149us/step - loss: 0.8627 - accuracy: 0.4920 - val_loss: 0.5843 - val_accuracy: 0.7097\n",
      "Epoch 17/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.0704 - accuracy: 0.37 - 0s 147us/step - loss: 0.9176 - accuracy: 0.5160 - val_loss: 0.5848 - val_accuracy: 0.7097\n",
      "Epoch 18/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7914 - accuracy: 0.56 - 0s 150us/step - loss: 0.8000 - accuracy: 0.5600 - val_loss: 0.5839 - val_accuracy: 0.7097\n",
      "Epoch 19/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4974 - accuracy: 0.43 - 0s 147us/step - loss: 0.8232 - accuracy: 0.5960 - val_loss: 0.5843 - val_accuracy: 0.7097\n",
      "Epoch 20/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4682 - accuracy: 0.62 - 0s 150us/step - loss: 0.8193 - accuracy: 0.5880 - val_loss: 0.5852 - val_accuracy: 0.6935\n",
      "Epoch 21/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.68 - 0s 149us/step - loss: 0.6977 - accuracy: 0.6360 - val_loss: 0.5850 - val_accuracy: 0.7097\n",
      "Epoch 22/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.62 - 0s 149us/step - loss: 0.7462 - accuracy: 0.6360 - val_loss: 0.5832 - val_accuracy: 0.6935\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "250/250 [==============================] - ETA: 3s - loss: 1.5588 - accuracy: 0.25 - 0s 1ms/step - loss: 1.6646 - accuracy: 0.5080 - val_loss: 0.6378 - val_accuracy: 0.5484\n",
      "Epoch 2/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3734 - accuracy: 0.50 - 0s 110us/step - loss: 1.4266 - accuracy: 0.5000 - val_loss: 0.6263 - val_accuracy: 0.5645\n",
      "Epoch 3/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.2962 - accuracy: 0.56 - 0s 127us/step - loss: 1.4509 - accuracy: 0.4720 - val_loss: 0.6197 - val_accuracy: 0.6129\n",
      "Epoch 4/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.68 - 0s 145us/step - loss: 0.9769 - accuracy: 0.5000 - val_loss: 0.6145 - val_accuracy: 0.6290\n",
      "Epoch 5/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4943 - accuracy: 0.50 - 0s 148us/step - loss: 1.0586 - accuracy: 0.5040 - val_loss: 0.6099 - val_accuracy: 0.7097\n",
      "Epoch 6/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.37 - 0s 142us/step - loss: 1.0011 - accuracy: 0.5000 - val_loss: 0.6034 - val_accuracy: 0.7097\n",
      "Epoch 7/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.2114 - accuracy: 0.43 - 0s 145us/step - loss: 0.9940 - accuracy: 0.5440 - val_loss: 0.5990 - val_accuracy: 0.7097\n",
      "Epoch 8/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8245 - accuracy: 0.56 - 0s 150us/step - loss: 1.0956 - accuracy: 0.5560 - val_loss: 0.5935 - val_accuracy: 0.7258\n",
      "Epoch 9/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3257 - accuracy: 0.56 - 0s 153us/step - loss: 1.0670 - accuracy: 0.5400 - val_loss: 0.5943 - val_accuracy: 0.7097\n",
      "Epoch 10/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9710 - accuracy: 0.50 - 0s 155us/step - loss: 0.8312 - accuracy: 0.6040 - val_loss: 0.5915 - val_accuracy: 0.7097\n",
      "Epoch 11/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.7195 - accuracy: 0.50 - 0s 149us/step - loss: 0.9799 - accuracy: 0.5760 - val_loss: 0.5891 - val_accuracy: 0.7258\n",
      "Epoch 12/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3960 - accuracy: 0.50 - 0s 148us/step - loss: 0.9271 - accuracy: 0.5840 - val_loss: 0.5914 - val_accuracy: 0.7258\n",
      "Epoch 13/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.75 - 0s 141us/step - loss: 0.9302 - accuracy: 0.5360 - val_loss: 0.5935 - val_accuracy: 0.7258\n",
      "Epoch 14/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.1513 - accuracy: 0.43 - 0s 142us/step - loss: 0.8841 - accuracy: 0.5280 - val_loss: 0.5952 - val_accuracy: 0.7419\n",
      "Epoch 15/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8460 - accuracy: 0.62 - 0s 151us/step - loss: 0.8825 - accuracy: 0.5520 - val_loss: 0.5940 - val_accuracy: 0.7419\n",
      "Epoch 16/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.62 - 0s 149us/step - loss: 0.7910 - accuracy: 0.5920 - val_loss: 0.5904 - val_accuracy: 0.7419\n",
      "Epoch 17/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.56 - 0s 147us/step - loss: 0.8480 - accuracy: 0.6000 - val_loss: 0.5890 - val_accuracy: 0.7419\n",
      "Epoch 18/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7394 - accuracy: 0.56 - 0s 149us/step - loss: 0.8373 - accuracy: 0.5320 - val_loss: 0.5873 - val_accuracy: 0.7581\n",
      "Epoch 19/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.62 - 0s 149us/step - loss: 0.7659 - accuracy: 0.5920 - val_loss: 0.5865 - val_accuracy: 0.7581\n",
      "Epoch 20/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8528 - accuracy: 0.43 - 0s 167us/step - loss: 0.7572 - accuracy: 0.6120 - val_loss: 0.5850 - val_accuracy: 0.7581\n",
      "Epoch 21/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.50 - 0s 155us/step - loss: 0.7032 - accuracy: 0.5800 - val_loss: 0.5839 - val_accuracy: 0.7581\n",
      "Epoch 22/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.43 - 0s 148us/step - loss: 0.7682 - accuracy: 0.5920 - val_loss: 0.5833 - val_accuracy: 0.7581\n",
      "Epoch 23/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.68 - 0s 154us/step - loss: 0.7390 - accuracy: 0.6000 - val_loss: 0.5831 - val_accuracy: 0.7419\n",
      "Epoch 24/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.62 - 0s 153us/step - loss: 0.7951 - accuracy: 0.6240 - val_loss: 0.5828 - val_accuracy: 0.7419\n",
      "Epoch 25/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.62 - 0s 146us/step - loss: 0.7470 - accuracy: 0.6080 - val_loss: 0.5849 - val_accuracy: 0.7419\n",
      "Epoch 26/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.75 - 0s 153us/step - loss: 0.6675 - accuracy: 0.6800 - val_loss: 0.5828 - val_accuracy: 0.7258\n",
      "Epoch 27/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9699 - accuracy: 0.62 - 0s 153us/step - loss: 0.7365 - accuracy: 0.5840 - val_loss: 0.5819 - val_accuracy: 0.7258\n",
      "Epoch 28/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.0013 - accuracy: 0.31 - 0s 161us/step - loss: 0.7766 - accuracy: 0.5760 - val_loss: 0.5814 - val_accuracy: 0.7419\n",
      "Epoch 29/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.62 - 0s 156us/step - loss: 0.7587 - accuracy: 0.6280 - val_loss: 0.5825 - val_accuracy: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.68 - 0s 149us/step - loss: 0.6678 - accuracy: 0.6600 - val_loss: 0.5794 - val_accuracy: 0.7419\n",
      "Epoch 31/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.75 - 0s 141us/step - loss: 0.6933 - accuracy: 0.6120 - val_loss: 0.5779 - val_accuracy: 0.7581\n",
      "Epoch 32/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.50 - 0s 146us/step - loss: 0.7246 - accuracy: 0.6320 - val_loss: 0.5770 - val_accuracy: 0.7258\n",
      "Epoch 33/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.56 - 0s 145us/step - loss: 0.6751 - accuracy: 0.6120 - val_loss: 0.5781 - val_accuracy: 0.7258\n",
      "Epoch 34/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.68 - 0s 149us/step - loss: 0.6718 - accuracy: 0.6480 - val_loss: 0.5786 - val_accuracy: 0.7258\n",
      "Epoch 35/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.62 - 0s 152us/step - loss: 0.7094 - accuracy: 0.6200 - val_loss: 0.5768 - val_accuracy: 0.7258\n",
      "Epoch 36/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.75 - 0s 151us/step - loss: 0.6443 - accuracy: 0.6400 - val_loss: 0.5737 - val_accuracy: 0.7258\n",
      "Epoch 37/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6521 - accuracy: 0.81 - 0s 146us/step - loss: 0.6529 - accuracy: 0.6120 - val_loss: 0.5724 - val_accuracy: 0.7258\n",
      "Epoch 38/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8948 - accuracy: 0.50 - 0s 147us/step - loss: 0.6844 - accuracy: 0.6280 - val_loss: 0.5750 - val_accuracy: 0.7258\n",
      "Epoch 39/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.68 - 0s 147us/step - loss: 0.6331 - accuracy: 0.6880 - val_loss: 0.5731 - val_accuracy: 0.7258\n",
      "Epoch 40/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.56 - 0s 152us/step - loss: 0.7086 - accuracy: 0.6360 - val_loss: 0.5717 - val_accuracy: 0.7258\n",
      "Epoch 41/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.62 - 0s 152us/step - loss: 0.6517 - accuracy: 0.6240 - val_loss: 0.5710 - val_accuracy: 0.7258\n",
      "Epoch 42/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.81 - 0s 146us/step - loss: 0.7069 - accuracy: 0.6000 - val_loss: 0.5679 - val_accuracy: 0.7258\n",
      "Epoch 43/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - 0s 141us/step - loss: 0.6700 - accuracy: 0.6080 - val_loss: 0.5680 - val_accuracy: 0.7258\n",
      "Epoch 44/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.62 - 0s 151us/step - loss: 0.6472 - accuracy: 0.6440 - val_loss: 0.5677 - val_accuracy: 0.7258\n",
      "Epoch 45/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8085 - accuracy: 0.62 - 0s 154us/step - loss: 0.7210 - accuracy: 0.6080 - val_loss: 0.5694 - val_accuracy: 0.7258\n",
      "Epoch 46/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.43 - 0s 150us/step - loss: 0.7258 - accuracy: 0.6320 - val_loss: 0.5718 - val_accuracy: 0.7419\n",
      "Epoch 47/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7356 - accuracy: 0.68 - 0s 152us/step - loss: 0.6889 - accuracy: 0.6400 - val_loss: 0.5740 - val_accuracy: 0.7419\n",
      "Epoch 48/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.68 - 0s 148us/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.5738 - val_accuracy: 0.7419\n",
      "Epoch 49/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.62 - 0s 150us/step - loss: 0.6303 - accuracy: 0.6480 - val_loss: 0.5719 - val_accuracy: 0.7419\n",
      "Epoch 50/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.50 - 0s 151us/step - loss: 0.6819 - accuracy: 0.6120 - val_loss: 0.5699 - val_accuracy: 0.7419\n",
      "Epoch 51/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.68 - 0s 167us/step - loss: 0.5981 - accuracy: 0.6920 - val_loss: 0.5673 - val_accuracy: 0.7419\n",
      "Epoch 52/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.68 - 0s 166us/step - loss: 0.6421 - accuracy: 0.6680 - val_loss: 0.5652 - val_accuracy: 0.7258\n",
      "Epoch 53/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8280 - accuracy: 0.50 - 0s 158us/step - loss: 0.6215 - accuracy: 0.6440 - val_loss: 0.5635 - val_accuracy: 0.7258\n",
      "Epoch 54/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.81 - 0s 160us/step - loss: 0.6195 - accuracy: 0.6560 - val_loss: 0.5636 - val_accuracy: 0.7258\n",
      "Epoch 55/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.62 - 0s 169us/step - loss: 0.6444 - accuracy: 0.6720 - val_loss: 0.5642 - val_accuracy: 0.7581\n",
      "Epoch 56/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9631 - accuracy: 0.37 - 0s 155us/step - loss: 0.6196 - accuracy: 0.6440 - val_loss: 0.5637 - val_accuracy: 0.7581\n",
      "Epoch 57/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.75 - 0s 152us/step - loss: 0.6932 - accuracy: 0.6480 - val_loss: 0.5617 - val_accuracy: 0.7581\n",
      "Epoch 58/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.68 - 0s 173us/step - loss: 0.6139 - accuracy: 0.6760 - val_loss: 0.5584 - val_accuracy: 0.7581\n",
      "Epoch 59/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.75 - 0s 161us/step - loss: 0.6043 - accuracy: 0.6920 - val_loss: 0.5562 - val_accuracy: 0.7581\n",
      "Epoch 60/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.75 - 0s 158us/step - loss: 0.6391 - accuracy: 0.6520 - val_loss: 0.5580 - val_accuracy: 0.7581\n",
      "Epoch 61/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.62 - 0s 147us/step - loss: 0.6382 - accuracy: 0.6760 - val_loss: 0.5569 - val_accuracy: 0.7581\n",
      "Epoch 62/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.75 - 0s 140us/step - loss: 0.6192 - accuracy: 0.6480 - val_loss: 0.5527 - val_accuracy: 0.7581\n",
      "Epoch 63/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5834 - accuracy: 0.75 - 0s 152us/step - loss: 0.6164 - accuracy: 0.6760 - val_loss: 0.5504 - val_accuracy: 0.7581\n",
      "Epoch 64/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.56 - 0s 146us/step - loss: 0.6445 - accuracy: 0.6520 - val_loss: 0.5472 - val_accuracy: 0.7581\n",
      "Epoch 65/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.68 - 0s 158us/step - loss: 0.6075 - accuracy: 0.6840 - val_loss: 0.5457 - val_accuracy: 0.7581\n",
      "Epoch 66/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.50 - 0s 163us/step - loss: 0.6190 - accuracy: 0.6640 - val_loss: 0.5437 - val_accuracy: 0.7581\n",
      "Epoch 67/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.68 - 0s 155us/step - loss: 0.6221 - accuracy: 0.6400 - val_loss: 0.5445 - val_accuracy: 0.7581\n",
      "Epoch 68/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7987 - accuracy: 0.50 - 0s 154us/step - loss: 0.5970 - accuracy: 0.6920 - val_loss: 0.5449 - val_accuracy: 0.7581\n",
      "Epoch 69/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.56 - 0s 151us/step - loss: 0.6471 - accuracy: 0.6440 - val_loss: 0.5457 - val_accuracy: 0.7581\n",
      "Epoch 70/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.62 - 0s 151us/step - loss: 0.6484 - accuracy: 0.6600 - val_loss: 0.5457 - val_accuracy: 0.7581\n",
      "Epoch 71/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.68 - 0s 151us/step - loss: 0.6049 - accuracy: 0.6640 - val_loss: 0.5461 - val_accuracy: 0.7581\n",
      "Epoch 72/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.68 - 0s 153us/step - loss: 0.6143 - accuracy: 0.6560 - val_loss: 0.5464 - val_accuracy: 0.7581\n",
      "Epoch 73/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.62 - 0s 152us/step - loss: 0.6202 - accuracy: 0.6840 - val_loss: 0.5461 - val_accuracy: 0.7581\n",
      "Epoch 74/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.62 - 0s 151us/step - loss: 0.6124 - accuracy: 0.7000 - val_loss: 0.5444 - val_accuracy: 0.7581\n",
      "Epoch 75/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.62 - 0s 151us/step - loss: 0.6104 - accuracy: 0.6440 - val_loss: 0.5428 - val_accuracy: 0.7581\n",
      "Epoch 76/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7134 - accuracy: 0.75 - 0s 152us/step - loss: 0.6228 - accuracy: 0.6960 - val_loss: 0.5424 - val_accuracy: 0.7581\n",
      "Epoch 77/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4758 - accuracy: 0.68 - 0s 146us/step - loss: 0.5976 - accuracy: 0.6480 - val_loss: 0.5411 - val_accuracy: 0.7581\n",
      "Epoch 78/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.56 - 0s 146us/step - loss: 0.6044 - accuracy: 0.6760 - val_loss: 0.5397 - val_accuracy: 0.7581\n",
      "Epoch 79/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7113 - accuracy: 0.56 - 0s 150us/step - loss: 0.6264 - accuracy: 0.7000 - val_loss: 0.5388 - val_accuracy: 0.7581\n",
      "Epoch 80/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.68 - 0s 151us/step - loss: 0.5796 - accuracy: 0.7040 - val_loss: 0.5388 - val_accuracy: 0.7581\n",
      "Epoch 81/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5940 - accuracy: 0.68 - 0s 147us/step - loss: 0.5763 - accuracy: 0.6920 - val_loss: 0.5381 - val_accuracy: 0.7581\n",
      "Epoch 82/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.81 - 0s 148us/step - loss: 0.5766 - accuracy: 0.7080 - val_loss: 0.5379 - val_accuracy: 0.7581\n",
      "Epoch 83/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8244 - accuracy: 0.62 - 0s 156us/step - loss: 0.6145 - accuracy: 0.6720 - val_loss: 0.5380 - val_accuracy: 0.7581\n",
      "Epoch 84/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.68 - 0s 147us/step - loss: 0.5998 - accuracy: 0.6680 - val_loss: 0.5379 - val_accuracy: 0.7581\n",
      "Epoch 85/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.75 - 0s 152us/step - loss: 0.5750 - accuracy: 0.6920 - val_loss: 0.5360 - val_accuracy: 0.7581\n",
      "Epoch 86/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.50 - 0s 155us/step - loss: 0.6400 - accuracy: 0.6600 - val_loss: 0.5361 - val_accuracy: 0.7581\n",
      "Epoch 87/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.81 - 0s 151us/step - loss: 0.5543 - accuracy: 0.7080 - val_loss: 0.5352 - val_accuracy: 0.7419\n",
      "Epoch 88/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.68 - 0s 153us/step - loss: 0.6049 - accuracy: 0.6680 - val_loss: 0.5336 - val_accuracy: 0.7581\n",
      "Epoch 89/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.81 - 0s 149us/step - loss: 0.6065 - accuracy: 0.7160 - val_loss: 0.5335 - val_accuracy: 0.7581\n",
      "Epoch 90/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.75 - 0s 157us/step - loss: 0.6042 - accuracy: 0.6960 - val_loss: 0.5337 - val_accuracy: 0.7581\n",
      "Epoch 91/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.87 - 0s 150us/step - loss: 0.6032 - accuracy: 0.6960 - val_loss: 0.5329 - val_accuracy: 0.7581\n",
      "Epoch 92/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.75 - 0s 149us/step - loss: 0.5654 - accuracy: 0.7080 - val_loss: 0.5307 - val_accuracy: 0.7419\n",
      "Epoch 93/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.68 - 0s 154us/step - loss: 0.6220 - accuracy: 0.6920 - val_loss: 0.5302 - val_accuracy: 0.7581\n",
      "Epoch 94/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.75 - 0s 159us/step - loss: 0.5991 - accuracy: 0.6760 - val_loss: 0.5334 - val_accuracy: 0.7581\n",
      "Epoch 95/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.87 - 0s 143us/step - loss: 0.5824 - accuracy: 0.7120 - val_loss: 0.5329 - val_accuracy: 0.7581\n",
      "Epoch 96/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7474 - accuracy: 0.50 - 0s 138us/step - loss: 0.6162 - accuracy: 0.6400 - val_loss: 0.5329 - val_accuracy: 0.7581\n",
      "Epoch 97/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5867 - accuracy: 0.68 - 0s 143us/step - loss: 0.5899 - accuracy: 0.7000 - val_loss: 0.5320 - val_accuracy: 0.7581\n",
      "Epoch 98/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.81 - 0s 151us/step - loss: 0.5999 - accuracy: 0.6960 - val_loss: 0.5312 - val_accuracy: 0.7581\n",
      "Epoch 99/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.43 - 0s 149us/step - loss: 0.6018 - accuracy: 0.6840 - val_loss: 0.5312 - val_accuracy: 0.7581\n",
      "Epoch 100/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.87 - 0s 144us/step - loss: 0.5560 - accuracy: 0.7280 - val_loss: 0.5284 - val_accuracy: 0.7581\n",
      "Epoch 101/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.56 - 0s 156us/step - loss: 0.5953 - accuracy: 0.6520 - val_loss: 0.5262 - val_accuracy: 0.7581\n",
      "Epoch 102/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.75 - 0s 160us/step - loss: 0.5773 - accuracy: 0.6800 - val_loss: 0.5269 - val_accuracy: 0.7581\n",
      "Epoch 103/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.75 - 0s 159us/step - loss: 0.5575 - accuracy: 0.7000 - val_loss: 0.5253 - val_accuracy: 0.7581\n",
      "Epoch 104/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4646 - accuracy: 0.87 - 0s 155us/step - loss: 0.5662 - accuracy: 0.7000 - val_loss: 0.5228 - val_accuracy: 0.7581\n",
      "Epoch 105/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.43 - 0s 157us/step - loss: 0.5616 - accuracy: 0.6760 - val_loss: 0.5205 - val_accuracy: 0.7581\n",
      "Epoch 106/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.87 - 0s 146us/step - loss: 0.5982 - accuracy: 0.7520 - val_loss: 0.5196 - val_accuracy: 0.7581\n",
      "Epoch 107/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.81 - 0s 147us/step - loss: 0.5847 - accuracy: 0.6800 - val_loss: 0.5199 - val_accuracy: 0.7581\n",
      "Epoch 108/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.62 - 0s 154us/step - loss: 0.5610 - accuracy: 0.7160 - val_loss: 0.5195 - val_accuracy: 0.7581\n",
      "Epoch 109/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.81 - 0s 142us/step - loss: 0.5960 - accuracy: 0.6520 - val_loss: 0.5200 - val_accuracy: 0.7581\n",
      "Epoch 110/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.93 - 0s 146us/step - loss: 0.5479 - accuracy: 0.7560 - val_loss: 0.5180 - val_accuracy: 0.7581\n",
      "Epoch 111/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.62 - 0s 143us/step - loss: 0.6144 - accuracy: 0.6880 - val_loss: 0.5179 - val_accuracy: 0.7581\n",
      "Epoch 112/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.68 - 0s 145us/step - loss: 0.6156 - accuracy: 0.6720 - val_loss: 0.5191 - val_accuracy: 0.7581\n",
      "Epoch 113/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.75 - 0s 151us/step - loss: 0.5690 - accuracy: 0.7040 - val_loss: 0.5191 - val_accuracy: 0.7581\n",
      "Epoch 114/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.68 - 0s 150us/step - loss: 0.5598 - accuracy: 0.7040 - val_loss: 0.5183 - val_accuracy: 0.7581\n",
      "Epoch 115/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8045 - accuracy: 0.56 - 0s 157us/step - loss: 0.6056 - accuracy: 0.7160 - val_loss: 0.5193 - val_accuracy: 0.7581\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.5173 - accuracy: 0.75 - 0s 165us/step - loss: 0.5599 - accuracy: 0.7080 - val_loss: 0.5192 - val_accuracy: 0.7581\n",
      "Epoch 117/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.68 - 0s 163us/step - loss: 0.6112 - accuracy: 0.6680 - val_loss: 0.5200 - val_accuracy: 0.7581\n",
      "Epoch 118/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.87 - 0s 155us/step - loss: 0.5717 - accuracy: 0.7040 - val_loss: 0.5192 - val_accuracy: 0.7581\n",
      "Epoch 119/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.93 - 0s 149us/step - loss: 0.5399 - accuracy: 0.7520 - val_loss: 0.5202 - val_accuracy: 0.7581\n",
      "Epoch 120/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.75 - 0s 149us/step - loss: 0.5773 - accuracy: 0.7280 - val_loss: 0.5188 - val_accuracy: 0.7581\n",
      "Epoch 121/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.56 - 0s 147us/step - loss: 0.5724 - accuracy: 0.6840 - val_loss: 0.5187 - val_accuracy: 0.7581\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "250/250 [==============================] - ETA: 4s - loss: 1.2727 - accuracy: 0.37 - 0s 2ms/step - loss: 1.0769 - accuracy: 0.5400 - val_loss: 0.6927 - val_accuracy: 0.5161\n",
      "Epoch 2/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7854 - accuracy: 0.50 - 0s 112us/step - loss: 1.0163 - accuracy: 0.5280 - val_loss: 0.6615 - val_accuracy: 0.5806\n",
      "Epoch 3/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.6586 - accuracy: 0.50 - 0s 119us/step - loss: 1.2794 - accuracy: 0.5120 - val_loss: 0.6416 - val_accuracy: 0.7097\n",
      "Epoch 4/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7709 - accuracy: 0.56 - 0s 130us/step - loss: 1.0917 - accuracy: 0.5120 - val_loss: 0.6255 - val_accuracy: 0.6935\n",
      "Epoch 5/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.62 - 0s 146us/step - loss: 0.9202 - accuracy: 0.5280 - val_loss: 0.6162 - val_accuracy: 0.7097\n",
      "Epoch 6/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8792 - accuracy: 0.56 - 0s 151us/step - loss: 0.9603 - accuracy: 0.5400 - val_loss: 0.6127 - val_accuracy: 0.6774\n",
      "Epoch 7/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7675 - accuracy: 0.56 - 0s 142us/step - loss: 1.0115 - accuracy: 0.5400 - val_loss: 0.6096 - val_accuracy: 0.6613\n",
      "Epoch 8/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8686 - accuracy: 0.56 - 0s 148us/step - loss: 0.7589 - accuracy: 0.5800 - val_loss: 0.6085 - val_accuracy: 0.6613\n",
      "Epoch 9/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.0853 - accuracy: 0.37 - 0s 153us/step - loss: 0.9157 - accuracy: 0.5280 - val_loss: 0.6042 - val_accuracy: 0.6613\n",
      "Epoch 10/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8815 - accuracy: 0.68 - 0s 151us/step - loss: 0.7440 - accuracy: 0.6120 - val_loss: 0.6004 - val_accuracy: 0.6613\n",
      "Epoch 11/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8151 - accuracy: 0.62 - 0s 148us/step - loss: 0.8576 - accuracy: 0.5480 - val_loss: 0.5983 - val_accuracy: 0.6613\n",
      "Epoch 12/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7474 - accuracy: 0.50 - 0s 149us/step - loss: 0.8147 - accuracy: 0.5280 - val_loss: 0.5972 - val_accuracy: 0.6774\n",
      "Epoch 13/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.50 - 0s 155us/step - loss: 0.8114 - accuracy: 0.5680 - val_loss: 0.5939 - val_accuracy: 0.6774\n",
      "Epoch 14/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.50 - 0s 155us/step - loss: 0.6973 - accuracy: 0.6680 - val_loss: 0.5903 - val_accuracy: 0.6613\n",
      "Epoch 15/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7116 - accuracy: 0.56 - 0s 154us/step - loss: 0.7796 - accuracy: 0.5920 - val_loss: 0.5866 - val_accuracy: 0.6613\n",
      "Epoch 16/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.68 - 0s 153us/step - loss: 0.7749 - accuracy: 0.5640 - val_loss: 0.5826 - val_accuracy: 0.6613\n",
      "Epoch 17/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7638 - accuracy: 0.62 - 0s 154us/step - loss: 0.7422 - accuracy: 0.5920 - val_loss: 0.5784 - val_accuracy: 0.6613\n",
      "Epoch 18/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.68 - 0s 153us/step - loss: 0.7899 - accuracy: 0.5600 - val_loss: 0.5799 - val_accuracy: 0.6774\n",
      "Epoch 19/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.50 - 0s 159us/step - loss: 0.7561 - accuracy: 0.6080 - val_loss: 0.5795 - val_accuracy: 0.6935\n",
      "Epoch 20/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.43 - 0s 160us/step - loss: 0.7418 - accuracy: 0.6160 - val_loss: 0.5801 - val_accuracy: 0.7097\n",
      "Epoch 21/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.9907 - accuracy: 0.25 - 0s 157us/step - loss: 0.7269 - accuracy: 0.5920 - val_loss: 0.5828 - val_accuracy: 0.7097\n",
      "Epoch 22/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7986 - accuracy: 0.50 - 0s 152us/step - loss: 0.7479 - accuracy: 0.5800 - val_loss: 0.5823 - val_accuracy: 0.7097\n",
      "Epoch 23/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.75 - 0s 150us/step - loss: 0.6597 - accuracy: 0.6080 - val_loss: 0.5825 - val_accuracy: 0.7097\n",
      "Epoch 24/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.81 - 0s 158us/step - loss: 0.7609 - accuracy: 0.5800 - val_loss: 0.5837 - val_accuracy: 0.7097\n",
      "Epoch 25/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0.75 - 0s 162us/step - loss: 0.7348 - accuracy: 0.6240 - val_loss: 0.5847 - val_accuracy: 0.7419\n",
      "Epoch 26/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.56 - 0s 151us/step - loss: 0.7105 - accuracy: 0.5880 - val_loss: 0.5844 - val_accuracy: 0.7419\n",
      "Epoch 27/10000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7714 - accuracy: 0.50 - 0s 157us/step - loss: 0.6832 - accuracy: 0.5720 - val_loss: 0.5847 - val_accuracy: 0.7581\n",
      "NN has optimized parameters\n",
      "NN: {'learning_rate': 0.001, 'input_shape': 30, 'input_dropout': 0.6390508031418598, 'hidden_layers': 2, 'hidden_units': 56, 'hidden_dropout': 0.8863564940982054, 'batch_norm': 'non', 'batch_size': 32, 'epochs': 10000}\n",
      "------------------------------------------------------------------------------------------------\n",
      "Train on 248 samples, validate on 63 samples\n",
      "Epoch 1/10000\n",
      "248/248 [==============================] - ETA: 1s - loss: 2.7932 - accuracy: 0.46 - 0s 2ms/step - loss: 2.7829 - accuracy: 0.4839 - val_loss: 0.6783 - val_accuracy: 0.6349\n",
      "Epoch 2/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.3847 - accuracy: 0.68 - 0s 68us/step - loss: 2.6406 - accuracy: 0.5040 - val_loss: 0.6775 - val_accuracy: 0.6667\n",
      "Epoch 3/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.8965 - accuracy: 0.46 - 0s 77us/step - loss: 2.2986 - accuracy: 0.4919 - val_loss: 0.6767 - val_accuracy: 0.6349\n",
      "Epoch 4/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.7271 - accuracy: 0.62 - 0s 86us/step - loss: 2.1263 - accuracy: 0.5282 - val_loss: 0.6748 - val_accuracy: 0.6349\n",
      "Epoch 5/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.7550 - accuracy: 0.37 - 0s 94us/step - loss: 2.5434 - accuracy: 0.4677 - val_loss: 0.6723 - val_accuracy: 0.6984\n",
      "Epoch 6/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.3940 - accuracy: 0.50 - 0s 94us/step - loss: 2.4095 - accuracy: 0.4798 - val_loss: 0.6698 - val_accuracy: 0.6984\n",
      "Epoch 7/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.1473 - accuracy: 0.43 - 0s 93us/step - loss: 2.1483 - accuracy: 0.4839 - val_loss: 0.6665 - val_accuracy: 0.6825\n",
      "Epoch 8/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.7320 - accuracy: 0.59 - 0s 98us/step - loss: 2.7199 - accuracy: 0.5040 - val_loss: 0.6640 - val_accuracy: 0.6825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.9480 - accuracy: 0.59 - 0s 99us/step - loss: 2.4928 - accuracy: 0.4556 - val_loss: 0.6606 - val_accuracy: 0.6667\n",
      "Epoch 10/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.2046 - accuracy: 0.56 - 0s 99us/step - loss: 2.1130 - accuracy: 0.5161 - val_loss: 0.6588 - val_accuracy: 0.6825\n",
      "Epoch 11/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.7306 - accuracy: 0.56 - 0s 97us/step - loss: 2.3928 - accuracy: 0.5081 - val_loss: 0.6568 - val_accuracy: 0.6825\n",
      "Epoch 12/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.6393 - accuracy: 0.53 - 0s 96us/step - loss: 2.3703 - accuracy: 0.4919 - val_loss: 0.6560 - val_accuracy: 0.6825\n",
      "Epoch 13/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.3455 - accuracy: 0.37 - 0s 94us/step - loss: 1.6710 - accuracy: 0.5202 - val_loss: 0.6542 - val_accuracy: 0.6825\n",
      "Epoch 14/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.4322 - accuracy: 0.50 - 0s 95us/step - loss: 2.2384 - accuracy: 0.4960 - val_loss: 0.6527 - val_accuracy: 0.6984\n",
      "Epoch 15/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.3732 - accuracy: 0.62 - 0s 93us/step - loss: 2.0097 - accuracy: 0.5403 - val_loss: 0.6533 - val_accuracy: 0.6984\n",
      "Epoch 16/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.4891 - accuracy: 0.46 - 0s 99us/step - loss: 2.2234 - accuracy: 0.4879 - val_loss: 0.6525 - val_accuracy: 0.6984\n",
      "Epoch 17/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.4441 - accuracy: 0.50 - 0s 102us/step - loss: 1.6070 - accuracy: 0.5444 - val_loss: 0.6519 - val_accuracy: 0.6825\n",
      "Epoch 18/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.9858 - accuracy: 0.65 - 0s 100us/step - loss: 1.8454 - accuracy: 0.5323 - val_loss: 0.6517 - val_accuracy: 0.6984\n",
      "Epoch 19/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.4747 - accuracy: 0.46 - 0s 95us/step - loss: 2.0151 - accuracy: 0.5040 - val_loss: 0.6510 - val_accuracy: 0.7143\n",
      "Epoch 20/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 4.1101 - accuracy: 0.53 - 0s 97us/step - loss: 1.9763 - accuracy: 0.5121 - val_loss: 0.6505 - val_accuracy: 0.7302\n",
      "Epoch 21/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.7958 - accuracy: 0.53 - 0s 98us/step - loss: 1.7351 - accuracy: 0.5444 - val_loss: 0.6508 - val_accuracy: 0.7302\n",
      "Epoch 22/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.0800 - accuracy: 0.53 - 0s 96us/step - loss: 1.5375 - accuracy: 0.5282 - val_loss: 0.6516 - val_accuracy: 0.7143\n",
      "Epoch 23/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.8505 - accuracy: 0.56 - 0s 95us/step - loss: 1.6477 - accuracy: 0.5242 - val_loss: 0.6529 - val_accuracy: 0.6984\n",
      "Epoch 24/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.1329 - accuracy: 0.56 - 0s 94us/step - loss: 1.4829 - accuracy: 0.4960 - val_loss: 0.6545 - val_accuracy: 0.6984\n",
      "Epoch 25/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.7967 - accuracy: 0.40 - 0s 100us/step - loss: 1.8182 - accuracy: 0.4637 - val_loss: 0.6561 - val_accuracy: 0.7143\n",
      "Epoch 26/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.8366 - accuracy: 0.50 - 0s 102us/step - loss: 1.6633 - accuracy: 0.5282 - val_loss: 0.6578 - val_accuracy: 0.7143\n",
      "Epoch 27/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.5442 - accuracy: 0.50 - 0s 107us/step - loss: 1.6948 - accuracy: 0.4879 - val_loss: 0.6587 - val_accuracy: 0.6984\n",
      "Epoch 28/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.2918 - accuracy: 0.56 - 0s 99us/step - loss: 1.3745 - accuracy: 0.5000 - val_loss: 0.6594 - val_accuracy: 0.6825\n",
      "Epoch 29/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 2.2418 - accuracy: 0.37 - 0s 98us/step - loss: 1.3598 - accuracy: 0.5081 - val_loss: 0.6599 - val_accuracy: 0.6825\n",
      "Epoch 30/10000\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.5799 - accuracy: 0.59 - 0s 98us/step - loss: 1.6436 - accuracy: 0.4879 - val_loss: 0.6601 - val_accuracy: 0.6825\n",
      "Train on 249 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - ETA: 1s - loss: 1.8290 - accuracy: 0.56 - 0s 2ms/step - loss: 2.2525 - accuracy: 0.5060 - val_loss: 0.6664 - val_accuracy: 0.6290\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.7069 - accuracy: 0.46 - 0s 68us/step - loss: 2.6370 - accuracy: 0.5020 - val_loss: 0.6460 - val_accuracy: 0.6129\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.9024 - accuracy: 0.37 - 0s 75us/step - loss: 2.4822 - accuracy: 0.4859 - val_loss: 0.6331 - val_accuracy: 0.6129\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.2810 - accuracy: 0.68 - 0s 74us/step - loss: 2.3772 - accuracy: 0.5100 - val_loss: 0.6220 - val_accuracy: 0.6613\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.9602 - accuracy: 0.46 - 0s 86us/step - loss: 2.1896 - accuracy: 0.4940 - val_loss: 0.6130 - val_accuracy: 0.6774\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.5652 - accuracy: 0.46 - 0s 90us/step - loss: 2.4100 - accuracy: 0.4900 - val_loss: 0.6085 - val_accuracy: 0.6613\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.9512 - accuracy: 0.40 - 0s 93us/step - loss: 2.6157 - accuracy: 0.4458 - val_loss: 0.6039 - val_accuracy: 0.6613\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.7103 - accuracy: 0.43 - 0s 93us/step - loss: 2.2057 - accuracy: 0.5181 - val_loss: 0.5998 - val_accuracy: 0.6774\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.3943 - accuracy: 0.46 - 0s 95us/step - loss: 2.1660 - accuracy: 0.5100 - val_loss: 0.5981 - val_accuracy: 0.6935\n",
      "Epoch 10/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.9749 - accuracy: 0.37 - 0s 95us/step - loss: 2.3041 - accuracy: 0.5141 - val_loss: 0.5951 - val_accuracy: 0.7097\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.9006 - accuracy: 0.34 - 0s 97us/step - loss: 2.4364 - accuracy: 0.4498 - val_loss: 0.5943 - val_accuracy: 0.7258\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8323 - accuracy: 0.62 - 0s 96us/step - loss: 1.7437 - accuracy: 0.5261 - val_loss: 0.5941 - val_accuracy: 0.7258\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6879 - accuracy: 0.65 - 0s 92us/step - loss: 2.0038 - accuracy: 0.5261 - val_loss: 0.5945 - val_accuracy: 0.7258\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6071 - accuracy: 0.46 - 0s 102us/step - loss: 2.0100 - accuracy: 0.4900 - val_loss: 0.5957 - val_accuracy: 0.7419\n",
      "Epoch 15/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.2271 - accuracy: 0.46 - 0s 99us/step - loss: 1.8951 - accuracy: 0.4940 - val_loss: 0.5968 - val_accuracy: 0.7419\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6061 - accuracy: 0.50 - 0s 103us/step - loss: 1.8449 - accuracy: 0.4819 - val_loss: 0.5975 - val_accuracy: 0.7419\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.4605 - accuracy: 0.40 - 0s 100us/step - loss: 1.8007 - accuracy: 0.5382 - val_loss: 0.5980 - val_accuracy: 0.7742\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4474 - accuracy: 0.59 - 0s 102us/step - loss: 1.8112 - accuracy: 0.5181 - val_loss: 0.6000 - val_accuracy: 0.7903\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5751 - accuracy: 0.62 - 0s 102us/step - loss: 1.7955 - accuracy: 0.4859 - val_loss: 0.6030 - val_accuracy: 0.7742\n",
      "Epoch 20/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.1670 - accuracy: 0.43 - 0s 103us/step - loss: 1.8814 - accuracy: 0.5341 - val_loss: 0.6036 - val_accuracy: 0.7903\n",
      "Epoch 21/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6647 - accuracy: 0.50 - 0s 98us/step - loss: 1.7114 - accuracy: 0.5100 - val_loss: 0.6050 - val_accuracy: 0.7903\n",
      "Epoch 22/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - ETA: 0s - loss: 2.2892 - accuracy: 0.56 - 0s 104us/step - loss: 1.8145 - accuracy: 0.5181 - val_loss: 0.6065 - val_accuracy: 0.7903\n",
      "Train on 249 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - ETA: 2s - loss: 2.5004 - accuracy: 0.40 - 0s 2ms/step - loss: 2.3698 - accuracy: 0.4980 - val_loss: 0.6965 - val_accuracy: 0.5161\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.4750 - accuracy: 0.46 - 0s 70us/step - loss: 2.3037 - accuracy: 0.5060 - val_loss: 0.6848 - val_accuracy: 0.5323\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.8791 - accuracy: 0.53 - 0s 70us/step - loss: 2.5445 - accuracy: 0.4940 - val_loss: 0.6749 - val_accuracy: 0.5323\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4048 - accuracy: 0.56 - 0s 84us/step - loss: 2.4807 - accuracy: 0.5422 - val_loss: 0.6666 - val_accuracy: 0.5161\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.0774 - accuracy: 0.62 - 0s 85us/step - loss: 2.4305 - accuracy: 0.5181 - val_loss: 0.6592 - val_accuracy: 0.5645\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.7841 - accuracy: 0.53 - 0s 95us/step - loss: 2.0781 - accuracy: 0.4940 - val_loss: 0.6519 - val_accuracy: 0.5968\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.9505 - accuracy: 0.50 - 0s 93us/step - loss: 2.1397 - accuracy: 0.5382 - val_loss: 0.6477 - val_accuracy: 0.6129\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.53 - 0s 96us/step - loss: 2.1237 - accuracy: 0.5382 - val_loss: 0.6447 - val_accuracy: 0.6452\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6665 - accuracy: 0.50 - 0s 91us/step - loss: 1.9677 - accuracy: 0.5100 - val_loss: 0.6442 - val_accuracy: 0.6613\n",
      "Epoch 10/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3241 - accuracy: 0.59 - 0s 97us/step - loss: 2.3051 - accuracy: 0.5261 - val_loss: 0.6429 - val_accuracy: 0.6613\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4943 - accuracy: 0.50 - 0s 92us/step - loss: 1.7279 - accuracy: 0.4940 - val_loss: 0.6403 - val_accuracy: 0.6774\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.9517 - accuracy: 0.53 - 0s 98us/step - loss: 2.0741 - accuracy: 0.5141 - val_loss: 0.6376 - val_accuracy: 0.7097\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5849 - accuracy: 0.50 - 0s 92us/step - loss: 1.8911 - accuracy: 0.5301 - val_loss: 0.6367 - val_accuracy: 0.7097\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6802 - accuracy: 0.56 - 0s 96us/step - loss: 2.1552 - accuracy: 0.5141 - val_loss: 0.6350 - val_accuracy: 0.7097\n",
      "Epoch 15/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7992 - accuracy: 0.75 - 0s 98us/step - loss: 1.9881 - accuracy: 0.5141 - val_loss: 0.6335 - val_accuracy: 0.7097\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.2690 - accuracy: 0.50 - 0s 98us/step - loss: 1.9951 - accuracy: 0.5060 - val_loss: 0.6321 - val_accuracy: 0.7258\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.9257 - accuracy: 0.53 - 0s 96us/step - loss: 1.9461 - accuracy: 0.4779 - val_loss: 0.6310 - val_accuracy: 0.7258\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8406 - accuracy: 0.56 - 0s 95us/step - loss: 1.5968 - accuracy: 0.5582 - val_loss: 0.6301 - val_accuracy: 0.7581\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4095 - accuracy: 0.53 - 0s 94us/step - loss: 1.7594 - accuracy: 0.5060 - val_loss: 0.6285 - val_accuracy: 0.7742\n",
      "Epoch 20/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0477 - accuracy: 0.68 - 0s 99us/step - loss: 1.7289 - accuracy: 0.5221 - val_loss: 0.6265 - val_accuracy: 0.7581\n",
      "Epoch 21/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3248 - accuracy: 0.50 - 0s 101us/step - loss: 1.4535 - accuracy: 0.5783 - val_loss: 0.6257 - val_accuracy: 0.7742\n",
      "Epoch 22/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4405 - accuracy: 0.50 - 0s 100us/step - loss: 1.5255 - accuracy: 0.5582 - val_loss: 0.6255 - val_accuracy: 0.7742\n",
      "Epoch 23/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6979 - accuracy: 0.46 - 0s 119us/step - loss: 1.8006 - accuracy: 0.5020 - val_loss: 0.6250 - val_accuracy: 0.7581\n",
      "Epoch 24/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8148 - accuracy: 0.50 - 0s 107us/step - loss: 1.7793 - accuracy: 0.5422 - val_loss: 0.6252 - val_accuracy: 0.7581\n",
      "Epoch 25/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.2075 - accuracy: 0.59 - 0s 106us/step - loss: 1.7283 - accuracy: 0.4739 - val_loss: 0.6252 - val_accuracy: 0.7581\n",
      "Epoch 26/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.68 - 0s 101us/step - loss: 1.3465 - accuracy: 0.5863 - val_loss: 0.6263 - val_accuracy: 0.7581\n",
      "Epoch 27/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.0568 - accuracy: 0.56 - 0s 102us/step - loss: 1.5194 - accuracy: 0.5382 - val_loss: 0.6276 - val_accuracy: 0.7581\n",
      "Epoch 28/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.9976 - accuracy: 0.46 - 0s 93us/step - loss: 1.8080 - accuracy: 0.4739 - val_loss: 0.6284 - val_accuracy: 0.7581\n",
      "Epoch 29/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3416 - accuracy: 0.53 - 0s 93us/step - loss: 1.1735 - accuracy: 0.5622 - val_loss: 0.6283 - val_accuracy: 0.7419\n",
      "Epoch 30/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.65 - 0s 96us/step - loss: 1.2828 - accuracy: 0.5020 - val_loss: 0.6280 - val_accuracy: 0.7258\n",
      "Epoch 31/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6261 - accuracy: 0.62 - 0s 104us/step - loss: 1.2429 - accuracy: 0.5582 - val_loss: 0.6278 - val_accuracy: 0.7258\n",
      "Epoch 32/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.2407 - accuracy: 0.46 - 0s 107us/step - loss: 1.2811 - accuracy: 0.5542 - val_loss: 0.6281 - val_accuracy: 0.7419\n",
      "Epoch 33/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.1826 - accuracy: 0.43 - 0s 111us/step - loss: 1.3335 - accuracy: 0.5341 - val_loss: 0.6288 - val_accuracy: 0.7581\n",
      "Train on 249 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - ETA: 2s - loss: 2.8338 - accuracy: 0.43 - 0s 2ms/step - loss: 2.7288 - accuracy: 0.4659 - val_loss: 0.7459 - val_accuracy: 0.5645\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 4.6344 - accuracy: 0.43 - 0s 66us/step - loss: 2.9820 - accuracy: 0.5060 - val_loss: 0.7342 - val_accuracy: 0.5645\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.0565 - accuracy: 0.37 - 0s 71us/step - loss: 2.0283 - accuracy: 0.5582 - val_loss: 0.7260 - val_accuracy: 0.5806\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.7064 - accuracy: 0.50 - 0s 84us/step - loss: 2.5740 - accuracy: 0.4699 - val_loss: 0.7174 - val_accuracy: 0.5968\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.1526 - accuracy: 0.37 - 0s 82us/step - loss: 1.6912 - accuracy: 0.5221 - val_loss: 0.7083 - val_accuracy: 0.5968\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.1711 - accuracy: 0.56 - 0s 89us/step - loss: 2.6507 - accuracy: 0.4578 - val_loss: 0.6997 - val_accuracy: 0.6129\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 0.62 - 0s 99us/step - loss: 1.9486 - accuracy: 0.5422 - val_loss: 0.6913 - val_accuracy: 0.6290\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5681 - accuracy: 0.62 - 0s 95us/step - loss: 1.9639 - accuracy: 0.5341 - val_loss: 0.6833 - val_accuracy: 0.6290\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.4748 - accuracy: 0.50 - 0s 95us/step - loss: 2.1335 - accuracy: 0.4859 - val_loss: 0.6788 - val_accuracy: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.9596 - accuracy: 0.40 - 0s 96us/step - loss: 2.3518 - accuracy: 0.4940 - val_loss: 0.6751 - val_accuracy: 0.6290\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3357 - accuracy: 0.37 - 0s 90us/step - loss: 1.8297 - accuracy: 0.4819 - val_loss: 0.6718 - val_accuracy: 0.6290\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.1169 - accuracy: 0.53 - 0s 97us/step - loss: 1.8463 - accuracy: 0.5462 - val_loss: 0.6675 - val_accuracy: 0.6290\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.3962 - accuracy: 0.68 - 0s 101us/step - loss: 2.0671 - accuracy: 0.4980 - val_loss: 0.6636 - val_accuracy: 0.6613\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.0711 - accuracy: 0.37 - 0s 104us/step - loss: 1.6466 - accuracy: 0.4900 - val_loss: 0.6603 - val_accuracy: 0.6774\n",
      "Epoch 15/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.2194 - accuracy: 0.40 - 0s 104us/step - loss: 2.0821 - accuracy: 0.4900 - val_loss: 0.6585 - val_accuracy: 0.6774\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8660 - accuracy: 0.62 - 0s 106us/step - loss: 1.8427 - accuracy: 0.5100 - val_loss: 0.6563 - val_accuracy: 0.6613\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.0509 - accuracy: 0.53 - 0s 103us/step - loss: 1.9308 - accuracy: 0.4980 - val_loss: 0.6548 - val_accuracy: 0.6613\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.5868 - accuracy: 0.40 - 0s 104us/step - loss: 1.8510 - accuracy: 0.5582 - val_loss: 0.6535 - val_accuracy: 0.6613\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.9753 - accuracy: 0.56 - 0s 102us/step - loss: 1.9854 - accuracy: 0.5221 - val_loss: 0.6520 - val_accuracy: 0.6613\n",
      "Epoch 20/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8522 - accuracy: 0.56 - 0s 109us/step - loss: 1.4786 - accuracy: 0.5783 - val_loss: 0.6510 - val_accuracy: 0.6774\n",
      "Epoch 21/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3229 - accuracy: 0.53 - 0s 117us/step - loss: 1.5871 - accuracy: 0.5141 - val_loss: 0.6509 - val_accuracy: 0.6774\n",
      "Epoch 22/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.50 - 0s 103us/step - loss: 1.6230 - accuracy: 0.5221 - val_loss: 0.6513 - val_accuracy: 0.6774\n",
      "Epoch 23/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.6249 - accuracy: 0.37 - 0s 104us/step - loss: 1.6960 - accuracy: 0.4659 - val_loss: 0.6523 - val_accuracy: 0.6613\n",
      "Epoch 24/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.2430 - accuracy: 0.53 - 0s 101us/step - loss: 1.1964 - accuracy: 0.5341 - val_loss: 0.6529 - val_accuracy: 0.6613\n",
      "Epoch 25/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4154 - accuracy: 0.53 - 0s 101us/step - loss: 1.5750 - accuracy: 0.4699 - val_loss: 0.6528 - val_accuracy: 0.6452\n",
      "Epoch 26/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5893 - accuracy: 0.53 - 0s 109us/step - loss: 1.6403 - accuracy: 0.4940 - val_loss: 0.6529 - val_accuracy: 0.6613\n",
      "Epoch 27/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.3257 - accuracy: 0.37 - 0s 105us/step - loss: 1.6605 - accuracy: 0.5141 - val_loss: 0.6532 - val_accuracy: 0.6452\n",
      "Epoch 28/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.2846 - accuracy: 0.37 - 0s 110us/step - loss: 1.6114 - accuracy: 0.4498 - val_loss: 0.6542 - val_accuracy: 0.6452\n",
      "Epoch 29/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.3148 - accuracy: 0.40 - 0s 108us/step - loss: 1.4002 - accuracy: 0.5100 - val_loss: 0.6545 - val_accuracy: 0.6774\n",
      "Epoch 30/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.5152 - accuracy: 0.56 - 0s 110us/step - loss: 1.1670 - accuracy: 0.5582 - val_loss: 0.6551 - val_accuracy: 0.6935\n",
      "Epoch 31/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.7383 - accuracy: 0.56 - 0s 128us/step - loss: 1.2142 - accuracy: 0.5382 - val_loss: 0.6556 - val_accuracy: 0.6774\n",
      "Train on 249 samples, validate on 62 samples\n",
      "Epoch 1/10000\n",
      "249/249 [==============================] - ETA: 2s - loss: 1.7120 - accuracy: 0.53 - 1s 2ms/step - loss: 2.3328 - accuracy: 0.4900 - val_loss: 0.5773 - val_accuracy: 0.7097\n",
      "Epoch 2/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6754 - accuracy: 0.68 - 0s 78us/step - loss: 2.2998 - accuracy: 0.5382 - val_loss: 0.5753 - val_accuracy: 0.7097\n",
      "Epoch 3/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.0879 - accuracy: 0.46 - 0s 90us/step - loss: 2.4452 - accuracy: 0.4940 - val_loss: 0.5729 - val_accuracy: 0.7097\n",
      "Epoch 4/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.4249 - accuracy: 0.40 - 0s 103us/step - loss: 2.7246 - accuracy: 0.4940 - val_loss: 0.5704 - val_accuracy: 0.7097\n",
      "Epoch 5/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4883 - accuracy: 0.59 - 0s 122us/step - loss: 2.1869 - accuracy: 0.5542 - val_loss: 0.5681 - val_accuracy: 0.7097\n",
      "Epoch 6/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.56 - 0s 115us/step - loss: 2.2025 - accuracy: 0.5020 - val_loss: 0.5629 - val_accuracy: 0.7258\n",
      "Epoch 7/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.6476 - accuracy: 0.50 - 0s 117us/step - loss: 1.8071 - accuracy: 0.5502 - val_loss: 0.5591 - val_accuracy: 0.7419\n",
      "Epoch 8/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.9965 - accuracy: 0.43 - 0s 118us/step - loss: 2.1297 - accuracy: 0.5462 - val_loss: 0.5555 - val_accuracy: 0.7419\n",
      "Epoch 9/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.7168 - accuracy: 0.59 - 0s 112us/step - loss: 2.0030 - accuracy: 0.5462 - val_loss: 0.5527 - val_accuracy: 0.7419\n",
      "Epoch 10/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8698 - accuracy: 0.59 - 0s 108us/step - loss: 2.3301 - accuracy: 0.4980 - val_loss: 0.5539 - val_accuracy: 0.7258\n",
      "Epoch 11/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0861 - accuracy: 0.59 - 0s 106us/step - loss: 2.3144 - accuracy: 0.5181 - val_loss: 0.5550 - val_accuracy: 0.7258\n",
      "Epoch 12/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.3655 - accuracy: 0.53 - 0s 104us/step - loss: 2.0046 - accuracy: 0.5301 - val_loss: 0.5582 - val_accuracy: 0.7258\n",
      "Epoch 13/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.0951 - accuracy: 0.56 - 0s 108us/step - loss: 1.6872 - accuracy: 0.5020 - val_loss: 0.5612 - val_accuracy: 0.6935\n",
      "Epoch 14/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.8143 - accuracy: 0.75 - 0s 117us/step - loss: 1.5519 - accuracy: 0.5863 - val_loss: 0.5636 - val_accuracy: 0.6935\n",
      "Epoch 15/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.3461 - accuracy: 0.50 - 0s 110us/step - loss: 1.9534 - accuracy: 0.5341 - val_loss: 0.5654 - val_accuracy: 0.7097\n",
      "Epoch 16/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 2.8231 - accuracy: 0.43 - 0s 116us/step - loss: 2.0061 - accuracy: 0.5221 - val_loss: 0.5662 - val_accuracy: 0.7097\n",
      "Epoch 17/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.1306 - accuracy: 0.71 - 0s 148us/step - loss: 1.7441 - accuracy: 0.5502 - val_loss: 0.5658 - val_accuracy: 0.7097\n",
      "Epoch 18/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.8080 - accuracy: 0.53 - 0s 158us/step - loss: 1.5750 - accuracy: 0.5823 - val_loss: 0.5659 - val_accuracy: 0.7097\n",
      "Epoch 19/10000\n",
      "249/249 [==============================] - ETA: 0s - loss: 1.7119 - accuracy: 0.62 - 0s 156us/step - loss: 1.8201 - accuracy: 0.5141 - val_loss: 0.5674 - val_accuracy: 0.7097\n"
     ]
    }
   ],
   "source": [
    "%run -i pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
