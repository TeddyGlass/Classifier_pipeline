{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "Using TensorFlow backend.\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from utils import Paramset\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from neuralnetwork import NNClassifier\n",
    "import optuna\n",
    "\n",
    "\n",
    "class Objective:\n",
    "     \n",
    "    '''\n",
    "    # Usage\n",
    "    obj = Objective(LGBMRegressor(), X, y)\n",
    "    study = optuna.create_study(\n",
    "        sampler=optuna.samplers.RandomSampler(seed=123))\n",
    "    study.optimize(obj, n_trials=10, n_jobs=-1)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, x, y):\n",
    "        self.model = model\n",
    "        self.model_type = type(self.model).__name__\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_splits = 5\n",
    "        self.random_state = 1214\n",
    "        self.early_stopping_rounds = 20\n",
    "        paramset = Paramset(self.model)\n",
    "        paramset.swiching_lr('params_search')\n",
    "        self.PARAMS = paramset.generate_params()\n",
    "    \n",
    "    def __call__(self, trial):\n",
    "        if self.model_type == 'LGBMClassifier':\n",
    "            SPACE = {\n",
    "                'num_leaves': trial.suggest_int(\n",
    "                'num_leaves', 32, 2*32),\n",
    "                'subsample': trial.suggest_uniform('subsample', 0.60, 0.80),\n",
    "                'colsample_bytree': trial.suggest_uniform(\n",
    "                    'colsample_bytree', 0.60, 0.80),\n",
    "                'bagging_freq': trial.suggest_int(\n",
    "                    'bagging_freq', 1, 51, 5),\n",
    "                'min_child_weight': trial.suggest_loguniform(\n",
    "                    'min_child_weight', 1, 32),\n",
    "                'min_child_samples': int(trial.suggest_discrete_uniform(\n",
    "                    'min_child_samples', 128, 512, 16)),\n",
    "                'min_split_gain': trial.suggest_loguniform(\n",
    "                    'min_split_gain', 1e-5, 1e-1)\n",
    "            }\n",
    "            self.PARAMS.update(SPACE)\n",
    "            # cross validation\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits,\n",
    "            random_state=self.random_state, shuffle=True)\n",
    "            LOGLOSS = []\n",
    "            for tr_idx, va_idx in skf.split(self.x, self.y):\n",
    "                clf = Trainer(LGBMClassifier(**self.PARAMS))\n",
    "                clf.fit(\n",
    "                    self.x[tr_idx],\n",
    "                    self.y[tr_idx],\n",
    "                    self.x[va_idx],\n",
    "                    self.y[va_idx],\n",
    "                    self.early_stopping_rounds\n",
    "                )\n",
    "                y_pred = clf.predict_proba(self.x[va_idx])  # best_iteration\n",
    "                logloss = log_loss(self.y[va_idx], y_pred)\n",
    "                LOGLOSS.append(logloss)\n",
    "            return np.mean(LOGLOSS)\n",
    "        elif self.model_type == 'XGBClassifier':\n",
    "            SPACE = {\n",
    "                'subsample': trial.suggest_uniform(\n",
    "                    'subsample', 0.65, 0.85),\n",
    "                'colsample_bytree': trial.suggest_uniform(\n",
    "                    'colsample_bytree', 0.65, 0.80),\n",
    "                'gamma': trial.suggest_loguniform(\n",
    "                    'gamma', 1e-8, 1.0),\n",
    "                'min_child_weight': trial.suggest_loguniform(\n",
    "                    'min_child_weight', 1, 32)\n",
    "            }\n",
    "            self.PARAMS.update(SPACE)\n",
    "            # cross validation\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits,\n",
    "            random_state=self.random_state, shuffle=True)\n",
    "            LOGLOSS = []\n",
    "            for tr_idx, va_idx in skf.split(self.x, self.y):\n",
    "                clf = Trainer(XGBClassifier(**self.PARAMS))\n",
    "                clf.fit(\n",
    "                    self.x[tr_idx],\n",
    "                    self.y[tr_idx],\n",
    "                    self.x[va_idx],\n",
    "                    self.y[va_idx],\n",
    "                    self.early_stopping_rounds\n",
    "                )\n",
    "                y_pred = clf.predict_proba(self.x[va_idx])  # best_iteration\n",
    "                logloss = log_loss(self.y[va_idx], y_pred)\n",
    "                LOGLOSS.append(logloss)\n",
    "            return np.mean(LOGLOSS)\n",
    "        elif self.model_type == 'NNClassifier':\n",
    "            SPACE = {\n",
    "                \"input_dropout\": trial.suggest_uniform(\n",
    "                    \"input_dropout\", 0.0, 1.0),\n",
    "                \"hidden_layers\": trial.suggest_int(\n",
    "                    \"hidden_layers\", 1, 3),\n",
    "                'hidden_units': int(trial.suggest_discrete_uniform(\n",
    "                    'hidden_units', 64, 1024, 64)),\n",
    "                'hidden_dropout': trial.suggest_uniform(\n",
    "                    'hidden_dropout', 0.0, 1.0),\n",
    "                'batch_norm': trial.suggest_categorical(\n",
    "                'batch_norm', ['before_act', 'non']),\n",
    "                'batch_size': int(trial.suggest_discrete_uniform(\n",
    "                    'batch_size', 16, 96, 16))\n",
    "            }\n",
    "            self.PARAMS.update(SPACE)\n",
    "            self.PARAMS['input_shape'] = self.x.shape[1]\n",
    "            print(self.PARAMS)\n",
    "            # cross validation\n",
    "            skf = StratifiedKFold(n_splits=self.n_splits,\n",
    "            random_state=self.random_state, shuffle=True)\n",
    "            LOGLOSS = []\n",
    "            for tr_idx, va_idx in skf.split(self.x, self.y):\n",
    "                clf = Trainer(NNClassifier(**self.PARAMS))\n",
    "                clf.fit(\n",
    "                    self.x[tr_idx],\n",
    "                    self.y[tr_idx],\n",
    "                    self.x[va_idx],\n",
    "                    self.y[va_idx],\n",
    "                    self.early_stopping_rounds\n",
    "                )\n",
    "                logloss = clf.get_model().history.history[\"val_loss\"][-(self.early_stopping_rounds+1)]\n",
    "                LOGLOSS.append(logloss)\n",
    "            return np.mean(LOGLOSS)\n",
    "            \n",
    "def optuna_search(obj, n_trials, n_jobs, random_state):\n",
    "    study = optuna.create_study(\n",
    "        sampler=optuna.samplers.RandomSampler(seed=random_state))\n",
    "    study.optimize(obj, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "brest_c = load_breast_cancer()\n",
    "X = brest_c['data']\n",
    "y = brest_c['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.5488135039273248, 'hidden_layers': 2, 'hidden_units': 896, 'hidden_dropout': 0.8579456176227568, 'batch_norm': 'non', 'batch_size': 48, 'epochs': 10000}{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.6458941130666561, 'hidden_layers': 1, 'hidden_units': 320, 'hidden_dropout': 0.05671297731744318, 'batch_norm': 'before_act', 'batch_size': 48, 'epochs': 10000}{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.7917250380826646, 'hidden_layers': 3, 'hidden_units': 640, 'hidden_dropout': 0.925596638292661, 'batch_norm': 'non', 'batch_size': 48, 'epochs': 10000}\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "455/455 [==============================] - ETA: 3s - loss: 4.8361 - accuracy: 0.56 - ETA: 0s - loss: 5.7334 - accuracy: 0.5833 - ETA: 4s - loss: 3.7293 - accuracy: 0.6042 - ETA: 4s - loss: 3.3208 - accuracy: 0.58 - ETA: 0s - loss: 6.0850 - accuracy: 0.52 - ETA: 0s - loss: 5.4256 - accuracy: 0.54 - ETA: 0s - loss: 5.6262 - accuracy: 0.58 - ETA: 0s - loss: 5.6096 - accuracy: 0.58 - 1s 2ms/step - loss: 6.0664 - accuracy: 0.5758 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 2/10000\n",
      " - 1s 2ms/step - loss: 5.8000 - accuracy: 0.5912 - val_loss: 6.0134 - val_accuracy: 0.6228==============================288/455 [=================>............]\n",
      " - ETA: 0s - loss: 5.3567 - accuracy: 0.6632455/455 [==============================] - 1s 2ms/step - loss: 5.8155 - accuracy: 0.5758 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 2/10000455/455 [==============================]Epoch 2/10000 - 0s 239us/step - loss: 5.7744 - accuracy: 0.6374 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "\n",
      "\n",
      " 48/455 [==>...........................]\n",
      "240/455 [==============>...............]5750 48/455 [==>...........................] - ETA: 0s - loss: 7.3106 - accuracy: 0.5417 - ETA: 0s - loss: 6.6500 - accuracy: 0 - ETA: 0s - loss: 5.8969 - accuracy: 0.6302240/455 [==============>...............]144/455 [========>.....................] - ETA: 0s - loss: 6.3178 - accuracy: 0. - ETA: 0s - loss: 7.0238 - accuracy: 0.5595336/455 [=====================>........] - ETA: 0s - loss: 5.6967 - accuracy: 0.64 - ETA: 0s - loss: 6.2492 - accuracy: 0384/455 [========================>.....] - ETA: 0s - loss: 6.1066 - accuracy: 0.6172455/455 [==============================]455/455 [==============================] - 0s 457us/step - loss: 5.7142 - accuracy: 0.6418 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - 0s 458us/step - loss: 6.8082 - accuracy: 0.5736 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 3/10000\n",
      "Epoch 3/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.3105 - accuracy: 0.6042 48/455 [==>...........................] - ETA: 0s - loss: 6.6756 - accuracy: 0.58 - 0s 523us/step - loss: 6.1005 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 4/10000\n",
      "455/455 [==============================]6042TA: 0s - loss: 5.6536 - accuracy: 0.6192/455 [===========>..................]192/455 [===========>..................] - ETA: 0s - loss: 6.9302 - accuracy: 0.56 - ETA: 0s - loss: 5.9036 - accuracy: 0.63336/455 [=====================>........]336/455 [=====================>........] - ETA: 0s - loss: 7.3346 - accuracy: 0.5417 - ETA: 0s - loss: 6.0796 - accuracy: 0.61 - ETA: 0s - loss: 6.1270 - accuracy: 0.61 - ETA: 0s - loss: 6.1682 - accuracy: 0.61 - 0s 446us/step - loss: 7.4597 - accuracy: 0.5341 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 4/10000\n",
      " 48/455 [==>...........................]455/455 [============================= - ETA: 0s - loss: 6.4511 - accuracy: 0.5833 - 0s 515us/step - loss: 6.1717 - accuracy: 0.6132 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 4/10000455/455 [==============================]\n",
      " - 0s 413us/step - loss: 6.2426 - accuracy: 0.6088 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 5/10000\n",
      "455/455 [==============================]5625455 [==>...........................] - ETA: 0s - loss: 6.6427 - accuracy: 0.5833 - ETA: 0s - loss: 8.3033 - accuracy: 0.47 - ETA: 0s - loss: 6.9672 - accuracy: 0.5144/455 [========>.....................]192/455 [===========>..................] - ETA: 0s - loss: 6.2339 - accuracy: 0.60 - ETA: 0s - loss: 7.1595 - accuracy: 0.55 - ETA: 0s - loss: 6.3784 - accuracy: 0.60 - ETA: 0s - loss: 6.4112 - accuracy: 0.59 - 0s 432us/step - loss: 7.4523 - accuracy: 0.5341 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.1892 - accuracy: 0.6120 - ETA: 0s - loss: 8.6867 - accuracy: 0.45 - 0s 484us/step - loss: 6.1495 - accuracy: 0.6132 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================]Epoch 5/10000 - 0s 500us/step - loss: 5.9942 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 6/10000\n",
      " - ETA: 0s - loss: 6.3168 - accuracy: 0.6042TA: 0s - loss: 6.5660 - accuracy: 0.5885 48/455 [==>...........................] - ETA: 0s - loss: 5.6499 - accuracy: 0. - ETA: 0s - loss: 7.5038 - accuracy: 0.529192/455 [===========>..................] - ETA: 0s - loss: 5.9009 - accuracy: 0336/455 [=====================>........] - ETA: 0s - loss: 5.8408 - accuracy: 0.6339455/455 [==============================] - 0s 455us/step - loss: 7.5173 - accuracy: 0.5297 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 6/10000\n",
      " 48/455 [==>...........................] - ETA: 0s - loss: 9.3400 - accuracy: 0.41455/455 [==============================]455/455 [==============================] - 0s 504us/step - loss: 6.0655 - accuracy: 0.6198 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - 0s 488us/step - loss: 6.1729 - accuracy: 0.6132 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 6/100Epoch 7/10000\n",
      "\n",
      "455/455 [==============================] - ETA: 0s - loss: 8.3537 - accuracy: 0.4792 48/455 [==>...........................] 48/455 [==>...........................] - ETA: 0s - loss: 5.3178 - accuracy: 0.6667 - ETA: 0s - loss: 6.6427 - accuracy: 0.58 - ETA: 0s - loss: 7.6882 - accuracy: 0.52192/455 [===========>..................]192/455 [===========>..................] - ETA: 0s - loss: 6.0623 - accuracy: 0.6198 - ETA: 0s - loss: 5.9911 - accuracy: 0.61 - 0s 460us/step - loss: 7.7936 - accuracy: 0.5143 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 7/100\n",
      " - 0s 482us/step - loss: 6.1867 - accuracy: 0.6110 - val_loss: 6.0134 - val_accuracy: 0.6228 loss: 6.0044 - accuracy: 0.6220 - ETA: 0s - loss: 6.3663 - accuracy: 0.5982 - ETA: 0s - loss: 4.6791 - accuracy: 0. - ETA: 0s - loss: 5.8841 - accuracy: 0.63\n",
      "455/455 [==============================] - 0s 492us/step - loss: 6.0693 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 7/10000\n",
      "Epoch 8/10000\n",
      "455/455 [==============================] 48/455 [==>...........................] - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - ETA: 0s - loss: 7.6427 - accuracy: 0.5208 - ETA: 0s - loss: 6.4611 - accuracy: 0.59192/455 [===========>..................]192/455 [===========>..................] - ETA: 0s - loss: 6.7303 - accuracy: 0.5781 - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - 0s 407us/step - loss: 6.5452 - accuracy: 0.5890 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 8/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 8.0041 - accuracy: 0.50 - ETA: 0s - loss: 5.6968 - accuracy: 0.64 - ETA: 0s - loss: 6.4107 - accuracy: 0.59 - ETA: 0s - loss: 7.0032 - accuracy: 0.56 - ETA: 0s - loss: 5.9443 - accuracy: 0.62 - 0s 484us/step - loss: 6.0986 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      " 48/455 [==>...........................] - ETA: 0s - loss: 6.6699 - accuracy: 0.58 - ETA: 0s - loss: 8.3106 - accuracy: 0.4792455/455 [==============================] - 0s 545us/step - loss: 6.0994 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 8/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 4.9820 - accuracy: 0.68 - ETA: 0s - loss: 5.8151 - accuracy: 0.63 - 0s 469us/step - loss: 6.8599 - accuracy: 0.5714 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 9/10000\n",
      "455/455 [==============================] ETA: 0s - loss: 6.0040 - accuracy: 0.62192/455 [===========>..................]288/455 [=================>............] - ETA: 0s - loss: 5.8972 - accuracy: 0.6302 - ETA: 0s - loss: 5.8142 - accuracy: 0288/455 [=================>............] - ETA: 0s - loss: 5.6475 - accuracy: 0.6458384/455 [========================>.....]192/455 [===========>..................] - ETA: 0s - loss: 7.3390 - accuracy: 0.5417 - ETA: 0s - loss: 6.0637 - accuracy: 0.61288/455 [=================>............]384/455 [========================>.... - ETA: 0s - loss: 7.2815 - accuracy: 0.5451 - ETA: 0s - loss: 5.8963 - accuracy: 0.6302 - 0s 515us/step - loss: 6.0289 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 10/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - ETA: 0s - loss: 7.0853 - accuracy: 0.55 - 0s 598us/step - loss: 5.9580 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 9/10000\n",
      "455/455 [==============================] 48/455 [==>...........................] - ETA: 0s - loss: 7.9749 - accuracy: 0.5000 - ETA: 0s - loss: 6.1454 - accuracy: 0.61 - 0s 534us/step - loss: 7.1778 - accuracy: 0.5495 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 10/10000\n",
      "336/455 [=====================>........] - ETA: 0s - loss: 4.3397 - accuracy: 0.336/455 [=====================>........] - ETA: 0s - loss: 6.1490 - accuracy: 0.6146 - ETA: 0s - loss: 6.0274 - accuracy: 0.62 - ETA: 0s - loss: 6.0022 - accuracy: 0.62 - ETA: 0s - loss: 6.0295 - accuracy: 0.288/455 [=================>............]455/455 [==============================] - ETA: 0s - loss: 6.4979 - accuracy: 0.5938 - 0s 515us/step - loss: 5.9584 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 11/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - 0s 467us/step - loss: 6.0994 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 10/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6638 - accuracy: 0.5833 - ETA: 0s - loss: 6.6427 - accuracy: 0. - ETA: 0s - loss: 5.6508 - accuracy: 0.6458 - 0s 523us/step - loss: 6.6427 - accuracy: 0.5846 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 11/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9802 - accuracy: 0.6250 - ETA: 0s - loss: 7.6574 - accuracy: 0.52 - ETA: 0s - loss: 5.8882 - accuracy: 0.63 - ETA: 0s - loss: 6.1698 - accuracy: 0.61 - ETA: 0s - loss: 6.3261 - accuracy: 0.60 - ETA: 0s - loss: 5.9800 - accuracy: 0.6250 - 0s 523us/step - loss: 6.1355 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 12/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9456 - accuracy: 0.6280 - ETA: 0s - loss: 4.3177 - accuracy: 0.72 - 0s 513us/step - loss: 5.9931 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 11/10000\n",
      "455/455 [==============================] ETA: 0s - loss: 5.6463 - accuracy: 0.6458 - ETA: 0s - loss: 6.1398 - accuracy: 0.61 - ETA: 0s - loss: 5.1499 - accuracy: 0.67 - 0s 552us/step - loss: 6.0755 - accuracy: 0.6198 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "192/455 [===========>..................]Epoch 12/10000\n",
      "455/455 [==============================]604248/455 [==>...........................]336/455 [=====================>........] - ETA: 0s - loss: 5.1734 - accuracy: 0.67 - ETA: 0s - loss: 5.7966 - accuracy: 0.63 - ETA: 0s - loss: 6.4894 - accuracy: 0.59 - 0s 533us/step - loss: 5.9946 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 478us/step - loss: 5.9979 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 12/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6093 - accuracy: 0.5863 - ETA: 0s - loss: 5.9821 - accuracy: 0.6250 - ETA: 0s - loss: 5.9784 - accuracy: 0.62 - ETA: 0s - loss: 7.8678 - accuracy: 0.5192/455 [===========>..................] - ETA: 0s - loss: 6.0623 - accuracy: 0.6198 - 0s 502us/step - loss: 6.2854 - accuracy: 0.6066 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 13/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2144 - accuracy: 0.6094/455 [=================>............] - ETA: 0s - loss: 6.0903 - accuracy: 0.61 - ETA: 0s - loss: 6.8298 - accuracy: 0. - ETA: 0s - loss: 5.9383 - accuracy: 0.6336/455 [=====================>........] - ETA: 0s - loss: 6.6114 - accuracy: 0.58 - 0s 550us/step - loss: 5.9577 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 13/10000455/455 [==============================] - 0s 583us/step - loss: 6.2736 - accuracy: 0.6044 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 14/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6463 - accuracy: 0.5833 - ETA: 0s - loss: 6.9858 - accuracy: 0.56 - 0s 510us/step - loss: 6.4661 - accuracy: 0.5934 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 14/10000\n",
      "455/455 [==============================]6198 48/455 [==>...........................] - ETA: 0s - loss: 4.6645 - accuracy: 0. - ETA: 0s - loss: 5.9794 - accuracy: 0.62 - ETA: 0s - loss: 6.0374 - accuracy: 0.6215 - ETA: 0s - loss: 5.9918 - accuracy: 0.62 - ETA: 0s - loss: 6.0169 - accuracy: 0.62 - ETA: 0s - loss: 5.9825 - accuracy: 0.62 - ETA: 0s - loss: 5.7794 - accuracy: 0.63 - 0s 522us/step - loss: 5.9580 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 14/10000\n",
      "455/455 [==============================] - 0s 547us/step - loss: 6.0320 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 15/10000\n",
      "144/455 [========>.....................] - ETA: 0s - loss: 6.9748 - accuracy: 0.56 - ETA: 0s - loss: 5.5502 - accuracy: 0.6510 - ETA: 0s - loss: 6.3105 - accuracy: 0.60 - ETA: 0s - loss: 6.0891 - accuracy: 0.455/455 [==============================]144/455 [========>.....................] - ETA: 0s - loss: 6.0976 - accuracy: 0.6181 - 0s 584us/step - loss: 5.7380 - accuracy: 0.6396 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 15/10000\n",
      "455/455 [==============================]6806455 [==>...........................] - ETA: 0s - loss: 6.2448 - accuracy: 0.6083 - ETA: 0s - loss: 3.9929 - accuracy: 0.75 - ETA: 0s - loss: 6.2625 - accuracy: 0.336/455 [=====================>........] - ETA: 0s - loss: 5.9320 - accuracy: 0.62 - ETA: 0s - loss: 5.9853 - accuracy: 0.62 - ETA: 0s - loss: 5.9800 - accuracy: 0.62 - ETA: 0s - loss: 5.8787 - accuracy: 0.63 - 0s 520us/step - loss: 6.1036 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 16/10000\n",
      "455/455 [==============================] - 0s 604us/step - loss: 6.0281 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 15/10000\n",
      " 48/455 [==>...........................]] - ETA: 0s - loss: 7.3106 - accuracy: 0.5417 - ETA: 0s - loss: 5.9889 - accuracy: 0.6250 - ETA: 0s - loss: 5.3141 - accuracy: 0.455/455 [==============================]192/455 [===========>................. - ETA: 0s - loss: 6.2302 - accuracy: 0.6094 - 0s 564us/step - loss: 5.9323 - accuracy: 0.6286 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "192/455 [===========>..................]Epoch 16/10000 - ETA: 0s - loss: 5.8687 - accuracy: 0.6302\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6463 - accuracy: 0.58 - ETA: 0s - loss: 5.7392 - accuracy: 0.63 - ETA: 0s - loss: 6.4112 - accuracy: 0.59 - ETA: 0s - loss: 6.3676 - accuracy: 0.59 - ETA: 0s - loss: 5.9665 - accuracy: 0.62 - 0s 484us/step - loss: 6.2430 - accuracy: 0.6088 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 17/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2957 - accuracy: 0.60 - ETA: 0s - loss: 6.6536 - accuracy: 0.5833 - 0s 511us/step - loss: 5.8752 - accuracy: 0.6308 - val_loss: 6.0134 - val_accuracy: 0.6228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/10000\n",
      "455/455 [==============================]6250TA: 0s - loss: 5.9821 - accuracy: 0.6384/455 [========================>.....]144/455 [========>.....................] - ETA: 0s - loss: 6.3178 - accuracy: 0. - ETA: 0s - loss: 5.8142 - accuracy: 0.6354 - ETA: 0s - loss: 6.5850 - accuracy: 0.58 - 0s 589us/step - loss: 5.9502 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 17/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9930 - accuracy: 0.62 - ETA: 0s - loss: 5.9796 - accuracy: 0.62 - ETA: 0s - loss: 6.6523 - accuracy: 0.58 - ETA: 0s - loss: 6.9870 - accuracy: 0.56 - ETA: 0s - loss: 5.9054 - accuracy: 0.62 - 0s 559us/step - loss: 6.3512 - accuracy: 0.6022 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 18/100\n",
      " - 0s 540us/step - loss: 5.9573 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "288/455 [=================>............] - ETA: 0s - loss: 6.9316 - accuracy: 0.5660Epoch 17/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 4.9857 - accuracy: 0.6875 - ETA: 0s - loss: 6.6463 - accuracy: 0.432/455 [===========================>..]144/455 [========>.....................] - ETA: 0s - loss: 6.4347 - accuracy: 0.5972 - ETA: 0s - loss: 5.8726 - accuracy: 0.63 - ETA: 0s - loss: 5.9793 - accuracy: 0.62 - 0s 538us/step - loss: 6.3196 - accuracy: 0.6044 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 18/100\n",
      " - 0s 464us/step - loss: 5.8868 - accuracy: 0.6308 - val_loss: 6.0134 - val_accuracy: 0.62280s - loss: 6.9821 - accuracy: 0.56 - ETA: 0s - loss: 5.8840 - accuracy: 0.63 - ETA: 0s - loss: 6.2440 - accuracy: 0. - ETA: 0s - loss: 7.4128 - accuracy: 0.536455/455 [==============================]\n",
      "455/455 [==============================] - 0s 498us/step - loss: 6.2796 - accuracy: 0.6066 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 18/10000Epoch 19/10000\n",
      "\n",
      "455/455 [==============================]7083 48/455 [==>...........................] - ETA: 0s - loss: 5.6572 - accuracy: 0.64 - ETA: 0s - loss: 6.8982 - accuracy: 0. - ETA: 0s - loss: 5.3153 - accuracy: 0.6667 - ETA: 0s - loss: 5.7339 - accuracy: 0.64 - 0s 479us/step - loss: 6.8494 - accuracy: 0.5714 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 19/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.3288 - accuracy: 0.288/455 [=================>............]288/455 [=================>............] - ETA: 0s - loss: 5.9845 - accuracy: 0.6250 - ETA: 0s - loss: 6.0899 - accuracy: 0. - ETA: 0s - loss: 6.2120 - accuracy: 0.61 - ETA: 0s - loss: 6.1080 - accuracy: 0.6172 - ETA: 0s - loss: 5.9424 - accuracy: 0.62 - 0s 552us/step - loss: 5.9574 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 19/100288/455 [=================>............]\n",
      " - ETA: 0s - loss: 6.3233 - accuracy: 0.6042455/455 [==============================] - 0s 574us/step - loss: 6.2076 - accuracy: 0.6110 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 20/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9784 - accuracy: 0.6250 - ETA: 0s - loss: 7.6391 - accuracy: 0.52 - ETA: 0s - loss: 6.5835 - accuracy: 0.58 - ETA: 0s - loss: 6.0903 - accuracy: 0.6192/455 [===========>..................] - 0s 535us/step - loss: 6.4613 - accuracy: 0.5956 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 5.7320 - accuracy: 0.6406Epoch 20/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.7053 - accuracy: 0.6424 - ETA: 0s - loss: 6.9968 - accuracy: 0.56 - ETA: 0s - loss: 6.4107 - accuracy: 0.59 - ETA: 0s - loss: 6.0563 - accuracy: 0.62 - ETA: 0s - loss: 6.4940 - accuracy: 0.59 - 0s 493us/step - loss: 6.0304 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 20/10000\n",
      "455/455 [==============================] - 0s 503us/step - loss: 6.1371 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 21/10000\n",
      "455/455 [==============================]5972TA: 0s - loss: 6.5160 - accuracy: 0.5923 - ETA: 0s - loss: 6.9785 - accuracy: 0.5625 - ETA: 0s - loss: 5.3178 - accuracy: 0.66 - ETA: 0s - loss: 6.4363 - accuracy: 0.5144/455 [========>.....................]192/455 [===========>..................] - ETA: 0s - loss: 5.4857 - accuracy: 0.65 - 0s 487us/step - loss: 6.4629 - accuracy: 0.5956 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 21/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.0499 - accuracy: 0.62080/455 [==============>...............] - ETA: 0s - loss: 5.7612 - accuracy: 0.63336/455 [=====================>........]144/455 [========>.....................] - ETA: 0s - loss: 6.2203 - accuracy: 0.6101 - ETA: 0s - loss: 7.0977 - accuracy: 0.55 - ETA: 0s - loss: 5.9825 - accuracy: 0. - ETA: 0s - loss: 6.6551 - accuracy: 0.5833 - 0s 531us/step - loss: 5.9954 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 21/10000\n",
      "455/455 [==============================] - 0s 546us/step - loss: 6.3111 - accuracy: 0.6044 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================] - ETA: 0s - loss: 4.9893 - accuracy: 0.68 - ETA: 0s - loss: 6.6988 - accuracy: 0.58 - ETA: 0s - loss: 5.7330 - accuracy: 0.64 - 0s 548us/step - loss: 6.6206 - accuracy: 0.5846 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "model type is NNClassifier\n",
      "384/455 [========================>.....] - ETA: 0s - loss: 5.7320 - accuracy: 0.6406None\n",
      "455/455 [==============================] - 0s 417us/step - loss: 5.9946 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "model type is NNClassifier\n",
      "None\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "455/455 [==============================] - ETA: 4s - loss: 3.5013 - accuracy: 0.58 - ETA: 0s - loss: 5.3383 - accuracy: 0.5833 - ETA: 4s - loss: 4.5062 - accuracy: 0.4375 - ETA: 4s - loss: 4.4647 - accuracy: 0.47 - ETA: 0s - loss: 5.2725 - accuracy: 0.55 - ETA: 0s - loss: 4.9930 - accuracy: 0.58 - ETA: 0s - loss: 5.9977 - accuracy: 0.54 - ETA: 0s - loss: 5.5227 - accuracy: 0.58 - ETA: 0s - loss: 5.9702 - accuracy: 0.56 - 1s 2ms/step - loss: 5.6474 - accuracy: 0.5934 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 2/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.5661 - accuracy: 0.56 - ETA: 0s - loss: 5.8430 - accuracy: 0.62 - 1s 2ms/step - loss: 6.0218 - accuracy: 0.5648 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 5.6439 - accuracy: 0.5868 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================] - 0s 313us/step - loss: 5.9448 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 3/10000\n",
      " 48/455 [==>...........................] - ETA: 0s - loss: 4.9857 - accuracy: 0.6875Epoch 2/10000\n",
      " 48/455 [==>...........................]\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.0399 - accuracy: 0.6215 - ETA: 0s - loss: 6.0040 - accuracy: 0.6250 - ETA: 0s - loss: 6.6537 - accuracy: 0.432/455 [===========================>..]144/455 [========>.....................] - ETA: 0s - loss: 6.2055 - accuracy: 0.6111 - ETA: 0s - loss: 6.3279 - accuracy: 0.60 - ETA: 0s - loss: 5.9880 - accuracy: 0.62 - 0s 396us/step - loss: 6.1371 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 4/100\n",
      "192/455 [===========>..................] - ETA: 0s - loss: 7.0486 - accuracy: 0.5590 - ETA: 0s - loss: 4.9893 - accuracy: 0.6875144/455 [========>.....................] - ETA: 0s - loss: 6.5396 - accuracy: 0.192/455 [===========>..................] - ETA: 0s - loss: 6.1107 - accuracy: 0.6146432/455 [===========================>..] - ETA: 0s - loss: 6.5088 - accuracy: 0.5926 - ETA: 0s - loss: 6.2858 - accuracy: 0.60336/455 [=====================>........]455/455 [==============================] - ETA: 0s - loss: 6.1051 - accuracy: 0.61 - 0s 612us/step - loss: 6.4952 - accuracy: 0.5934 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 3/10000288/455 [=================>............]\n",
      "455/455 [==============================]6215 - ETA: 0s - loss: 6.6536 - accuracy: 0. - ETA: 0s - loss: 5.7206 - accuracy: 0.6406 - 0s 448us/step - loss: 5.8753 - accuracy: 0.6308 - val_loss: 6.0134 - val_accuracy: 0.6228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6527 - accuracy: 0.5833 - ETA: 0s - loss: 5.3141 - accuracy: 0.66 - 0s 857us/step - loss: 5.9503 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 3/10000\n",
      "240/455 [==============>...............]6583TA: 0s - loss: 5.6536 - accuracy: 0.6458144/455 [========>.....................] - ETA: 0s - loss: 6.3750 - accuracy: 0.6007 - ETA: 0s - loss: 5.8689 - accuracy: 0 - ETA: 0s - loss: 6.0692 - accuracy: 0.6198240/455 [==============>...............]144/455 [========>.....................] - ETA: 0s - loss: 5.3190 - accuracy:  - ETA: 0s - loss: 5.7438 - accuracy: 0.6399455/455 [==============================] - ETA: 0s - loss: 5.5850 - accuracy: 0.6500 - 0s 611us/step - loss: 6.2453 - accuracy: 0.6088 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 4/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.9821 - accuracy: 0.56 - ETA: 0s - loss: 6.2235 - accuracy: 0.61 - 0s 591us/step - loss: 5.9954 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 6/100\n",
      "288/455 [=================>............]5625TA: 0s - loss: 6.6858 - accuracy: 0.57432/455 [===========================>..] - ETA: 0s - loss: 6.0599 - accuracy: 0.62 - ETA: 0s - loss: 6.6162 - accuracy: 0.144/455 [========>.....................]455/455 [==============================] - 0s 709us/step - loss: 6.1398 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 6.5344 - accuracy: 0.5903Epoch 4/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.5845 - accuracy: 0.5859 - ETA: 0s - loss: 7.9822 - accuracy: 0.50 - ETA: 0s - loss: 5.8713 - accuracy: 0.63 - 0s 575us/step - loss: 6.5038 - accuracy: 0.5912 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 5/100\n",
      "288/455 [=================>............] ETA: 0s - loss: 5.8215 - accuracy: 0.6354 - ETA: 0s - loss: 5.7749 - accuracy: 0.6380 - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - ETA: 0s - loss: 6.2065 - accuracy: 0.61455/455 [==============================]192/455 [===========>..................] - 0s 645us/step - loss: 5.8922 - accuracy: 0.6308 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 5.6545 - accuracy: 0.6458Epoch 7/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2185 - accuracy: 0.6088 - ETA: 0s - loss: 6.3142 - accuracy: 0.60 - ETA: 0s - loss: 5.8196 - accuracy: 0.63 - 0s 587us/step - loss: 6.1147 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 5/10000\n",
      "455/455 [==============================]6276384/455 [========================>.....] 48/455 [==>...........................] - ETA: 0s - loss: 6.6463 - accuracy: 0. - ETA: 0s - loss: 6.3185 - accuracy: 0.6042 - 0s 573us/step - loss: 6.2811 - accuracy: 0.6066 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 6/100\n",
      "144/455 [========>.....................] - ETA: 0s - loss: 6.2312 - accuracy: 0.609 - ETA: 0s - loss: 5.6572 - accuracy: 0.6458384/455 [========================>.....] - ETA: 0s - loss: 6.4844 - accuracy: 0.59 - ETA: 0s - loss: 5.6493 - accuracy: 0.64 - ETA: 0s - loss: 6.2108 - accuracy: 0.384/455 [========================>.....]455/455 [==============================] - ETA: 0s - loss: 5.9415 - accuracy: 0.6276 - 0s 604us/step - loss: 6.1383 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 8/10000\n",
      "455/455 [==============================] ETA: 0s - loss: 6.9858 - accuracy: 0.5625 - ETA: 0s - loss: 5.9316 - accuracy: 0.62 - 0s 572us/step - loss: 6.0666 - accuracy: 0.6198 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 6/10000\n",
      "144/455 [========>.....................]60425 [===========>..................] - ETA: 0s - loss: 5.6536 - accuracy: 0.6458432/455 [===========================>..] - ETA: 0s - loss: 6.2473 - accuracy: 288/455 [=================>............] - ETA: 0s - loss: 5.3214 - accuracy: 0.6667455/455 [==============================] - ETA: 0s - loss: 6.5411 - accuracy: 0.5903 - 0s 600us/step - loss: 6.2827 - accuracy: 0.6066 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 7/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.3141 - accuracy: 0.66 - ETA: 0s - loss: 5.6521 - accuracy: 0.64 - ETA: 0s - loss: 6.2826 - accuracy: 0.60 - ETA: 0s - loss: 5.4273 - accuracy: 0.6336/455 [=====================>........] - ETA: 0s - loss: 6.1750 - accuracy: 0.6131 - 0s 571us/step - loss: 6.2457 - accuracy: 0.6088 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 9/10000\n",
      " - ETA: 0s - loss: 5.5857 - accuracy: 0.650055 [==============>...............] - ETA: 0s - loss: 6.6536 - accuracy: 0.5833432/455 [===========================>..] - ETA: 0s - loss: 6.1702 - accuracy: 0.336/455 [=====================>........]455/455 [==============================] - ETA: 0s - loss: 5.7010 - accuracy: 0.6429 - 0s 644us/step - loss: 6.2453 - accuracy: 0.6088 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "144/455 [========>.....................] - ETA: 0s - loss: 5.8762 - accuracy: 0.6319Epoch 7/10000\n",
      "288/455 [=================>............] - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - ETA: 0s - loss: 5.8024 - accuracy: 0.63 - ETA: 0s - loss: 6.0989 - accuracy: 0.61192/455 [===========>..................]455/455 [==============================] - 0s 672us/step - loss: 5.8245 - accuracy: 0.6352 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 5.6518 - accuracy: 0.6458Epoch 8/10000\n",
      "336/455 [=====================>........] - ETA: 0s - loss: 6.4876 - accuracy: 0.5938 - ETA: 0s - loss: 4.3324 - accuracy: 0.72 - ETA: 0s - loss: 5.5561 - accuracy: 0.455/455 [==============================]144/455 [========>.....................] - ETA: 0s - loss: 6.1025 - accuracy: 0.6181 - 0s 609us/step - loss: 6.4575 - accuracy: 0.5956 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 10/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9464 - accuracy: 0.627240/455 [==============>...............] - ETA: 0s - loss: 7.6647 - accuracy: 0.5208 - ETA: 0s - loss: 6.4558 - accuracy: 0.59 - 0s 548us/step - loss: 5.9611 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 8/10000\n",
      "432/455 [===========================>..] 48/455 [==>...........................]336/455 [=====================>........] - ETA: 0s - loss: 7.2096 - accuracy: 0.5486 - ETA: 0s - loss: 8.3070 - accuracy: 0.4792 - ETA: 0s - loss: 6.5113 - accuracy: 0.59240/455 [==============>...............]144/455 [========>.................... - ETA: 0s - loss: 6.5865 - accuracy: 0.5875 - ETA: 0s - loss: 6.6500 - accuracy: 0.5833 - ETA: 0s - loss: 6.6532 - accuracy: 0.5240/455 [==============>.............. - ETA: 0s - loss: 6.1156 - accuracy: 0.6167336/455 [=====================>........]455/455 [==============================] - ETA: 0s - loss: 6.2183 - accuracy: 0.6101 - 0s 651us/step - loss: 6.5626 - accuracy: 0.5890 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 9/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.6536 - accuracy: 0.64 - ETA: 0s - loss: 6.1729 - accuracy: 0.61 - 0s 617us/step - loss: 6.4463 - accuracy: 0.5956 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 11/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.6536 - accuracy: 0.64 48/455 [==>...........................] - ETA: 0s - loss: 6.6500 - accuracy: 0.5833432/455 [===========================>..] - ETA: 0s - loss: 6.0198 - accuracy: 0.62336/455 [=====================>........]144/455 [========>.................... - ETA: 0s - loss: 6.0790 - accuracy: 0.6190 - ETA: 0s - loss: 6.3166 - accuracy: 0.6042 - 0s 660us/step - loss: 5.9958 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 9/10000\n",
      "192/455 [===========>..................] - ETA: 0s - loss: 5.6499 - accuracy: 0.432/455 [===========================>..]240/455 [==============>...............] - ETA: 0s - loss: 6.2809 - accuracy: 0.6065 - ETA: 0s - loss: 6.5171 - accuracy: 0.336/455 [=====================>........] - ETA: 0s - loss: 6.3663 - accuracy: 0.6012455/455 [==============================] - ETA: 0s - loss: 6.6491 - accuracy: 0.5833 - 0s 572us/step - loss: 6.1737 - accuracy: 0.6132 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 10/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.3178 - accuracy: 0.66 - ETA: 0s - loss: 6.4117 - accuracy: 0.59 - 0s 587us/step - loss: 6.3523 - accuracy: 0.6022 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 12/100\n",
      "336/455 [=====================>........]6042TA: 0s - loss: 5.8789 - accuracy: 0.630 48/455 [==>...........................]432/455 [===========================>..] - ETA: 0s - loss: 6.0948 - accuracy: 0.61 - ETA: 0s - loss: 5.9231 - accuracy: 0.62455/455 [==============================]192/455 [===========>..................] - ETA: 0s - loss: 6.4885 - accuracy: 0.5938 - 0s 625us/step - loss: 6.1021 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 10/10000\n",
      "455/455 [==============================]5625432/455 [===========================>..] - ETA: 0s - loss: 5.9374 - accuracy: 0.62 - ETA: 0s - loss: 6.2120 - accuracy: 0. - 0s 591us/step - loss: 5.9530 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "\bEpoch 11/10000192/455 [===========>..................]\n",
      "192/455 [===========>..................] - 0s 579us/step - loss: 6.3177 - accuracy: 0.6044 - val_loss: 6.0134 - val_accuracy: 0.6228TA: 0s - loss: 3.9856 - accuracy: 0. - ETA: 0s - loss: 5.6524 - accuracy: 0.645455/455 [==============================]\n",
      " - ETA: 0s - loss: 5.6536 - accuracy: 0.6458Epoch 13/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 7.3106 - accuracy: 0.54288/455 [=================>............]432/455 [===========================>..] - ETA: 0s - loss: 5.9857 - accuracy: 0.6250 - ETA: 0s - loss: 6.0202 - accuracy: 0.62 - ETA: 0s - loss: 6.8991 - accuracy: 0.56 - 0s 629us/step - loss: 6.0667 - accuracy: 0.6198 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 11/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9845 - accuracy: 0.625288/455 [=================>............] - ETA: 0s - loss: 4.3177 - accuracy: 0.7292 - ETA: 0s - loss: 6.9280 - accuracy: 0.56 - 0s 548us/step - loss: 6.1379 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 12/10000\n",
      "432/455 [===========================>..] 48/455 [==>...........................] - ETA: 0s - loss: 5.0939 - accuracy: 0.6806 - ETA: 0s - loss: 5.3141 - accuracy: 0.66 - ETA: 0s - loss: 6.4314 - accuracy: 0240/455 [==============>...............]144/455 [========>.....................] - ETA: 0s - loss: 5.0499 - accuracy: 0.6833455/455 [==============================] - 0s 570us/step - loss: 6.3516 - accuracy: 0.6022 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 5.6524 - accuracy: 0.6458Epoch 14/10000\n",
      " - ETA: 0s - loss: 6.5247 - accuracy: 0.5903TA: 0s - loss: 5.5055 - accuracy: 0.6548 - ETA: 0s - loss: 6.3178 - accuracy: 0.60 - ETA: 0s - loss: 6.7102 - accuracy: 0.57432/455 [===========================>..]336/455 [=====================>........] - ETA: 0s - loss: 6.1286 - accuracy: 0.6161 - ETA: 0s - loss: 5.7959 - accuracy: 0.6288/455 [=================>............]455/455 [==============================] - 0s 659us/step - loss: 5.8533 - accuracy: 0.6330 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 12/10000\n",
      "455/455 [==============================] - 0s 586us/step - loss: 6.1379 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 13/10000 48/455 [==>...........................]\n",
      "192/455 [===========>..................]62 - ETA: 0s - loss: 6.3484 - accuracy: 0.6016 - ETA: 0s - loss: 4.9893 - accuracy: 0.68 - ETA: 0s - loss: 5.8972 - accuracy: 0.63455/455 [==============================]144/455 [========>.....................] - ETA: 0s - loss: 5.6548 - accuracy: 0.6458 - 0s 564us/step - loss: 6.2345 - accuracy: 0.6088 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 15/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.3288 - accuracy: 0.288/455 [=================>............]336/455 [=====================>........] - ETA: 0s - loss: 5.8845 - accuracy: 0.6310 - ETA: 0s - loss: 6.3769 - accuracy: 0.6192/455 [===========>................. - ETA: 0s - loss: 6.5715 - accuracy: 0.5885432/455 [===========================>..]384/455 [========================>.....] - ETA: 0s - loss: 5.8320 - accuracy: 0.6343 - ETA: 0s - loss: 6.1960 - accuracy: 0. - 0s 601us/step - loss: 5.8525 - accuracy: 0.6330 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 6.7090 - accuracy: 0.5799455/455 [==============================]Epoch 13/10000 - 0s 580us/step - loss: 6.4213 - accuracy: 0.5978 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 14/10000\n",
      "240/455 [==============>...............] - 0s 626us/step - loss: 6.3150 - accuracy: 0.6044 - val_loss: 6.0134 - val_accuracy: 0.6228: 0s - loss: 6.2822 - accuracy: 0.60 - ETA: 0s - loss: 5.6487 - accuracy: 0.64 - ETA: 0s - loss: 5.1554 - accuracy: 0.\n",
      " - ETA: 0s - loss: 5.8485 - accuracy: 0.63Epoch 16/10000\n",
      "455/455 [==============================]455/455 [==============================]6354 - ETA: 0s - loss: 6.3178 - accuracy: 0.384/455 [========================>.....]384/455 [========================>.....] - ETA: 0s - loss: 6.1933 - accuracy: 0.6120 - ETA: 0s - loss: 5.9816 - accuracy: 0.62 - ETA: 0s - loss: 6.3206 - accuracy: 0.288/455 [=================>............] - 0s 604us/step - loss: 6.1036 - accuracy: 0.6176 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - ETA: 0s - loss: 6.5971 - accuracy: 0.5868 - 0s 641us/step - loss: 6.0293 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 14/10000Epoch 15/10000\n",
      "\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.6463 - accuracy: 0.6458 - ETA: 0s - loss: 7.6391 - accuracy: 0.52 - ETA: 0s - loss: 6.3933 - accuracy: 0.144/455 [========>.....................]144/455 [========>.....................] - ETA: 0s - loss: 6.5319 - accuracy: 0.5903 - ETA: 0s - loss: 6.8726 - accuracy: 0.56 - 0s 617us/step - loss: 6.3508 - accuracy: 0.6022 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 17/10000\n",
      "240/455 [==============>...............]240/455 [==============>...............] - ETA: 0s - loss: 7.0072 - accuracy: 0.5542 - ETA: 0s - loss: 6.0470 - accuracy: 0.6208 - ETA: 0s - loss: 7.9858 - accuracy: 0.50336/455 [=====================>........]336/455 [=====================>........] - ETA: 0s - loss: 6.5751 - accuracy: 0.5833 - ETA: 0s - loss: 5.8856 - accuracy: 0.63 - ETA: 0s - loss: 6.5429 - accuracy: 0.59432/455 [===========================>..]432/455 [===========================>..] - ETA: 0s - loss: 5.9800 - accuracy: 0.6250 - ETA: 0s - loss: 6.3322 - accuracy: 0.59 - ETA: 0s - loss: 6.3208 - accuracy: 0.455/455 [==============================]455/455 [==============================] - 0s 664us/step - loss: 6.1172 - accuracy: 0.6132 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " - 0s 662us/step - loss: 5.8529 - accuracy: 0.6330 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 16/10000Epoch 15/10000\n",
      "\n",
      "455/455 [==============================]6667A: 0s - loss: 7.9822 - accuracy: 0.5000 48/455 [==>...........................]384/455 [========================>.....] - ETA: 0s - loss: 6.1536 - accuracy: 0.144/455 [========>.....................] - ETA: 0s - loss: 5.2059 - accuracy: 0.6736 - ETA: 0s - loss: 6.9809 - accuracy: 0.56 - 0s 628us/step - loss: 6.3512 - accuracy: 0.6022 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 18/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.3214 - accuracy: 0.240/455 [==============>...............] - ETA: 0s - loss: 6.5799 - accuracy: 0.5875 - ETA: 0s - loss: 5.7722 - accuracy: 0.63 - ETA: 0s - loss: 6.1509 - accuracy: 0.61336/455 [=====================>........]336/455 [=====================>........] - ETA: 0s - loss: 5.7698 - accuracy: 0.6369 - ETA: 0s - loss: 6.1708 - accuracy: 0.61 - ETA: 0s - loss: 6.1284 - accuracy: 0.61432/455 [===========================>..]336/455 [=====================>........] - ETA: 0s - loss: 6.0388 - accuracy: 0.6204 - ETA: 0s - loss: 6.3178 - accuracy: 0. - 0s 639us/step - loss: 6.1344 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================]Epoch 16/10000 - 0s 661us/step - loss: 6.1190 - accuracy: 0.6154 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "\n",
      "432/455 [===========================>..]Epoch 17/10000 - ETA: 0s - loss: 6.3174 - accuracy: 0.6042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - ETA: 0s - loss: 4.9820 - accuracy: 0.6875 - ETA: 0s - loss: 3.6571 - accuracy: 0.77 - 0s 563us/step - loss: 6.2788 - accuracy: 0.6066 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 19/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.5641 - accuracy: 0.6510 - ETA: 0s - loss: 6.6500 - accuracy: 0.58 - ETA: 0s - loss: 5.9027 - accuracy: 0.63 - ETA: 0s - loss: 5.9796 - accuracy: 0.62 - ETA: 0s - loss: 6.4273 - accuracy: 0.59 - ETA: 0s - loss: 5.9297 - accuracy: 0.62 - ETA: 0s - loss: 5.9798 - accuracy: 0.62 - ETA: 0s - loss: 6.3835 - accuracy: 0.60 - ETA: 0s - loss: 6.0276 - accuracy: 0.62 - 0s 536us/step - loss: 5.9577 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 17/10000\n",
      "336/455 [=====================>........] - ETA: 0s - loss: 6.3168 - accuracy: 0.60 48/455 [==>...........................]455/455 [==============================] - ETA: 0s - loss: 5.9784 - accuracy: 0.6250 - 0s 583us/step - loss: 6.0697 - accuracy: 0.6198 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 18/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2063 - accuracy: 0.6111 - ETA: 0s - loss: 7.3289 - accuracy: 0.54 - ETA: 0s - loss: 5.8677 - accuracy: 0.63 - 0s 627us/step - loss: 6.2083 - accuracy: 0.6110 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 20/10000\n",
      "455/455 [==============================]6076144/455 [========>.....................] - ETA: 0s - loss: 5.6536 - accuracy: 0.64 - ETA: 0s - loss: 5.8677 - accuracy: 0.6288/455 [=================>............] - ETA: 0s - loss: 5.7606 - accuracy: 0.63 - ETA: 0s - loss: 6.0619 - accuracy: 0.384/455 [========================>.....]192/455 [===========>..................] - ETA: 0s - loss: 6.3701 - accuracy: 0.6016 - ETA: 0s - loss: 6.0660 - accuracy: 0.61 - 0s 596us/step - loss: 5.9569 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 18/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2619 - accuracy: 0.60 - ETA: 0s - loss: 8.9713 - accuracy: 0.4375 - 0s 617us/step - loss: 6.7102 - accuracy: 0.5802 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 19/10000\n",
      "455/455 [==============================] ETA: 0s - loss: 4.9857 - accuracy: 0.68 - ETA: 0s - loss: 6.4018 - accuracy: 0.5990144/455 [========>.....................] - ETA: 0s - loss: 6.8665 - accuracy: 0.192/455 [===========>..................]240/455 [==============>...............] - ETA: 0s - loss: 6.9101 - accuracy: 0.5677 - ETA: 0s - loss: 6.3784 - accuracy: 0.6000 - 0s 693us/step - loss: 6.1632 - accuracy: 0.6132 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 21/10000\n",
      "455/455 [==============================]6273TA: 0s - loss: 5.6499 - accuracy: 0. - ETA: 0s - loss: 6.2167 - accuracy: 0.6101 - ETA: 0s - loss: 7.0478 - accuracy: 0.5432/455 [===========================>.384/455 [========================>.....] - ETA: 0s - loss: 5.5687 - accuracy: 0.6510 - ETA: 0s - loss: 6.9530 - accuracy: 0.56 - 0s 639us/step - loss: 5.8175 - accuracy: 0.6352 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 19/10000\n",
      " - ETA: 0s - loss: 5.5946 - accuracy: 0.6493455/455 [==============================] - 0s 607us/step - loss: 6.8510 - accuracy: 0.5714 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      " 48/455 [==>...........................]Epoch 20/10000\n",
      "455/455 [==============================]62384/455 [========================>.....] - ETA: 0s - loss: 6.6646 - accuracy: 0.5833 - ETA: 0s - loss: 6.0231 - accuracy: 0.62 - ETA: 0s - loss: 6.5319 - accuracy: 0.59 - ETA: 0s - loss: 5.7716 - accuracy: 0.63 - 0s 605us/step - loss: 5.9249 - accuracy: 0.6286 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================] ETA: 0s - loss: 5.9796 - accuracy: 0.6250 - ETA: 0s - loss: 6.4588 - accuracy: 0.59 - ETA: 0s - loss: 6.1228 - accuracy: 0.61 - ETA: 0s - loss: 6.6599 - accuracy: 0. - ETA: 0s - loss: 6.5855 - accuracy: 0.5880 - 0s 613us/step - loss: 6.0285 - accuracy: 0.6220 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 20/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.6463 - accuracy: 0.64 - 0s 646us/step - loss: 6.6038 - accuracy: 0.5868 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 21/10000\n",
      "192/455 [===========>..................] - ETA: 0s - loss: 7.9932 - accuracy: 0.50 - ETA: 0s - loss: 5.4811 - accuracy: 0.6562model type is NNClassi\n",
      "None192/455 [===========>..................]288/455 [=================>............] - ETA: 0s - loss: 5.6469 - accuracy: 0.6458 - ETA: 0s - loss: 7.2413 - accuracy: 0.5469\n",
      "455/455 [==============================]288/455 [=================>............] - ETA: 0s - loss: 5.8137 - accuracy: 0.6354 - ETA: 0s - loss: 6.8799 - accuracy: 0.56 - ETA: 0s - loss: 6.7440 - accuracy: 0.57 - 0s 528us/step - loss: 5.9584 - accuracy: 0.6264 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "Epoch 21/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 7.3069 - accuracy: 0.54 - 0s 560us/step - loss: 6.6408 - accuracy: 0.5846 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.3954 - accuracy: 0.59 - ETA: 0s - loss: 5.9320 - accuracy: 0.62 - 0s 429us/step - loss: 5.9923 - accuracy: 0.6242 - val_loss: 6.0134 - val_accuracy: 0.6228\n",
      "model type is NNClassifier\n",
      "None\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "455/455 [==============================] - ETA: 6s - loss: 4.4736 - accuracy: 0.54 - ETA: 0s - loss: 4.9470 - accuracy: 0.59 - ETA: 0s - loss: 5.5025 - accuracy: 0.59 - 1s 2ms/step - loss: 5.5747 - accuracy: 0.5978 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 2/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.9754 - accuracy: 0.56 - ETA: 0s - loss: 6.2786 - accuracy: 0.60 - 0s 301us/step - loss: 5.8678 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 3/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9821 - accuracy: 0.6250 - ETA: 7s - loss: 4.3093 - accuracy: 0.54 - ETA: 0s - loss: 5.9799 - accuracy: 0.62 - ETA: 1s - loss: 4.8381 - accuracy: 0.54 - ETA: 0s - loss: 6.0132 - accuracy: 0.62 - ETA: 0s - loss: 5.1360 - accuracy: 0.57 - 0s 430us/step - loss: 6.0209 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 4/10000\n",
      "455/455 [==============================]6172TA: 8s - loss: 5.1469 - accuracy: 0.43336/455 [=====================>........] - ETA: 0s - loss: 5.5438 - accuracy: 0.56 - ETA: 3s - loss: 5.3805 - accuracy: 0. - ETA: 0s - loss: 5.5018 - accuracy: 0.5856144/455 [========>.....................] - ETA: 0s - loss: 5.3153 - accuracy: 0.66 - ETA: 1s - loss: 5.8588 - accuracy: 0.47 - ETA: 0s - loss: 5.6913 - accuracy: 0.64 - ETA: 0s - loss: 6.0800 - accuracy: 0.384/455 [========================>.....] - ETA: 0s - loss: 6.2310 - accuracy: 0.51 - 0s 601us/step - loss: 6.0241 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 5/10000\n",
      " - 1s 3ms/step - loss: 5.5615 - accuracy: 0.5846 - val_loss: 5.8735 - val_accuracy: 0.63160s - loss: 5.5813 - accuracy: 0.6455/455 [==============================]\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9054 - accuracy: 0.62 - 0s 357us/step - loss: 5.9226 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 6/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 7.6391 - accuracy: 0. - 2s 3ms/step - loss: 5.9984 - accuracy: 0.5429 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "240/455 [==============>...............] - ETA: 0s - loss: 5.9127 - accuracy: 0.6292Epoch 2/10000\n",
      "455/455 [==============================]6328 48/455 [==>...........................] - ETA: 0s - loss: 5.3215 - accuracy: 0.66 - 0s 416us/step - loss: 5.9573 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 7/100\n",
      " 48/455 [==>...........................] - ETA: 0s - loss: 5.9821 - accuracy: 0.6250192/455 [===========>..................] - ETA: 0s - loss: 6.8206 - accuracy: 0.5729Epoch 2/10000\n",
      "455/455 [==============================]288/455 [=================>............] - ETA: 0s - loss: 6.0623 - accuracy: 0.6198 - ETA: 0s - loss: 6.4883 - accuracy: 0.5938 - ETA: 0s - loss: 6.9931 - accuracy: 0.336/455 [=====================>........]384/455 [========================>.....] - ETA: 0s - loss: 6.0749 - accuracy: 0.6190 - ETA: 0s - loss: 6.2390 - accuracy: 0.6094 - ETA: 0s - loss: 5.9949 - accuracy: 0 - ETA: 0s - loss: 6.1025 - accuracy: 0.6181 - 0s 447us/step - loss: 6.0628 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "455/455 [==============================] - 0s 633us/step - loss: 6.2827 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 8/10000\n",
      "Epoch 3/10000\n",
      "455/455 [==============================]5833 48/455 [==>...........................] - ETA: 0s - loss: 6.9858 - accuracy: 0.56 - ETA: 0s - loss: 5.9649 - accuracy: 0.62 - ETA: 0s - loss: 6.7277 - accuracy: 0.5792 - ETA: 0s - loss: 6.0715 - accuracy: 0. - ETA: 0s - loss: 6.2564 - accuracy: 0.60288/455 [=================>............] - ETA: 0s - loss: 6.5512 - accuracy: 0.5903336/455 [=====================>........] - ETA: 0s - loss: 6.0415 - accuracy: 0.6432/455 [===========================>..] - ETA: 0s - loss: 6.6594 - accuracy: 0.58 - ETA: 0s - loss: 6.3239 - accuracy: 0.6019 - 0s 481us/step - loss: 6.0571 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 9/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9821 - accuracy: 0.6250 - 0s 563us/step - loss: 6.2495 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 4/10000455/455 [==============================]\n",
      " - 0s 941us/step - loss: 6.6721 - accuracy: 0.5824 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 3/10000\n",
      "455/455 [==============================]5417TA: 0s - loss: 5.1879 - accuracy: 0.6667 - ETA: 0s - loss: 5.6646 - accuracy: 0.64 - ETA: 0s - loss: 5.8151 - accuracy: 0.63192/455 [===========>..................] - ETA: 0s - loss: 6.1157 - accuracy: 0.6146144/455 [========>....................288/455 [=================>............] - ETA: 0s - loss: 5.7053 - accuracy: 0.6240/455 [==============>...............]384/455 [========================>.....]336/455 [=====================>........] - ETA: 0s - loss: 6.0098 - accuracy: 0.6220 - ETA: 0s - loss: 6.0236 - accuracy: 0.432/455 [===========================>..]336/455 [=====================>........] - ETA: 0s - loss: 5.8187 - accuracy: 0.6343 - ETA: 0s - loss: 7.1089 - accuracy: 0.55 - 0s 575us/step - loss: 6.2410 - accuracy: 0.6088 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 10/10000\n",
      " 48/455 [==>........................ - ETA: 0s - loss: 6.3105 - accuracy: 0.6042455/455 [==============================]432/455 [===========================>..] - 0s 588us/step - loss: 5.8754 - accuracy: 0.6308 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - ETA: 0s - loss: 6.6027 - accuracy: 0.5833Epoch 5/10000\n",
      "455/455 [==============================] ETA: 0s - loss: 4.6572 - accuracy: 0.70 - ETA: 0s - loss: 6.2023 - accuracy: 0.6111 - 0s 675us/step - loss: 6.5497 - accuracy: 0.5868 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 4/10000\n",
      "455/455 [==============================]6875240/455 [==============>...............] - ETA: 0s - loss: 4.9930 - accuracy: 0.6875 - ETA: 0s - loss: 6.3120 - accuracy: 0.60144/455 [========>.....................]336/455 [=====================>........] - ETA: 0s - loss: 6.0279 - accuracy: 0.6220 - ETA: 0s - loss: 5.8762 - accuracy: 0.63 - ETA: 0s - loss: 5.5368 - accuracy: 0.65240/455 [==============>...............]384/455 [========================>.....] - ETA: 0s - loss: 5.6887 - accuracy: 0.6432 - ETA: 0s - loss: 5.8536 - accuracy: 0.63 - 0s 554us/step - loss: 6.1005 - accuracy: 0.6176 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 11/10000\n",
      " - ETA: 0s - loss: 5.7970 - accuracy: 0.6369: 0s - loss: 5.3178 - accuracy: 0.666336/455 [=====================>........]455/455 [==============================] - 0s 579us/step - loss: 5.9226 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 6/10000\n",
      "288/455 [=================>............] - 0s 685us/step - loss: 6.2803 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316- loss: 6.0599 - accuracy: 0.6204 - ETA: 0s - loss: 5.5660 - accuracy: 0 - ETA: 0s - loss: 5.7570 - accuracy: 0.6389455/455 [==============================]\n",
      " - ETA: 0s - loss: 6.2029 - accuracy: 0.6111Epoch 5/10000\n",
      "384/455 [========================>.....] - ETA: 0s - loss: 6.6500 - accuracy: 0.58 - ETA: 0s - loss: 6.1901 - accuracy: 0.61 - ETA: 0s - loss: 6.0338 - accuracy: 0.62 - ETA: 0s - loss: 5.7606 - accuracy: 0.6 - ETA: 0s - loss: 5.9369 - accuracy: 0.6276455/455 [==============================] - 0s 623us/step - loss: 6.2414 - accuracy: 0.6088 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 12/10000\n",
      " - ETA: 0s - loss: 6.3148 - accuracy: 0.6042TA: 0s - loss: 6.1142 - accuracy: 0.6167 - ETA: 0s - loss: 4.9893 - accuracy: 0.6288/455 [=================>............]455/455 [==============================] - 0s 654us/step - loss: 5.9569 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 7/10000\n",
      " - ETA: 0s - loss: 6.6427 - accuracy: 0.5833TA: 0s - loss: 5.9808 - accuracy: 0.6250 - ETA: 0s - loss: 7.3069 - accuracy: 0.54 - ETA: 0s - loss: 5.8713 - accuracy: 0.63 - ETA: 0s - loss: 5.5828 - accuracy: 0.65455/455 [==============================] - 0s 703us/step - loss: 5.8198 - accuracy: 0.6352 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "336/455 [=====================>........]Epoch 6/10000 - ETA: 0s - loss: 5.9351 - accuracy: 0.6280\n",
      "455/455 [==============================] ETA: 0s - loss: 4.3177 - accuracy: 0.7292 - ETA: 0s - loss: 6.1777 - accuracy: 0.61 - ETA: 0s - loss: 6.1678 - accuracy: 0. - ETA: 0s - loss: 5.9315 - accuracy: 0.6280 - ETA: 0s - loss: 5.6490 - accuracy: 0.64 - 0s 669us/step - loss: 6.1017 - accuracy: 0.6176 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 13/10000\n",
      " - ETA: 0s - loss: 6.9821 - accuracy: 0.5625455/455 [==============================] - 0s 607us/step - loss: 6.0277 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 8/10000\n",
      "455/455 [==============================]5764TA: 0s - loss: 7.6391 - accuracy: 0.432/455 [===========================>..] - ETA: 0s - loss: 6.0206 - accuracy: 0.62240/455 [==============>..............192/455 [===========>..................] - ETA: 0s - loss: 5.9835 - accuracy: 0.6250 - ETA: 0s - loss: 6.3954 - accuracy: 0.5990 - 0s 632us/step - loss: 6.1124 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 7/10000\n",
      "455/455 [==============================]384/455 [========================>.....].6458336/455 [=====================>........]288/455 [=================>............] - ETA: 0s - loss: 5.9836 - accuracy: 0.6250 - ETA: 0s - loss: 5.7028 - accuracy: 0.64432/455 [===========================>..] - ETA: 0s - loss: 5.8552 - accuracy: 0.6328 - ETA: 0s - loss: 5.9095 - accuracy: 0.6296 - ETA: 0s - loss: 5.9018 - accuracy: 0.63 - 0s 669us/step - loss: 5.9966 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "\bEpoch 14/10000288/455 [=================>............]\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2594 - accuracy: 0.6076 - 0s 604us/step - loss: 5.9226 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 9/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9821 - accuracy: 0.6250 - ETA: 0s - loss: 6.3105 - accuracy: 0.60 - ETA: 0s - loss: 5.8990 - accuracy: 0.63 - ETA: 0s - loss: 5.8613 - accuracy: 0.62 - ETA: 0s - loss: 5.7582 - accuracy: 0. - 0s 616us/step - loss: 6.0651 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "240/455 [==============>...............] - ETA: 0s - loss: 5.5340 - accuracy: 0.6458Epoch 8/10000\n",
      "432/455 [===========================>..] - ETA: 0s - loss: 5.9134 - accuracy: 0.62 - ETA: 0s - loss: 3.9929 - accuracy: 0.7500 - ETA: 0s - loss: 5.6615 - accuracy: 0.63 - ETA: 0s - loss: 5.8137 - accuracy: 0.63 - ETA: 0s - loss: 5.8750 - accuracy: 0.6319 - ETA: 0s - loss: 5.6585 - accuracy: 0.64455/455 [==============================]240/455 [==============>.............. - 0s 630us/step - loss: 5.9681 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 609us/step - loss: 5.9584 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 15/10000\n",
      "Epoch 10/10000\n",
      " - ETA: 0s - loss: 6.0897 - accuracy: 0.6181TA: 0s - loss: 5.6499 - accuracy: 0.645 48/455 [==>...........................]336/455 [=====================>........] - ETA: 0s - loss: 6.3616 - accuracy: 0.60 - ETA: 0s - loss: 6.0915 - accuracy: 0.192/455 [===========>..................]432/455 [===========================>..] - ETA: 0s - loss: 5.9793 - accuracy: 0.6250 - ETA: 0s - loss: 6.1341 - accuracy: 0.61 - ETA: 0s - loss: 6.5113 - accuracy: 0.59455/455 [==============================] - 0s 683us/step - loss: 5.9992 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 9/10000\n",
      "455/455 [==============================]336/455 [=====================>........] - ETA: 0s - loss: 5.9784 - accuracy: 0.6250 - ETA: 0s - loss: 6.1218 - accuracy: 0.61 - ETA: 0s - loss: 5.9423 - accuracy: 0.62 - ETA: 0s - loss: 6.0534 - accuracy: 0.62 - ETA: 0s - loss: 6.3117 - accuracy: 0. - 0s 607us/step - loss: 5.9923 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 16/10000455/455 [==============================]\n",
      " - 0s 608us/step - loss: 5.9580 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 11/10000\n",
      "455/455 [==============================]336/455 [=====================>........] - ETA: 0s - loss: 5.3141 - accuracy: 0.6667 - ETA: 0s - loss: 6.2478 - accuracy: 0.6083 - ETA: 0s - loss: 5.3141 - accuracy: 0.144/455 [========>.....................] - ETA: 0s - loss: 5.3141 - accuracy: 0.6667 - ETA: 0s - loss: 6.2182 - accuracy: 0.6101 - ETA: 0s - loss: 6.3130 - accuracy: 0432/455 [===========================>..] - ETA: 0s - loss: 6.0911 - accuracy: 0.6181240/455 [==============>...............]288/455 [=================>............] - ETA: 0s - loss: 5.7570 - accuracy: 0.6389 - ETA: 0s - loss: 6.3784 - accuracy: 0.60 - 0s 683us/step - loss: 5.9935 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 10/100\n",
      "144/455 [========>.....................]336/455 [=====================>........] - ETA: 0s - loss: 5.9369 - accuracy: 0.6276 - ETA: 0s - loss: 6.0269 - accuracy: 0.6220 - ETA: 0s - loss: 6.6463 - accuracy: 0.58 - ETA: 0s - loss: 5.7586 - accuracy: 0.63 - ETA: 0s - loss: 5.6499 - accuracy: 0.64455/455 [==============================]455/455 [==============================] - 0s 671us/step - loss: 5.8864 - accuracy: 0.6308 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 653us/step - loss: 5.7828 - accuracy: 0.6374 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 12/10000Epoch 17/10000\n",
      "\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.3135 - accuracy: 0.6042 - ETA: 0s - loss: 6.6463 - accuracy: 0.5833 48/455 [==>...........................] - ETA: 0s - loss: 6.9785 - accuracy: 0.56 - ETA: 0s - loss: 5.9802 - accuracy: 0.336/455 [=====================>........]144/455 [========>.....................] - ETA: 0s - loss: 6.0754 - accuracy: 0.6190 - ETA: 0s - loss: 5.9808 - accuracy: 0384/455 [========================>.....] - ETA: 0s - loss: 6.1463 - accuracy: 0.6146192/455 [===========>..................]192/455 [===========>..................] - ETA: 0s - loss: 5.9802 - accuracy: 0.6250 - ETA: 0s - loss: 5.6472 - accuracy: 0.240/455 [==============>...............]288/455 [=================>............] - ETA: 0s - loss: 6.1791 - accuracy: 0.6125 - ETA: 0s - loss: 5.9249 - accuracy: 0.62 - 0s 780us/step - loss: 5.8880 - accuracy: 0.6308 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 11/10000\n",
      " - ETA: 0s - loss: 6.5994 - accuracy: 0.5833TA: 0s - loss: 6.7945 - accuracy: 0.384/455 [========================>.....]336/455 [=====================>........] - ETA: 0s - loss: 6.1223 - accuracy: 0.6161 - ETA: 0s - loss: 5.9798 - accuracy: 0. - ETA: 0s - loss: 6.2010 - accuracy: 0.61192/455 [===========>..................]455/455 [==============================] - 0s 783us/step - loss: 6.0281 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 13/10000\n",
      "455/455 [==============================] - 0s 845us/step - loss: 5.9927 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 18/10000\n",
      "144/455 [========>.....................] - ETA: 0s - loss: 5.3141 - accuracy: 0.6667288/455 [=================>............] - ETA: 0s - loss: 6.2263 - accuracy: 0.6076 - ETA: 0s - loss: 8.3033 - accuracy: 0.47 - ETA: 0s - loss: 6.5319 - accuracy: 0.5903192/455 [===========>..................]432/455 [===========================>..] - ETA: 0s - loss: 5.3407 - accuracy: 0.6615 - ETA: 0s - loss: 6.1441 - accuracy: 0.240/455 [==============>...............]455/455 [==============================] - ETA: 0s - loss: 6.0448 - accuracy: 0.6208 - 0s 597us/step - loss: 6.1142 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 12/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.8562 - accuracy: 0.6280 - ETA: 0s - loss: 4.9857 - accuracy: 0.68 - ETA: 0s - loss: 5.8958 - accuracy: 0.63 - 0s 514us/step - loss: 5.9718 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 14/10000\n",
      "455/455 [==============================]6146 48/455 [==>.......................... - ETA: 0s - loss: 5.9821 - accuracy: 0.6250 - 0s 537us/step - loss: 5.9218 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 19/10000\n",
      "455/455 [==============================]6667144/455 [========>.....................] - ETA: 0s - loss: 5.9255 - accuracy: 0.6285 - ETA: 0s - loss: 6.8702 - accuracy: 0.5144/455 [========>.....................]384/455 [========================>.....] - ETA: 0s - loss: 5.8701 - accuracy: 0.6319240/455 [==============>...............] - ETA: 0s - loss: 5.9171 - accuracy: 0.6292 - ETA: 0s - loss: 6.1052 - accuracy: 0.240/455 [==============>...............]336/455 [=====================>........] - ETA: 0s - loss: 6.2463 - accuracy: 0.60 - ETA: 0s - loss: 6.4107 - accuracy: 0.5982 - 0s 654us/step - loss: 6.0986 - accuracy: 0.6176 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 13/10000\n",
      "432/455 [===========================>..] 48/455 [==>...........................] - ETA: 0s - loss: 6.3158 - accuracy: 0.6042 - ETA: 0s - loss: 6.3105 - accuracy: 0.6042336/455 [=====================>........] - ETA: 0s - loss: 6.0749 - accuracy: 0.6455/455 [==============================] - 0s 701us/step - loss: 6.2769 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "144/455 [========>.................... - ETA: 0s - loss: 6.5319 - accuracy: 0.5903Epoch 15/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.0169 - accuracy: 0.6227 - ETA: 0s - loss: 6.3142 - accuracy: 0.60 - 0s 760us/step - loss: 6.0632 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.0891 - accuracy: 0.6181 - ETA: 0s - loss: 7.6391 - accuracy: 0.5208 - ETA: 0s - loss: 6.3166 - accuracy: 0.60 - ETA: 0s - loss: 5.7293 - accuracy: 0.64 - ETA: 0s - loss: 6.0507 - accuracy: 0.62 - ETA: 0s - loss: 6.5596 - accuracy: 0.58 - 0s 619us/step - loss: 5.8163 - accuracy: 0.6352 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 14/10000\n",
      " - ETA: 0s - loss: 6.3142 - accuracy: 0.6042TA: 0s - loss: 5.7763 - accuracy: 0.638 48/455 [==>...........................]336/455 [=====================>........] - ETA: 0s - loss: 6.0269 - accuracy: 0.144/455 [========>.....................]455/455 [==============================] - ETA: 0s - loss: 6.2035 - accuracy: 0.6111 - 0s 612us/step - loss: 6.0670 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "432/455 [===========================>..]Epoch 16/10000 - ETA: 0s - loss: 6.0530 - accuracy: 0.6204\n",
      "455/455 [==============================]240/455 [==============>...............] - ETA: 0s - loss: 5.3214 - accuracy: 0.6667 - ETA: 0s - loss: 6.7127 - accuracy: 0.57 - 0s 630us/step - loss: 6.0273 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 21/10000\n",
      "455/455 [==============================]432/455 [===========================>..]192/455 [===========>..................].]144/455 [========>.....................] - ETA: 0s - loss: 6.5504 - accuracy: 0.5893 - ETA: 0s - loss: 5.8762 - accuracy: 0.63 - ETA: 0s - loss: 6.2388 - accuracy: 0.6088 - ETA: 0s - loss: 5.7311 - accuracy: 0.6406 - ETA: 0s - loss: 6.3178 - accuracy: 0.60 - 0s 684us/step - loss: 6.1336 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 15/10000\n",
      "455/455 [==============================]336/455 [=====================>........] - ETA: 0s - loss: 6.1469 - accuracy: 0.6146 - ETA: 0s - loss: 6.4607 - accuracy: 0.5952 - ETA: 0s - loss: 4.9820 - accuracy: 0.68432/455 [===========================>..]384/455 [========================>.....] - ETA: 0s - loss: 6.3178 - accuracy: 0.6042 - ETA: 0s - loss: 5.9387 - accuracy: 0.62 - ETA: 0s - loss: 6.3963 - accuracy: 0.59 - 0s 710us/step - loss: 6.3489 - accuracy: 0.6022 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 17/10000\n",
      " - 0s 620us/step - loss: 5.9931 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.1469 - accuracy: 0.6146 - ETA: 0s - loss: 6.3142 - accuracy: 0.60 - ETA: 0s - loss: 6.2019 - accuracy: 0.61 - ETA: 0s - loss: 5.4820 - accuracy: 0.65 - 0s 550us/step - loss: 6.0986 - accuracy: 0.6176 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 16/10000\n",
      "455/455 [==============================]6204TA: 0s - loss: 6.0499 - accuracy: 0.6208 - ETA: 0s - loss: 5.9821 - accuracy: 0.336/455 [=====================>........]144/455 [========>.....................] - ETA: 0s - loss: 6.0780 - accuracy: 0.6190 - ETA: 0s - loss: 5.8713 - accuracy: 0.240/455 [==============>...............] - ETA: 0s - loss: 5.9813 - accuracy: 0.62 - 0s 625us/step - loss: 6.0666 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 18/10000\n",
      " 48/455 [==>...........................] - ETA: 0s - loss: 5.9802 - accuracy: 0.6250 - ETA: 0s - loss: 5.9894 - accuracy: 0.455/455 [==============================]192/455 [===========>..................] - 0s 543us/step - loss: 5.9931 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - ETA: 0s - loss: 6.4000 - accuracy: 0.5990Epoch 17/10000\n",
      "model type is NNClassifier 48/455 [==>...........................] - ETA: 0s - loss: 5.9784 - accuracy: 0.6250\n",
      "None336/455 [=====================>........]\n",
      "455/455 [==============================]60 - ETA: 0s - loss: 6.4766 - accuracy: 0.59 - 0s 460us/step - loss: 6.2083 - accuracy: 0.6110 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 19/10000\n",
      "455/455 [==============================]6399 48/455 [==>...........................] - ETA: 0s - loss: 4.9966 - accuracy: 0.68 - ETA: 0s - loss: 5.9045 - accuracy: 0.63 - 0s 485us/step - loss: 5.9218 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 18/10000\n",
      "455/455 [==============================]288/455 [=================>............] - ETA: 0s - loss: 5.9784 - accuracy: 0.6250 - ETA: 0s - loss: 5.8738 - accuracy: 0.144/455 [========>.....................] - ETA: 0s - loss: 6.0245 - accuracy: 0.6224 - ETA: 0s - loss: 5.4248 - accuracy: 0. - 0s 526us/step - loss: 6.0308 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "288/455 [=================>............]Epoch 20/10000 - ETA: 0s - loss: 5.4254 - accuracy: 0.6597\n",
      "455/455 [==============================] - ETA: 0s - loss: 7.6464 - accuracy: 0.52 - ETA: 0s - loss: 5.8312 - accuracy: 0.63 - ETA: 0s - loss: 6.2321 - accuracy: 0.60 - 0s 537us/step - loss: 5.9569 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 19/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 4.9820 - accuracy: 0.68 - ETA: 0s - loss: 5.8172 - accuracy: 0.63384/455 [========================>.....]192/455 [===========>..................] - ETA: 0s - loss: 5.9013 - accuracy: 0.6302 - ETA: 0s - loss: 5.6463 - accuracy: 0.64 - ETA: 0s - loss: 5.4802 - accuracy: 0.65 - 0s 605us/step - loss: 5.9627 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 21/10000\n",
      "455/455 [==============================]384/455 [========================>.....] - ETA: 0s - loss: 6.9748 - accuracy: 0.5625 - ETA: 0s - loss: 5.6463 - accuracy: 0. - ETA: 0s - loss: 6.4286 - accuracy: 0.5972 - 0s 616us/step - loss: 5.8514 - accuracy: 0.6330 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 20/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9821 - accuracy: 0.62 - ETA: 0s - loss: 6.1493 - accuracy: 0.61 - ETA: 0s - loss: 5.8963 - accuracy: 0.63 - ETA: 0s - loss: 6.2745 - accuracy: 0.60 - ETA: 0s - loss: 6.2636 - accuracy: 0.60 - 0s 617us/step - loss: 6.3835 - accuracy: 0.6000 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "455/455 [==============================] - 0s 474us/step - loss: 5.9569 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 21/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.6463 - accuracy: 0.64 - ETA: 0s - loss: 5.5651 - accuracy: 0.65 - ETA: 0s - loss: 5.9794 - accuracy: 0.62 - 0s 447us/step - loss: 6.0281 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "model type is NNClassifier\n",
      "None\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "455/455 [==============================] - ETA: 6s - loss: 4.8331 - accuracy: 0.37 - ETA: 0s - loss: 5.0059 - accuracy: 0.57 - ETA: 0s - loss: 5.3068 - accuracy: 0.59 - 1s 3ms/step - loss: 5.5999 - accuracy: 0.5890 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "432/455 [===========================>..] - ETA: 7s - loss: 3.7439 - accuracy: 0.60 - ETA: 0s - loss: 5.0939 - accuracy: 0.60 - ETA: 0s - loss: 5.4945 - accuracy: 0.6088Epoch 2/10000\n",
      " - ETA: 0s - loss: 5.2509 - accuracy: 0.6157TA: 0s - loss: 7.3182 - accuracy: 0.5417 - ETA: 8s - loss: 4.1172 - accuracy: 0.45 - ETA: 0s - loss: 6.9799 - accuracy: 0.55 - ETA: 2s - loss: 4.7083 - accuracy: 0.55 - ETA: 0s - loss: 6.5913 - accuracy: 0.58 - ETA: 0s - loss: 4.3423 - accuracy: 0. - ETA: 0s - loss: 6.4394 - accuracy: 0.5938 - ETA: 0s - loss: 4.9067 - accuracy: 0.6432/455 [===========================>..]455/455 [==============================] - 0s 556us/step - loss: 6.2066 - accuracy: 0.6088 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 3/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.9857 - accuracy: 0.62 - 1s 3ms/step - loss: 5.6392 - accuracy: 0.6022 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.8507 - accuracy: 0.57 - ETA: 0s - loss: 6.3607 - accuracy: 0.60 - 0s 365us/step - loss: 6.2099 - accuracy: 0.6110 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 4/10000\n",
      "240/455 [==============>...............] - ETA: 0s - loss: 5.6536 - accuracy: 0.64 - ETA: 0s - loss: 6.2485 - accuracy: 0.6083Epoch 2/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.2649 - accuracy: 0.6068 48/455 [==>...........................] - ETA: 0s - loss: 6.8994 - accuracy: 0. - 2s 4ms/step - loss: 5.3016 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "144/455 [========>.....................]455/455 [==============================] - 0s 444us/step - loss: 5.9881 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - ETA: 0s - loss: 7.4145 - accuracy: 0.5347Epoch 5/10000\n",
      " - ETA: 0s - loss: 6.1656 - accuracy: 0.6120TA: 0s - loss: 6.6536 - accuracy: 0.58 - ETA: 0s - loss: 6.3831 - accuracy: 0.60 - ETA: 0s - loss: 6.5680 - accuracy: 0.58 - ETA: 0s - loss: 6.4180 - accuracy: 0.59 - ETA: 0s - loss: 6.5400 - accuracy: 0.59432/455 [===========================>..] - ETA: 0s - loss: 6.1768 - accuracy: 0.61Epoch 2/100\n",
      "455/455 [==============================]455/455 [==============================] - 0s 759us/step - loss: 6.3220 - accuracy: 0.6022 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 539us/step - loss: 6.3266 - accuracy: 0.6022 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 6/10000Epoch 3/10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s - loss: 6.7633 - accuracy: 0.5764455 [==>...........................] 48/455 [==>...........................] - ETA: 0s - loss: 7.2500 - accuracy: 0.5417 - ETA: 0s - loss: 5.9857 - accuracy: 0.6250 - ETA: 0s - loss: 8.6830 - accuracy: 0.45144/455 [========>.....................]144/455 [========>.....................]144/455 [========>.....................] - ETA: 0s - loss: 5.9833 - accuracy: 0.6250 - ETA: 0s - loss: 7.2328 - accuracy: 0.5486 - ETA: 0s - loss: 6.3552 - accuracy: 0.59240/455 [==============>...............]240/455 [==============>.............. - ETA: 0s - loss: 6.3164 - accuracy: 0.6042 - ETA: 0s - loss: 6.2742 - accuracy: 0.6083 - ETA: 0s - loss: 6.4746 - accuracy: 0.336/455 [=====================>........] - ETA: 0s - loss: 5.9112 - accuracy: 432/455 [===========================>..]432/455 [===========================>..]288/455 [=================>............] - ETA: 0s - loss: 5.9635 - accuracy: 0.6250 - ETA: 0s - loss: 6.5580 - accuracy: 0.455/455 [==============================]455/455 [==============================] - 0s 719us/step - loss: 6.8785 - accuracy: 0.5692 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 730us/step - loss: 5.9427 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "336/455 [=====================>........]Epoch 4/10000 - ETA: 0s - loss: 6.2923 - accuracy: 0.6012Epoch 7/10000\n",
      "\n",
      " - ETA: 0s - loss: 6.5567 - accuracy: 0.5893455/455 [==============================]TA: 0s - loss: 5.6786 - accuracy: 0.6458 - ETA: 0s - loss: 6.3142 - accuracy: 0384/455 [========================>.....] - ETA: 0s - loss: 6.2959 - accuracy: 0.6016144/455 [========>.....................] - ETA: 0s - loss: 6.1133 - accuracy: 0.6432/455 [===========================>. - ETA: 0s - loss: 6.3193 - accuracy: 0.6042 - ETA: 0s - loss: 6.8696 - accuracy: 336/455 [=====================>........] - ETA: 0s - loss: 6.6692 - accuracy: 0.5833 - 1s 1ms/step - loss: 6.1552 - accuracy: 0.6110 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 3/10000\n",
      "432/455 [===========================>..]432/455 [===========================>..] 48/455 [==>...........................] - ETA: 0s - loss: 6.3949 - accuracy: 0.5995 - ETA: 0s - loss: 6.6529 - accuracy: 0.5833 - ETA: 0s - loss: 6.6630 - accuracy: 0.58455/455 [==============================]455/455 [==============================] - 0s 721us/step - loss: 6.6323 - accuracy: 0.5846 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 718us/step - loss: 6.3882 - accuracy: 0.6000 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 8/10000Epoch 5/100\n",
      "\n",
      "455/455 [==============================]6458TA: 0s - loss: 6.4329 - accuracy: 0.5972 48/455 [==>...........................] - ETA: 0s - loss: 6.3252 - accuracy: 0. - ETA: 0s - loss: 6.1212 - accuracy: 0.61 - ETA: 0s - loss: 5.5609 - accuracy: 0.6458 - ETA: 0s - loss: 6.5140 - accuracy: 0.59 - ETA: 0s - loss: 5.8341 - accuracy: 0.63 - ETA: 0s - loss: 6.2259 - accuracy: 0.61 - ETA: 0s - loss: 6.6458 - accuracy: 0. - ETA: 0s - loss: 6.1725 - accuracy: 0.61 - ETA: 0s - loss: 5.8299 - accuracy: 0.6319 - ETA: 0s - loss: 6.7331 - accuracy: 0.57 - 0s 796us/step - loss: 6.2463 - accuracy: 0.6088 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 4/10000\n",
      "455/455 [==============================]6276432/455 [===========================>..] - ETA: 0s - loss: 7.0180 - accuracy: 0.5602 - ETA: 0s - loss: 7.6500 - accuracy: 0.52 - 0s 710us/step - loss: 6.9101 - accuracy: 0.5670 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 6/100\n",
      "455/455 [==============================]144/455 [========>.....................] - 0s 752us/step - loss: 6.2502 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - ETA: 0s - loss: 6.9846 - accuracy: 0.5625Epoch 9/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.4023 - accuracy: 0.5990 - ETA: 0s - loss: 4.6572 - accuracy: 0.70 - ETA: 0s - loss: 6.7171 - accuracy: 0.57 - ETA: 0s - loss: 7.6830 - accuracy: 0. - ETA: 0s - loss: 6.6518 - accuracy: 0.5833192/455 [===========>..................] - ETA: 0s - loss: 5.4866 - accuracy: 0.65 - ETA: 0s - loss: 7.4786 - accuracy: 0. - ETA: 0s - loss: 5.6518 - accuracy: 0.64 - ETA: 0s - loss: 7.6840 - accuracy: 0.5384/455 [========================>.....] - ETA: 0s - loss: 5.7763 - accuracy: 0.63 - ETA: 0s - loss: 7.8691 - accuracy: 0.5093 - 0s 792us/step - loss: 6.3169 - accuracy: 0.6044 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 5/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6573 - accuracy: 0.58 - 0s 748us/step - loss: 7.7532 - accuracy: 0.5165 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 7/10000\n",
      "455/455 [==============================] - 0s 746us/step - loss: 5.8930 - accuracy: 0.6308 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 10/10000\n",
      "455/455 [==============================]288/455 [=================>............] - ETA: 0s - loss: 6.9876 - accuracy: 0.5625 ETA: 0s - loss: 5.5429 - accuracy: 0.6528 - ETA: 0s - loss: 8.3216 - accuracy: 0.144/455 [========>.....................]192/455 [===========>..................] - ETA: 0s - loss: 7.1360 - accuracy: 0.5486144/455 [========>.....................] - ETA: 0s - loss: 6.7644 - accuracy: 0.192/455 [===========>..................] - ETA: 0s - loss: 6.0989 - accuracy: 0.6181 - ETA: 0s - loss: 7.0183 - accuracy: 0.5384/455 [========================>....288/455 [=================>............]336/455 [=====================>........] - ETA: 0s - loss: 6.9310 - accuracy: 0.5660 - ETA: 0s - loss: 6.3900 - accuracy: 0.5990 - ETA: 0s - loss: 7.2556 - accuracy: 0.54 - ETA: 0s - loss: 6.4923 - accuracy: 0.59432/455 [===========================>..]384/455 [========================>.....] - ETA: 0s - loss: 7.3514 - accuracy: 0.5394 - ETA: 0s - loss: 6.4880 - accuracy: 0.59 - 0s 940us/step - loss: 6.3747 - accuracy: 0.6000 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 6/10000\n",
      "455/455 [==============================]455/455 [==============================] - 0s 840us/step - loss: 7.2624 - accuracy: 0.5451 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 828us/step - loss: 6.5976 - accuracy: 0.5868 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 8/10000\n",
      "Epoch 11/10000\n",
      " - 0s 750us/step - loss: 7.0954 - accuracy: 0.5560 - val_loss: 5.8735 - val_accuracy: 0.6316[==>...........................] - ETA: 0s - loss: 4.6572 - accuracy: 0.70 - ETA: 0s - loss: 6.0989 - accuracy: 0.61 - ETA: 0s - loss: 7.1233 - accuracy: 0.55 - ETA: 0s - loss: 5.9869 - accuracy: 0.62 - ETA: 0s - loss: 6.0536 - accuracy: 0. - ETA: 0s - loss: 5.9885 - accuracy: 0.6250240/455 [==============>...............] - ETA: 0s - loss: 6.9762 - accuracy: 0.56336/455 [=====================>........]240/455 [==============>...............] - ETA: 0s - loss: 6.0342 - accuracy: 0.6220 - ETA: 0s - loss: 5.8558 - accuracy: 0.63 - ETA: 0s - loss: 7.1286 - accuracy:  - ETA: 0s - loss: 6.0981 - accuracy: 0.6181336/455 [=====================>........] - ETA: 0s - loss: 6.2256 - accuracy: 0.6101 - ETA: 0s - loss: 7.1759 - accuracy: 0432/455 [===========================>..]\n",
      " - ETA: 0s - loss: 6.1723 - accuracy: 0.6134455/455 [==============================] - 0s 798us/step - loss: 6.0351 - accuracy: 0.6220 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 9/10000Epoch 7/10000\n",
      "\n",
      "\b 48/455 [==>...........................] - ETA: 0s - loss: 6.3252 - accuracy: 0.6042455/455 [==============================] 48/455 [==>...........................] - 0s 844us/step - loss: 6.1410 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - ETA: 0s - loss: 5.6499 - accuracy: 0.6458Epoch 12/10000\n",
      "432/455 [===========================>..]5764192/455 [===========>..................]/455 [========>.....................] - ETA: 0s - loss: 7.0935 - accuracy: 0.55 - ETA: 0s - loss: 5.0964 - accuracy: 0.68 - ETA: 0s - loss: 6.3865 - accuracy: 0.6000 - ETA: 0s - loss: 7.0736 - accuracy: 0.55 - ETA: 0s - loss: 5.5185 - accuracy: 0.65 - ETA: 0s - loss: 6.9732 - accuracy: 0.5625 - ETA: 0s - loss: 6.2735 - accuracy: 0.60 - ETA: 0s - loss: 6.1734 - accuracy: 0.61 - ETA: 0s - loss: 6.3596 - accuracy: 0.432/455 [===========================>..]455/455 [==============================] - ETA: 0s - loss: 5.9837 - accuracy: 0.6250 - 0s 690us/step - loss: 6.7302 - accuracy: 0.5780 - val_loss: 5.8735 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10000\n",
      " - 0s 768us/step - loss: 6.3188 - accuracy: 0.6044 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 8/10000......................... - ETA: 0s - loss: 7.6683 - accuracy: 0.5208455/455 [==============================]\n",
      " - 0s 733us/step - loss: 6.1371 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 13/10000\n",
      "432/455 [===========================>..]6339455 [=====>........................] - ETA: 0s - loss: 5.9894 - accuracy: 0.6250 - ETA: 0s - loss: 8.1739 - accuracy: 0.4896 48/455 [==>...........................] - ETA: 0s - loss: 6.9785 - accuracy: 0.56 - ETA: 0s - loss: 5.9918 - accuracy: 0.144/455 [========>.....................]192/455 [===========>..................] - ETA: 0s - loss: 6.4298 - accuracy: 0.5972 - ETA: 0s - loss: 7.2541 - accuracy: 0.54 - ETA: 0s - loss: 6.6580 - accuracy: 0. - ETA: 0s - loss: 5.5864 - accuracy: 0.6500 - ETA: 0s - loss: 6.9475 - accuracy: 0.56 - ETA: 0s - loss: 6.5619 - accuracy: 0.384/455 [========================>.....] - ETA: 0s - loss: 7.2103 - accuracy: 0.54 - ETA: 0s - loss: 6.3235 - accuracy: 0432/455 [===========================>..] - ETA: 0s - loss: 6.0218 - accuracy: 0.6227455/455 [==============================]455/455 [==============================] - 0s 725us/step - loss: 6.3554 - accuracy: 0.6022 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 847us/step - loss: 7.2464 - accuracy: 0.5473 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 9/10000Epoch 11/10000\n",
      "\n",
      " 48/455 [==>.......................... - ETA: 0s - loss: 5.9967 - accuracy: 0.6250 48/455 [==>...........................]455/455 [==============================] - ETA: 0s - loss: 5.9967 - accuracy: 0.6250 - 0s 789us/step - loss: 6.0682 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 14/10000\n",
      " - ETA: 0s - loss: 5.7814 - accuracy: 0.6380TA: 0s - loss: 7.3179 - accuracy: 0. - ETA: 0s - loss: 5.4145 - accuracy: 0.6615 - ETA: 0s - loss: 5.4082 - accuracy: 0.66 - ETA: 0s - loss: 5.5490 - accuracy: 0.65 - ETA: 0s - loss: 6.1315 - accuracy: 0.6288/455 [=================>............] - ETA: 0s - loss: 5.6031 - accuracy: 0.6493 - ETA: 0s - loss: 6.0543 - accuracy: 0.62 - ETA: 0s - loss: 6.2214 - accuracy: 0.6384/455 [========================>.....]336/455 [=====================>........] - ETA: 0s - loss: 6.2235 - accuracy: 0.61455/455 [==============================]432/455 [===========================>. - 0s 649us/step - loss: 6.4115 - accuracy: 0.5978 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "455/455 [==============================]6065Epoch 12/10000 - 0s 652us/step - loss: 5.9338 - accuracy: 0.6286 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "\n",
      "Epoch 10/10000\n",
      " - ETA: 0s - loss: 5.6572 - accuracy: 0.64585 [==>...........................] - ETA: 0s - loss: 8.3399 - accuracy: 0.4792455/455 [==============================] - 0s 656us/step - loss: 6.3862 - accuracy: 0.6000 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 15/10000\n",
      "432/455 [===========================>..] - ETA: 0s - loss: 7.6500 - accuracy: 0.52 - ETA: 0s - loss: 6.1037 - accuracy: 0.61 - ETA: 0s - loss: 6.4060 - accuracy: 0.59 - ETA: 0s - loss: 6.0952 - accuracy: 0.61 - ETA: 0s - loss: 6.1047 - accuracy: 0. - ETA: 0s - loss: 7.0428 - accuracy: 0.5590 - ETA: 0s - loss: 6.1865 - accuracy: 0.61 - ETA: 0s - loss: 6.3569 - accuracy: 0.60 - ETA: 0s - loss: 6.6143 - accuracy: 0.58 - ETA: 0s - loss: 6.1291 - accuracy: 0.61 - ETA: 0s - loss: 6.2014 - accuracy: 0.61 - ETA: 0s - loss: 6.1333 - accuracy: 0.61455/455 [==============================]455/455 [==============================] - 0s 687us/step - loss: 6.4612 - accuracy: 0.5956 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 671us/step - loss: 6.2738 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 13/10000Epoch 11/10000\n",
      "\n",
      " 48/455 [==>...........................]455/455 [==============================] - ETA: 0s - loss: 4.9966 - accuracy: 0.6875 48/455 [==>...........................] - ETA: 0s - loss: 6.3252 - accuracy: 0.6042 - 0s 680us/step - loss: 6.1741 - accuracy: 0.6132 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 16/10000\n",
      "432/455 [===========================>..] - ETA: 0s - loss: 5.9894 - accuracy: 0.62 - ETA: 0s - loss: 6.3203 - accuracy: 0.60 - ETA: 0s - loss: 6.4958 - accuracy: 0.59 - ETA: 0s - loss: 5.7655 - accuracy: 0.63 - ETA: 0s - loss: 6.2565 - accuracy: 0.60 - ETA: 0s - loss: 6.9408 - accuracy: 0. - ETA: 0s - loss: 5.9857 - accuracy: 0.6250 - ETA: 0s - loss: 6.0379 - accuracy: 0.62 - ETA: 0s - loss: 6.6342 - accuracy: 0.58 - ETA: 0s - loss: 6.1317 - accuracy: 0.61 - ETA: 0s - loss: 6.1402 - accuracy: 0.6432/455 [===========================>..] - ETA: 0s - loss: 6.4683 - accuracy: 0.5949455/455 [==============================]455/455 [==============================] - 0s 658us/step - loss: 6.6532 - accuracy: 0.5824 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 648us/step - loss: 6.0755 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 14/10000Epoch 12/10000\n",
      "\n",
      "455/455 [==============================] 48/455 [==>...........................] - ETA: 0s - loss: 5.9967 - accuracy: 0.6250 - ETA: 0s - loss: 3.6681 - accuracy: 0.77 - 0s 680us/step - loss: 6.4567 - accuracy: 0.5956 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 17/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 4.6572 - accuracy: 0.144/455 [========>.....................]144/455 [========>.....................] - ETA: 0s - loss: 5.6609 - accuracy: 0.6458 - ETA: 0s - loss: 5.3276 - accuracy: 0.66 - ETA: 0s - loss: 5.9027 - accuracy: 0. - ETA: 0s - loss: 6.0602 - accuracy: 0.6208240/455 [==============>...............] - ETA: 0s - loss: 5.8580 - accuracy: 0.63 - ETA: 0s - loss: 5.9845 - accuracy: 0.62 - ETA: 0s - loss: 6.5176 - accuracy: 0.59 - ETA: 0s - loss: 5.8976 - accuracy: 0.63 - ETA: 0s - loss: 5.9009 - accuracy: 0.63 - ETA: 0s - loss: 6.5873 - accuracy: 0.58 - ETA: 0s - loss: 5.9557 - accuracy: 0.62 - 0s 652us/step - loss: 6.7806 - accuracy: 0.5758 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 13/10000\n",
      "455/455 [==============================] - 0s 602us/step - loss: 5.7513 - accuracy: 0.6396 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 713us/step - loss: 6.0054 - accuracy: 0.6242 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 18/10000Epoch 15/10000\n",
      "\n",
      "455/455 [==============================] - ETA: 0s - loss: 5.6609 - accuracy: 0.6458 48/455 [==>...........................] 48/455 [==>...........................] - ETA: 0s - loss: 7.3106 - accuracy: 0.5417 - ETA: 0s - loss: 8.3180 - accuracy: 0.47 - ETA: 0s - loss: 6.3252 - accuracy: 0.144/455 [========>.....................]144/455 [========>.....................] - ETA: 0s - loss: 6.7607 - accuracy: 0.5764 - ETA: 0s - loss: 6.8734 - accuracy: 0.56 - ETA: 0s - loss: 6.2631 - accuracy: 0.240/455 [==============>...............]240/455 [==============>...............] - ETA: 0s - loss: 6.2529 - accuracy: 0.6083 - ETA: 0s - loss: 6.7176 - accuracy: 0.57 - ETA: 0s - loss: 6.3325 - accuracy: 0.60336/455 [=====================>........]336/455 [=====================>........] - ETA: 0s - loss: 6.2233 - accuracy: 0.6101 - ETA: 0s - loss: 6.3199 - accuracy: 0.60 - ETA: 0s - loss: 6.4047 - accuracy: 0.432/455 [===========================>..]432/455 [===========================>..] - ETA: 0s - loss: 6.0263 - accuracy: 0.62 - ETA: 0s - loss: 6.0959 - accuracy: 0.6181 - 0s 685us/step - loss: 6.5030 - accuracy: 0.5934 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 14/10000\n",
      " - 0s 737us/step - loss: 6.1035 - accuracy: 0.6176 - val_loss: 5.8735 - val_accuracy: 0.6316============================]\n",
      "455/455 [==============================] - 0s 735us/step - loss: 6.1433 - accuracy: 0.6154 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 19/10000\n",
      "Epoch 16/10000\n",
      " - 0s 589us/step - loss: 6.0674 - accuracy: 0.6198 - val_loss: 5.8735 - val_accuracy: 0.6316==>...........................] - ETA: 0s - loss: 6.9894 - accuracy: 0.5625 - ETA: 0s - loss: 6.7822 - accuracy: 0.57 - ETA: 0s - loss: 7.0940 - accuracy: 0.144/455 [========>.....................]240/455 [==============>...............] - ETA: 0s - loss: 5.9894 - accuracy: 0.6250 - ETA: 0s - loss: 6.8060 - accuracy: 0.57 - ETA: 0s - loss: 6.5171 - accuracy: 0.336/455 [=====================>........]240/455 [==============>...............] - ETA: 0s - loss: 5.7894 - accuracy: 0.6375 - ETA: 0s - loss: 7.1009 - accuracy: 0.55 - ETA: 0s - loss: 6.2334 - accuracy: 0.60 - ETA: 0s - loss: 7.1913 - accuracy: 0.55 - ETA: 0s - loss: 6.1333 - accuracy: 0.6455/455 [==============================]\n",
      "455/455 [============================= - 0s 684us/step - loss: 7.1443 - accuracy: 0.5538 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 20/10000432/455 [===========================>..]\n",
      "Epoch 15/10000 - ETA: 0s - loss: 6.2120 - accuracy: 0.6111\n",
      "455/455 [==============================] 48/455 [==>...........................] - ETA: 0s - loss: 6.9821 - accuracy: 0.5625 - ETA: 0s - loss: 7.3362 - accuracy: 0.54 - 0s 709us/step - loss: 6.2842 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 17/10000\n",
      "432/455 [===========================>..] - ETA: 0s - loss: 8.3216 - accuracy: 0.47144/455 [========>.....................]144/455 [========>.....................] - ETA: 0s - loss: 7.0892 - accuracy: 0.5556 - ETA: 0s - loss: 8.0066 - accuracy: 0.50 - ETA: 0s - loss: 6.9919 - accuracy: 0. - ETA: 0s - loss: 7.0859 - accuracy: 0.5542240/455 [==============>...............] - ETA: 0s - loss: 6.7806 - accuracy: 0.57 - ETA: 0s - loss: 7.1223 - accuracy: 0.55 - ETA: 0s - loss: 6.5066 - accuracy: 0.5923 - ETA: 0s - loss: 7.1564 - accuracy: 0.55 - ETA: 0s - loss: 6.6552 - accuracy: 0.432/455 [===========================>..]432/455 [===========================>..] - ETA: 0s - loss: 7.3295 - accuracy: 0.5394 - ETA: 0s - loss: 6.2436 - accuracy: 0.60 - ETA: 0s - loss: 6.3215 - accuracy: 0.455/455 [==============================]455/455 [==============================] - 0s 716us/step - loss: 7.2055 - accuracy: 0.5473 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 725us/step - loss: 6.3489 - accuracy: 0.6022 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 16/10000\n",
      "Epoch 21/10000\n",
      "455/455 [==============================] 48/455 [==>...........................] - 0s 667us/step - loss: 6.2122 - accuracy: 0.6110 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " 48/455 [==>...........................]Epoch 18/10000\n",
      "455/455 [==============================]6012 - ETA: 0s - loss: 5.9894 - accuracy: 0.62 - ETA: 0s - loss: 6.0978 - accuracy: 0.61 - ETA: 0s - loss: 7.9970 - accuracy: 0.50 - ETA: 0s - loss: 6.9931 - accuracy: 0.56 - ETA: 0s - loss: 5.6522 - accuracy: 0.64 - ETA: 0s - loss: 7.4440 - accuracy: 0.53 - ETA: 0s - loss: 6.6558 - accuracy: 0.58 - ETA: 0s - loss: 6.1740 - accuracy: 0.61 - ETA: 0s - loss: 7.0370 - accuracy: 0.5336/455 [=====================>........]432/455 [===========================>..] - ETA: 0s - loss: 6.0940 - accuracy: 0.61 - 0s 600us/step - loss: 6.8580 - accuracy: 0.5714 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 17/10000\n",
      " - ETA: 0s - loss: 8.0005 - accuracy: 0.50008/455 [==>...........................]455/455 [==============================] - 0s 677us/step - loss: 5.9261 - accuracy: 0.6264 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      " - 0s 715us/step - loss: 6.5299 - accuracy: 0.5912 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "192/455 [===========>..................] - ETA: 0s - loss: 7.7477 - accuracy: 0.5156Epoch 19/10000\n",
      "432/455 [===========================>..] - ETA: 0s - loss: 6.9858 - accuracy: 0.56 - ETA: 0s - loss: 6.9426 - accuracy: 0.56 - ETA: 0s - loss: 5.8242 - accuracy: 0.63 - ETA: 0s - loss: 6.6249 - accuracy: 0.336/455 [=====================>........]455/455 [==============================] - ETA: 0s - loss: 6.0848 - accuracy: 0.6190 - 0s 552us/step - loss: 6.6423 - accuracy: 0.5846 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 18/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.3252 - accuracy: 0.60 - 0s 499us/step - loss: 6.2846 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 20/100\n",
      "model type is NNClassifier336/455 [=====================>........]- accuracy: 0.6198 - ETA: 0s - loss: 8.3070 - accuracy: 0.47 - ETA: 0s - loss: 6.6056 - accuracy: 0.58 - ETA: 0s - loss: 6.3197 - accuracy: 0.60 - ETA: 0s - loss: 6.7372 - accuracy: 0.57 - ETA: 0s - loss: 6.0822 - accuracy: 0.6190\n",
      "455/455 [==============================]\n",
      " - 0s 544us/step - loss: 6.8187 - accuracy: 0.5736 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 19/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 7.3179 - accuracy: 0.54 - 0s 493us/step - loss: 5.6851 - accuracy: 0.6440 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 21/10000\n",
      "455/455 [==============================] ETA: 0s - loss: 6.9785 - accuracy: 0.5625 - ETA: 0s - loss: 5.9921 - accuracy: 0.62 - ETA: 0s - loss: 6.7376 - accuracy: 0.57 - ETA: 0s - loss: 6.2814 - accuracy: 0. - ETA: 0s - loss: 6.4399 - accuracy: 0.5972 - ETA: 0s - loss: 6.3690 - accuracy: 0.60 - 0s 520us/step - loss: 6.5364 - accuracy: 0.5912 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 20/10000\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.6573 - accuracy: 0.58 - 0s 494us/step - loss: 6.2775 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "455/455 [==============================] - ETA: 0s - loss: 6.9931 - accuracy: 0.56 - ETA: 0s - loss: 6.6583 - accuracy: 0.58 - 0s 445us/step - loss: 6.6396 - accuracy: 0.5846 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "Epoch 21/10000\n",
      "384/455 [========================>.....] - ETA: 0s - loss: 5.3398 - accuracy: 0.66 - ETA: 0s - loss: 6.5743 - accuracy: 0.58 - ETA: 0s - loss: 6.4347 - accuracy: 0.59 - ETA: 0s - loss: 6.4077 - accuracy: 0.5990model type is NNClassifier\n",
      "None\n",
      "455/455 [==============================] - 0s 567us/step - loss: 6.2877 - accuracy: 0.6066 - val_loss: 5.8735 - val_accuracy: 0.6316\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 456 samples, validate on 113 samples\n",
      "Epoch 1/10000\n",
      "Train on 456 samples, validate on 113 samples\n",
      "Train on 456 samples, validate on 113 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "456/456 [==============================] - ETA: 8s - loss: 5.0857 - accuracy: 0.35 - ETA: 0s - loss: 4.9920 - accuracy: 0.56 - ETA: 0s - loss: 5.9723 - accuracy: 0.54 - 1s 3ms/step - loss: 6.1166 - accuracy: 0.5461 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 2/10000\n",
      "456/456 [==============================]6111456 [==>...........................] - ETA: 0s - loss: 6.0719 - accuracy: 0.6042 - ETA: 8s - loss: 5.8010 - accuracy: 0.3958 - ETA: 8s - loss: 3.9114 - accuracy: 0.58 - ETA: 0s - loss: 6.7729 - accuracy: 0.144/456 [========>.....................] - ETA: 2s - loss: 4.8382 - accuracy: 0.56 - ETA: 0s - loss: 6.5086 - accuracy: 0.59 - ETA: 1s - loss: 5.1357 - accuracy: 0.59 - ETA: 1s - loss: 5.3724 - accuracy: 0.56 - ETA: 0s - loss: 6.6268 - accuracy: 0.58 - ETA: 0s - loss: 5.6183 - accuracy: 0.58 - ETA: 0s - loss: 5.4454 - accuracy: 0.59 - ETA: 0s - loss: 6.6372 - accuracy: 0.58 - ETA: 0s - loss: 5.5652 - accuracy: 0.60 - ETA: 0s - loss: 5.4586 - accuracy: 0.60 - 0s 730us/step - loss: 6.7098 - accuracy: 0.5789 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 3/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.0658 - accuracy: 0.60 - ETA: 0s - loss: 6.3525 - accuracy: 0.59 - ETA: 0s - loss: 6.4243 - accuracy: 0.59 - ETA: 0s - loss: 6.8775 - accuracy: 0.56 - 0s 474us/step - loss: 6.8317 - accuracy: 0.5702 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 4/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.6793 - accuracy: 0.58 - ETA: 0s - loss: 6.8690 - accuracy: 0.57 - ETA: 0s - loss: 6.6463 - accuracy: 0.58 - 2s 4ms/step - loss: 5.5524 - accuracy: 0.6053 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "456/456 [==============================] - 0s 404us/step - loss: 6.7203 - accuracy: 0.5789 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 5/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] 48/456 [==>...........................] - 2s 4ms/step - loss: 5.5062 - accuracy: 0.6118 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "456/456 [==============================]60 - ETA: 0s - loss: 6.6065 - accuracy: 0.58 - ETA: 0s - loss: 6.5601 - accuracy: 0.59 - 0s 372us/step - loss: 6.6709 - accuracy: 0.5833 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 6/10000\n",
      " 48/456 [==>...........................] - ETA: 0s - loss: 6.6646 - accuracy: 0.5833Epoch 2/10000\n",
      " - ETA: 0s - loss: 8.3436 - accuracy: 0.4792240/456 [==============>...............] - ETA: 0s - loss: 6.3989 - accuracy: 0.60Epoch 2/10000336/456 [=====================>........]144/456 [========>.....................]\n",
      " - 0s 478us/step - loss: 6.1416 - accuracy: 0.6140 - val_loss: 5.9255 - val_accuracy: 0.6283TA: 0s - loss: 5.3178 - accuracy: 0.6240/456 [==============>...............]456/456 [==============================]\n",
      " 96/456 [=====>........................]Epoch 7/10000\n",
      " - ETA: 0s - loss: 5.6499 - accuracy: 0.6458432/456 [===========================>..]62 - ETA: 0s - loss: 7.2704 - accuracy: 0. - ETA: 0s - loss: 5.9811 - accuracy: 0.625192/456 [===========>..................] - ETA: 0s - loss: 6.9127 - accuracy: 0.56288/456 [=================>............]456/456 [==============================] - 0s 713us/step - loss: 6.8647 - accuracy: 0.5680 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 3/10000\n",
      " - 0s 700us/step - loss: 6.7468 - accuracy: 0.5768 - val_loss: 5.9255 - val_accuracy: 0.6283 loss: 6.8247 - accuracy: 0.5714 - ETA: 0s - loss: 5.9009 - accuracy: 0.63 - ETA: 0s - loss: 7.1197 - accuracy: 0.5432/456 [===========================>..] - ETA: 0s - loss: 6.0210 - accuracy: 0.6227 - ETA: 0s - loss: 6.7149 - accuracy: 0.5240/456 [==============>..............456/456 [==============================]\n",
      "456/456 [==============================] - 0s 921us/step - loss: 6.0537 - accuracy: 0.6206 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 8/10000\n",
      "Epoch 3/10000\n",
      "240/456 [==============>...............]336/456 [=====================>........]625 - ETA: 0s - loss: 7.0990 - accuracy: 0.5565 - ETA: 0s - loss: 4.9893 - accuracy: 0.68 - ETA: 0s - loss: 6.2193 - accuracy: 0.6432/456 [===========================>..] - ETA: 0s - loss: 6.2059 - accuracy: 0.6111 - ETA: 0s - loss: 6.7064 - accuracy: 0.58 - ETA: 0s - loss: 6.2631 - accuracy: 0.456/456 [==============================] - ETA: 0s - loss: 6.0514 - accuracy: 0.6208 - 0s 766us/step - loss: 6.6339 - accuracy: 0.5855 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 4/10000\n",
      "144/456 [========>.....................] ETA: 0s - loss: 9.3253 - accuracy: 0.4167 - ETA: 0s - loss: 6.5788 - accuracy: 0.58 - ETA: 0s - loss: 6.1750 - accuracy: 0.61 - ETA: 0s - loss: 7.5277 - accuracy: 0.432/456 [===========================>..]456/456 [==============================] - ETA: 0s - loss: 6.1708 - accuracy: 0.6134 - 0s 659us/step - loss: 6.2055 - accuracy: 0.6118 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 9/10000\n",
      "456/456 [==============================]240/456 [==============>...............] - ETA: 0s - loss: 7.0004 - accuracy: 0.5625 - ETA: 0s - loss: 6.6781 - accuracy: 0.57 - 0s 762us/step - loss: 6.2667 - accuracy: 0.6075 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 4/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3778 - accuracy: 0.6012456 [========>.....................]336/456 [=====================>........] - ETA: 0s - loss: 6.7778 - accuracy: 0.5764 - ETA: 0s - loss: 6.8145 - accuracy: 0.57 - ETA: 0s - loss: 7.2011 - accuracy: 0.432/456 [===========================>..]240/456 [==============>...............] - ETA: 0s - loss: 6.8159 - accuracy: 0.5718 - ETA: 0s - loss: 6.4668 - accuracy: 0.59 - ETA: 0s - loss: 6.6505 - accuracy: 0.5336/456 [=====================>........] - 0s 734us/step - loss: 6.8429 - accuracy: 0.5702 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 5/10000\n",
      "456/456 [==============================]5208: 0s - loss: 9.6465 - accuracy: 0.3958 - ETA: 0s - loss: 5.9376 - accuracy: 0.62 - ETA: 0s - loss: 6.3296 - accuracy: 0.60432/456 [===========================>..] - ETA: 0s - loss: 5.9483 - accuracy: 0.62 - 0s 709us/step - loss: 6.2774 - accuracy: 0.6075 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 10/10000\n",
      "240/456 [==============>...............] - ETA: 0s - loss: 7.9932 - accuracy: 0.456/456 [==============================] - ETA: 0s - loss: 6.8588 - accuracy: 0.5708 - 0s 699us/step - loss: 5.8450 - accuracy: 0.6316 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 5/10000\n",
      "336/456 [=====================>........] ETA: 0s - loss: 6.9858 - accuracy: 0.5625 - ETA: 0s - loss: 6.7982 - accuracy: 0.5694 - ETA: 0s - loss: 6.8518 - accuracy: 0.57 - ETA: 0s - loss: 5.9857 - accuracy: 0.62 - ETA: 0s - loss: 7.0141 - accuracy: 0.55 - ETA: 0s - loss: 6.8828 - accuracy: 0.56 - ETA: 0s - loss: 6.1164 - accuracy: 0.6456/456 [==============================] - ETA: 0s - loss: 6.7245 - accuracy: 0.5774 - 0s 723us/step - loss: 6.8713 - accuracy: 0.5702 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 6/10000\n",
      "432/456 [===========================>..] - ETA: 0s - loss: 6.2236 - accuracy: 0.60 - ETA: 0s - loss: 6.0004 - accuracy: 0.6250 - ETA: 0s - loss: 6.4906 - accuracy: 0432/456 [===========================>..]144/456 [========>.....................] - ETA: 0s - loss: 6.0957 - accuracy: 0.6157456/456 [==============================] - ETA: 0s - loss: 5.7783 - accuracy: 0.6389 - 0s 689us/step - loss: 6.5001 - accuracy: 0.5921 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 11/10000\n",
      "456/456 [==============================] ETA: 0s - loss: 5.6792 - accuracy: 0.6458 - 0s 687us/step - loss: 6.0196 - accuracy: 0.6206 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 6/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.1949 - accuracy: 0.6125 - ETA: 0s - loss: 5.9857 - accuracy: 0.62 - ETA: 0s - loss: 6.4456 - accuracy: 0.59 - ETA: 0s - loss: 5.9448 - accuracy: 0.62 - ETA: 0s - loss: 5.6536 - accuracy: 0.64 - ETA: 0s - loss: 6.6033 - accuracy: 0.58 - ETA: 0s - loss: 5.8809 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 7.1939 - accuracy: 0.55 - 0s 700us/step - loss: 5.9579 - accuracy: 0.6272 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 7/10000\n",
      " - ETA: 0s - loss: 6.7717 - accuracy: 0.5764TA: 0s - loss: 5.8418 - accuracy: 0.63 48/456 [==>...........................]432/456 [===========================>..] - ETA: 0s - loss: 7.9895 - accuracy: 0.5000 - ETA: 0s - loss: 6.9479 - accuracy: 0.56 - ETA: 0s - loss: 5.9464 - accuracy: 0.6144/456 [========>.....................]456/456 [==============================] - 0s 713us/step - loss: 6.8277 - accuracy: 0.5724 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "456/456 [==============================]Epoch 12/10000\n",
      " - 0s 646us/step - loss: 6.0887 - accuracy: 0.6184 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 7/10000\n",
      "336/456 [=====================>........]5648240/456 [==============>...............] 48/456 [==>...........................] - ETA: 0s - loss: 6.9953 - accuracy: 0.5625 - ETA: 0s - loss: 5.9784 - accuracy: 0.62 - ETA: 0s - loss: 4.6621 - accuracy: 0.7336/456 [=====================>........]144/456 [========>.....................] - ETA: 0s - loss: 5.4248 - accuracy: 0.65 - ETA: 0s - loss: 5.2616 - accuracy: 0.6432/456 [===========================>..]240/456 [==============>...............] - ETA: 0s - loss: 5.4499 - accuracy: 0.65 - ETA: 0s - loss: 5.6661 - accuracy: 0.336/456 [=====================>........]456/456 [==============================] - ETA: 0s - loss: 5.6515 - accuracy: 0.6458 - 0s 775us/step - loss: 6.9779 - accuracy: 0.5636 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 8/10000432/456 [===========================>..]\n",
      "456/456 [==============================]6343 48/456 [==>...........................] - ETA: 0s - loss: 6.6646 - accuracy: 0.58 - 0s 692us/step - loss: 6.0349 - accuracy: 0.6228 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 13/10000\n",
      "456/456 [==============================] 48/456 [==>...........................] - 0s 745us/step - loss: 5.8818 - accuracy: 0.6294 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 8/10000loss: 4.6718 - accuracy: 0.70144/456 [========>.....................]\n",
      "456/456 [==============================] - ETA: 0s - loss: 5.6047 - accuracy: 0.650000 - ETA: 0s - loss: 5.6719 - accuracy: 0.64 - ETA: 0s - loss: 6.7325 - accuracy: 0.57 - ETA: 0s - loss: 5.2046 - accuracy: 0.6240/456 [==============>...............] - ETA: 0s - loss: 6.7600 - accuracy: 0.57 - ETA: 0s - loss: 5.6477 - accuracy: 0.6458384/456 [========================>.....]288/456 [=================>............] - ETA: 0s - loss: 6.4976 - accuracy: 0.5938 - ETA: 0s - loss: 5.9468 - accuracy: 0.62 - ETA: 0s - loss: 5.7907 - accuracy: 0. - ETA: 0s - loss: 6.0843 - accuracy: 0.6198 - 0s 769us/step - loss: 6.2785 - accuracy: 0.6075 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 9/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 5.7590 - accuracy: 0.6389 - ETA: 0s - loss: 6.3435 - accuracy: 0.60 - 0s 782us/step - loss: 6.3507 - accuracy: 0.6031 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 14/10000\n",
      "456/456 [==============================] - 0s 746us/step - loss: 5.9112 - accuracy: 0.6294 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 9/10000\n",
      "336/456 [=====================>........] ETA: 0s - loss: 6.9894 - accuracy: 0.5625 - ETA: 0s - loss: 7.1647 - accuracy: 0.5521 - ETA: 0s - loss: 5.6499 - accuracy: 0.64 - ETA: 0s - loss: 7.1136 - accuracy: 0. - ETA: 0s - loss: 7.0527 - accuracy: 0.5590144/456 [========>.....................] - ETA: 0s - loss: 5.7631 - accuracy: 0. - ETA: 0s - loss: 7.0712 - accuracy: 0.55 - ETA: 0s - loss: 6.9957 - accuracy: 0.5625 - ETA: 0s - loss: 5.8536 - accuracy: 0.63 - ETA: 0s - loss: 6.9577 - accuracy: 0.5456/456 [==============================] - ETA: 0s - loss: 6.1781 - accuracy: 0.6131 - 0s 699us/step - loss: 7.1190 - accuracy: 0.5548 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.7072 - accuracy: 0.5810 - ETA: 0s - loss: 7.3472 - accuracy: 0.54 - ETA: 0s - loss: 6.3195 - accuracy: 0.60 - 0s 687us/step - loss: 6.8110 - accuracy: 0.5746 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 15/10000\n",
      "144/456 [========>.....................] - ETA: 0s - loss: 5.8909 - accuracy: 0.63 48/456 [==>...........................]456/456 [==============================] - ETA: 0s - loss: 5.6682 - accuracy: 0.6458 - 0s 745us/step - loss: 6.2669 - accuracy: 0.6075 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 10/10000\n",
      "432/456 [===========================>..]5958TA: 0s - loss: 7.9858 - accuracy: 0.5000240/456 [==============>.............. - ETA: 0s - loss: 6.5318 - accuracy: 0.5917 - ETA: 0s - loss: 7.0029 - accuracy: 0. - ETA: 0s - loss: 6.6536 - accuracy: 0.58336/456 [=====================>........]240/456 [==============>...............] - ETA: 0s - loss: 6.5687 - accuracy: 0.5893 - ETA: 0s - loss: 6.4011 - accuracy: 0. - ETA: 0s - loss: 6.4795 - accuracy: 0.595240/456 [==============>...............]432/456 [===========================>..] - ETA: 0s - loss: 6.6622 - accuracy: 0. - ETA: 0s - loss: 6.4846 - accuracy: 0.59336/456 [=====================>........]456/456 [==============================] - ETA: 0s - loss: 6.2699 - accuracy: 0.6071 - 0s 808us/step - loss: 6.8725 - accuracy: 0.5702 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 11/10000\n",
      "456/456 [==============================] - 0s 746us/step - loss: 6.5290 - accuracy: 0.5921 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 16/1000\n",
      "456/456 [==============================]6250432/456 [===========================>..] - ETA: 0s - loss: 6.1321 - accuracy: 0.6157 - ETA: 0s - loss: 6.3398 - accuracy: 0. - 0s 830us/step - loss: 6.0894 - accuracy: 0.6184 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "144/456 [========>.....................]Epoch 11/10000 - ETA: 0s - loss: 5.7667 - accuracy: 0.6389\n",
      " - 0s 835us/step - loss: 5.8855 - accuracy: 0.6316 - val_loss: 5.9255 - val_accuracy: 0.62830s - loss: 5.3281 - accuracy: 0.6240/456 [==============>...............] - ETA: 0s - loss: 6.2580 - accuracy: 0.6083 - ETA: 0s - loss: 6.9997 - accuracy: 0.56 - ETA: 0s - loss: 5.9892 - accuracy: 0.62 - ETA: 0s - loss: 5.9445 - accuracy: 0. - ETA: 0s - loss: 6.8112 - accuracy: 0.5744 - ETA: 0s - loss: 6.2550 - accuracy: 0.432/456 [===========================>..]384/456 [========================>.....] - ETA: 0s - loss: 5.9541 - accuracy: 0.6273 - ETA: 0s - loss: 6.9607 - accuracy: 0.56 - ETA: 0s - loss: 6.2673 - accuracy: 0.60\n",
      "384/456 [========================>.....] - ETA: 0s - loss: 6.1138 - accuracy: 0.6172Epoch 12/100\n",
      "456/456 [==============================] - 0s 782us/step - loss: 6.8433 - accuracy: 0.5724 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 17/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 5.3214 - accuracy: 0.6667 - ETA: 0s - loss: 5.6682 - accuracy:  - 0s 785us/step - loss: 6.3391 - accuracy: 0.6031 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "144/456 [========>.....................]144/456 [========>.....................] - ETA: 0s - loss: 5.5514 - accuracy: 0.6528 - ETA: 0s - loss: 5.6524 - accuracy: 0.6458Epoch 12/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 2.6644 - accuracy: 0. - ETA: 0s - loss: 5.9288 - accuracy: 0.6292240/456 [==============>...............] - ETA: 0s - loss: 6.1178 - accuracy: 0.61144/456 [========>.....................]288/456 [=================>............] - ETA: 0s - loss: 5.1025 - accuracy: 0.6806 - ETA: 0s - loss: 5.9371 - accuracy: 0.62 - ETA: 0s - loss: 6.1781 - accuracy: 0.384/456 [========================>.....]240/456 [==============>...............] - ETA: 0s - loss: 5.9520 - accuracy: 0.6276 - ETA: 0s - loss: 5.9244 - accuracy: 0.62 - ETA: 0s - loss: 6.2477 - accuracy: 0 - ETA: 0s - loss: 6.1797 - accuracy: 0.6131456/456 [==============================] - 0s 793us/step - loss: 6.3042 - accuracy: 0.6053 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      " - 0s 768us/step - loss: 6.1690 - accuracy: 0.6140 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 13/10000Epoch 18/10000\n",
      "\n",
      "144/456 [========>.....................] 48/456 [==>...........................] - ETA: 0s - loss: 4.9930 - accuracy: 0.6875 - ETA: 0s - loss: 5.9930 - accuracy: 0.62 - ETA: 0s - loss: 5.9522 - accuracy: 0. - ETA: 0s - loss: 5.4598 - accuracy: 0.65456/456 [==============================]144/456 [========>.....................] - 0s 796us/step - loss: 5.9190 - accuracy: 0.6294 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      " - ETA: 0s - loss: 6.4359 - accuracy: 0.5972Epoch 13/10000\n",
      "288/456 [=================>............]6019: 0s - loss: 6.6683 - accuracy: 0.5833 - ETA: 0s - loss: 5.4096 - accuracy: 0.6583 - ETA: 0s - loss: 6.2573 - accuracy: 0.288/456 [=================>............]144/456 [========>.....................] - ETA: 0s - loss: 5.8390 - accuracy: 0.6319 - ETA: 0s - loss: 6.9919 - accuracy: 0.56 - ETA: 0s - loss: 6.3257 - accuracy: 0.60 - ETA: 0s - loss: 6.2931 - accuracy: 0.6432/456 [===========================>..]240/456 [==============>...............] - ETA: 0s - loss: 6.8595 - accuracy: 0.57 - ETA: 0s - loss: 6.8918 - accuracy: 0.5456/456 [==============================] - 0s 751us/step - loss: 6.4840 - accuracy: 0.5943 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "456/456 [==============================] - 0s 765us/step - loss: 6.2461 - accuracy: 0.6075 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 14/10000\n",
      "Epoch 19/10000\n",
      "456/456 [==============================]6458TA: 0s - loss: 6.3178 - accuracy: 0.604 48/456 [==>...........................]384/456 [========================>.....] - ETA: 0s - loss: 6.7501 - accuracy: 0.57432/456 [===========================>..]144/456 [========>.....................] 96/456 [=====>........................] - ETA: 0s - loss: 6.5490 - accuracy: 0.5903 - ETA: 0s - loss: 6.7402 - accuracy: 0.5764 - ETA: 0s - loss: 4.8324 - accuracy: 0.6192/456 [===========>.................240/456 [==============>...............] - ETA: 0s - loss: 6.9274 - accuracy: 0.5667 - 0s 911us/step - loss: 6.6306 - accuracy: 0.5833 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 14/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/456 [==============>...............] - ETA: 0s - loss: 4.6572 - accuracy: 0. - ETA: 0s - loss: 5.9450 - accuracy: 0.6285 - ETA: 0s - loss: 7.1365 - accuracy: 0. - ETA: 0s - loss: 5.5478 - accuracy: 0.6528 - ETA: 0s - loss: 6.4164 - accuracy: 0.59 - ETA: 0s - loss: 6.9566 - accuracy: 0.56 - ETA: 0s - loss: 5.6602 - accuracy: 0.64456/456 [==============================]456/456 [==============================] - 0s 780us/step - loss: 6.7653 - accuracy: 0.5768 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      " - 0s 761us/step - loss: 6.5586 - accuracy: 0.5899 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 20/10000Epoch 15/10000\n",
      "\n",
      "456/456 [==============================]5856TA: 0s - loss: 5.9920 - accuracy: 0.6250 48/456 [==>...........................] 48/456 [==>...........................] - ETA: 0s - loss: 5.9967 - accuracy: 0.6250 - ETA: 0s - loss: 6.9821 - accuracy: 0. 96/456 [=====>........................] - ETA: 0s - loss: 6.8179 - accuracy: 0.57 - ETA: 0s - loss: 6.8812 - accuracy: 0.56 - 0s 770us/step - loss: 6.5889 - accuracy: 0.5877 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 15/100\n",
      "456/456 [==============================]5833456 [==============>...............] - ETA: 0s - loss: 6.6537 - accuracy: 0.5833 - ETA: 0s - loss: 6.9909 - accuracy: 0.5625 - ETA: 0s - loss: 6.6536 - accuracy: 0.240/456 [==============>...............]288/456 [=================>............] - ETA: 0s - loss: 6.5909 - accuracy: 0.5875 - ETA: 0s - loss: 6.9919 - accuracy: 0.56 - ETA: 0s - loss: 6.4359 - accuracy: 0.5336/456 [=====================>........]288/456 [=================>............] - ETA: 0s - loss: 6.3787 - accuracy: 0. - ETA: 0s - loss: 6.3931 - accuracy: 0.60 - ETA: 0s - loss: 6.7025 - accuracy: 0.5807 - ETA: 0s - loss: 6.1823 - accuracy: 0.61 - ETA: 0s - loss: 6.2308 - accuracy: 0.61 - ETA: 0s - loss: 6.2141 - accuracy: 0.6111 - 0s 922us/step - loss: 6.7315 - accuracy: 0.5789 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 21/10000\n",
      " - ETA: 0s - loss: 4.8148 - accuracy: 0.68758/456 [==>...........................]456/456 [==============================] - 0s 1ms/step - loss: 6.3772 - accuracy: 0.6009 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 16/10000\n",
      " 48/456 [==>...........................] - ETA: 0s - loss: 5.3251 - accuracy: 0.6456/456 [==============================] - 0s 782us/step - loss: 5.8858 - accuracy: 0.6316 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "144/456 [========>.....................]Epoch 16/10000 - ETA: 0s - loss: 6.1563 - accuracy: 0.6111\n",
      "456/456 [==============================]]144/456 [========>.....................]192/456 [===========>..................] - ETA: 0s - loss: 5.3288 - accuracy: 0.6667 - ETA: 0s - loss: 6.4434 - accuracy: 0.5903 - ETA: 0s - loss: 6.2843 - accuracy: 0.144/456 [========>.....................]288/456 [=================>............] - ETA: 0s - loss: 5.3300 - accuracy: 0.6667 - ETA: 0s - loss: 6.1878 - accuracy: 0.61 - ETA: 0s - loss: 6.0625 - accuracy: 0.61384/456 [========================>.....]240/456 [==============>.............. - ETA: 0s - loss: 6.1816 - accuracy: 0.6120 - ETA: 0s - loss: 5.3974 - accuracy: 0.6625 - ETA: 0s - loss: 6.3769 - accuracy: 0.59288/456 [=================>............]432/456 [===========================>..] - ETA: 0s - loss: 5.3294 - accuracy: 0.6667 - ETA: 0s - loss: 6.2705 - accuracy: 0.60 - ETA: 0s - loss: 6.4408 - accuracy: 0. - 0s 890us/step - loss: 6.1852 - accuracy: 0.6118 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      " - ETA: 0s - loss: 5.4953 - accuracy: 0.6562456/456 [==============================] - 0s 809us/step - loss: 6.3474 - accuracy: 0.6009 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 17/10000\n",
      "456/456 [==============================] ETA: 0s - loss: 5.9894 - accuracy: 0.6250 - 0s 837us/step - loss: 5.8536 - accuracy: 0.6338 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 17/10000\n",
      " - ETA: 0s - loss: 6.5523 - accuracy: 0.5903TA: 0s - loss: 6.6646 - accuracy: 0.58 - ETA: 0s - loss: 6.5788 - accuracy: 0.5192/456 [===========>..................]288/456 [=================>............] - ETA: 0s - loss: 6.4700 - accuracy: 0.59 - ETA: 0s - loss: 6.4785 - accuracy: 0.59 - ETA: 0s - loss: 6.3773 - accuracy: 0.60456/456 [==============================] - 0s 571us/step - loss: 6.4372 - accuracy: 0.5965 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 18/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 9.0079 - accuracy: 0.43 - 0s 592us/step - loss: 6.5232 - accuracy: 0.5921 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 18/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.6573 - accuracy: 0.58 - ETA: 0s - loss: 7.0461 - accuracy: 0.55 - ETA: 0s - loss: 6.3301 - accuracy: 0.60 - ETA: 0s - loss: 6.8083 - accuracy: 0.57 - ETA: 0s - loss: 6.8595 - accuracy: 0.57 - ETA: 0s - loss: 6.7746 - accuracy: 0.57 - ETA: 0s - loss: 6.4717 - accuracy: 0.59 - 0s 602us/step - loss: 6.8553 - accuracy: 0.5702 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 19/10000\n",
      "456/456 [==============================] - 0s 568us/step - loss: 6.3104 - accuracy: 0.6053 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      " 48/456 [==>...........................]Epoch 19/10000model type is NNClassifier - ETA: 0s - loss: 6.6573 - accuracy: 0.5833\n",
      "\n",
      "None\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3325 - accuracy: 0.60 - ETA: 0s - loss: 5.4164 - accuracy: 0.66 - ETA: 0s - loss: 6.3261 - accuracy: 0.60 - ETA: 0s - loss: 6.1658 - accuracy: 0.61 - ETA: 0s - loss: 6.6604 - accuracy: 0.58 - ETA: 0s - loss: 6.2089 - accuracy: 0.61 - ETA: 0s - loss: 6.4100 - accuracy: 0.59 - 0s 583us/step - loss: 6.4203 - accuracy: 0.5987 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 20/10000\n",
      "456/456 [==============================] - 0s 597us/step - loss: 6.3104 - accuracy: 0.6053 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      " 48/456 [==>...........................] - ETA: 0s - loss: 8.0115 - accuracy: 0.5000Epoch 20/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3325 - accuracy: 0.60 - ETA: 0s - loss: 7.0871 - accuracy: 0.55 - ETA: 0s - loss: 6.2145 - accuracy: 0.61 - ETA: 0s - loss: 6.9633 - accuracy: 0.56 - ETA: 0s - loss: 6.3281 - accuracy: 0.60 - ETA: 0s - loss: 6.8256 - accuracy: 0.57 - ETA: 0s - loss: 6.4340 - accuracy: 0.59 - 0s 588us/step - loss: 6.8525 - accuracy: 0.5702 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 21/10000\n",
      " 48/456 [==>...........................]456/456 [==============================] - ETA: 0s - loss: 5.6719 - accuracy: 0.6458 - 0s 609us/step - loss: 6.4244 - accuracy: 0.5965 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 21/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.6464 - accuracy: 0.52 - ETA: 0s - loss: 6.4137 - accuracy: 0.59 - ETA: 0s - loss: 7.1001 - accuracy: 0.55 - ETA: 0s - loss: 6.1646 - accuracy: 0.61 - ETA: 0s - loss: 7.1968 - accuracy: 0.55 - ETA: 0s - loss: 6.1628 - accuracy: 0.61 - ETA: 0s - loss: 6.7928 - accuracy: 0.57 - 0s 567us/step - loss: 6.3822 - accuracy: 0.6009 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "456/456 [==============================] - 0s 551us/step - loss: 6.8433 - accuracy: 0.5724 - val_loss: 4.3737 - val_accuracy: 0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-01 08:38:19,806] Finished trial#0 with value: 5.939844148726479 with parameters: {'input_dropout': 0.5488135039273248, 'hidden_layers': 2, 'hidden_units': 896.0, 'hidden_dropout': 0.8579456176227568, 'batch_norm': 'non', 'batch_size': 48.0}. Best is trial#0 with value: 5.939844148726479."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/10000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "456/456 [==============================] - ETA: 0s - loss: 5.6682 - accuracy: 0.64 - ETA: 0s - loss: 6.2920 - accuracy: 0.60 - ETA: 0s - loss: 6.3948 - accuracy: 0.59 - 0s 393us/step - loss: 6.3345 - accuracy: 0.6031 - val_loss: 1.8450 - val_accuracy: 0.8850\n",
      "Epoch 23/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.0151 - accuracy: 0.50 - ETA: 0s - loss: 6.6857 - accuracy: 0.58 - ETA: 0s - loss: 6.6855 - accuracy: 0.58 - 0s 417us/step - loss: 6.8967 - accuracy: 0.5702 - val_loss: 1.7054 - val_accuracy: 0.8938\n",
      "Epoch 24/10000\n",
      "384/456 [========================>.....] - ETA: 0s - loss: 5.0076 - accuracy: 0.68 - ETA: 0s - loss: 6.6730 - accuracy: 0.58 - ETA: 0s - loss: 6.3875 - accuracy: 0.6016model type is NNClassifier\n",
      "None\n",
      "456/456 [==============================] - 0s 427us/step - loss: 6.3648 - accuracy: 0.6031 - val_loss: 1.6419 - val_accuracy: 0.8938\n",
      "Epoch 25/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3471 - accuracy: 0.60 - ETA: 0s - loss: 6.8453 - accuracy: 0.57 - ETA: 0s - loss: 6.8253 - accuracy: 0.57 - 0s 385us/step - loss: 6.8564 - accuracy: 0.5724 - val_loss: 1.6992 - val_accuracy: 0.8938\n",
      "Epoch 26/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.6939 - accuracy: 0.58 - ETA: 0s - loss: 7.7501 - accuracy: 0.51 - ETA: 0s - loss: 7.8298 - accuracy: 0.51 - 0s 369us/step - loss: 7.7700 - accuracy: 0.5154 - val_loss: 1.6299 - val_accuracy: 0.8938\n",
      "Epoch 27/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 5.0149 - accuracy: 0.68 - ETA: 0s - loss: 6.2876 - accuracy: 0.60 - ETA: 0s - loss: 6.6010 - accuracy: 0.58 - 0s 399us/step - loss: 6.5784 - accuracy: 0.5877 - val_loss: 1.6402 - val_accuracy: 0.8938\n",
      "Epoch 28/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-01 08:38:21,190]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Finished trial#2 with value: 5.939844148726479 with parameters: {'input_dropout': 0.7917250380826646, 'hidden_layers': 3, 'hidden_units': 640.0, 'hidden_dropout': 0.925596638292661, 'batch_norm': 'non', 'batch_size': 48.0}. Best is trial#0 with value: 5.939844148726479."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48/456 [==>...........................] - ETA: 0s - loss: 8.7123 - accuracy: 0.4583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - ETA: 0s - loss: 7.3472 - accuracy: 0.54 - ETA: 0s - loss: 7.2730 - accuracy: 0.54 - 0s 364us/step - loss: 7.3820 - accuracy: 0.5395 - val_loss: 1.9767 - val_accuracy: 0.8761\n",
      "Epoch 29/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.0224 - accuracy: 0.50 - ETA: 0s - loss: 7.9312 - accuracy: 0.50 - ETA: 0s - loss: 7.2022 - accuracy: 0.55 - 0s 462us/step - loss: 7.0304 - accuracy: 0.5614 - val_loss: 2.3984 - val_accuracy: 0.8496\n",
      "Epoch 30/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.3399 - accuracy: 0.54 - ETA: 0s - loss: 6.4070 - accuracy: 0.60 - ETA: 0s - loss: 6.9729 - accuracy: 0.56 - 0s 353us/step - loss: 6.9928 - accuracy: 0.5636 - val_loss: 2.3984 - val_accuracy: 0.8496\n",
      "Epoch 31/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.3473 - accuracy: 0.47 - ETA: 0s - loss: 7.6136 - accuracy: 0.52 - ETA: 0s - loss: 7.0868 - accuracy: 0.55 - 0s 347us/step - loss: 7.1003 - accuracy: 0.5570 - val_loss: 2.3984 - val_accuracy: 0.8496\n",
      "Epoch 32/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3471 - accuracy: 0.60 - ETA: 0s - loss: 6.5222 - accuracy: 0.59 - 0s 301us/step - loss: 6.6850 - accuracy: 0.5811 - val_loss: 3.5271 - val_accuracy: 0.7788\n",
      "Epoch 33/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3398 - accuracy: 0.60 - ETA: 0s - loss: 6.5661 - accuracy: 0.59 - 0s 308us/step - loss: 6.5018 - accuracy: 0.5943 - val_loss: 4.7968 - val_accuracy: 0.6991\n",
      "Epoch 34/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.0077 - accuracy: 0.56 - ETA: 0s - loss: 7.0661 - accuracy: 0.55 - 0s 314us/step - loss: 6.9905 - accuracy: 0.5636 - val_loss: 5.6433 - val_accuracy: 0.6460\n",
      "Epoch 35/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.3435 - accuracy: 0.54 - ETA: 0s - loss: 5.9347 - accuracy: 0.62 - ETA: 0s - loss: 5.9290 - accuracy: 0.62 - 0s 348us/step - loss: 6.0031 - accuracy: 0.6250 - val_loss: 5.7844 - val_accuracy: 0.6372\n",
      "Epoch 36/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.0040 - accuracy: 0.62 - ETA: 0s - loss: 6.7347 - accuracy: 0.57 - ETA: 0s - loss: 6.5862 - accuracy: 0.58 - 0s 387us/step - loss: 6.4226 - accuracy: 0.5987 - val_loss: 5.8051 - val_accuracy: 0.6283\n",
      "Epoch 37/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.0077 - accuracy: 0.62 - ETA: 0s - loss: 5.9164 - accuracy: 0.63 - ETA: 0s - loss: 6.5816 - accuracy: 0.58 - 0s 371us/step - loss: 6.3511 - accuracy: 0.6031 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 38/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 4.0039 - accuracy: 0.75 - ETA: 0s - loss: 6.2187 - accuracy: 0.61 - 0s 283us/step - loss: 6.4906 - accuracy: 0.5943 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 39/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.3435 - accuracy: 0.60 - ETA: 0s - loss: 6.4979 - accuracy: 0.59 - 0s 317us/step - loss: 6.3933 - accuracy: 0.5987 - val_loss: 5.9255 - val_accuracy: 0.6283\n",
      "Epoch 40/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.6610 - accuracy: 0.58 - ETA: 0s - loss: 6.0751 - accuracy: 0.61 - ETA: 0s - loss: 6.0078 - accuracy: 0.62 - 0s 339us/step - loss: 6.1830 - accuracy: 0.6118 - val_loss: 1.9396 - val_accuracy: 0.8761\n",
      "Epoch 41/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.6903 - accuracy: 0.52 - ETA: 0s - loss: 7.2888 - accuracy: 0.54 - 0s 302us/step - loss: 7.1422 - accuracy: 0.5548 - val_loss: 1.4233 - val_accuracy: 0.9115\n",
      "Epoch 42/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.3692 - accuracy: 0.47 - ETA: 0s - loss: 7.3588 - accuracy: 0.54 - 0s 264us/step - loss: 7.9595 - accuracy: 0.5044 - val_loss: 1.9954 - val_accuracy: 0.8761\n",
      "Epoch 43/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.7290 - accuracy: 0.56 - ETA: 0s - loss: 6.6420 - accuracy: 0.58 - 0s 259us/step - loss: 7.0123 - accuracy: 0.5614 - val_loss: 3.7086 - val_accuracy: 0.7699\n",
      "Epoch 44/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.7013 - accuracy: 0.52 - ETA: 0s - loss: 7.8962 - accuracy: 0.50 - ETA: 0s - loss: 8.0302 - accuracy: 0.50 - 0s 316us/step - loss: 8.1719 - accuracy: 0.4912 - val_loss: 5.2776 - val_accuracy: 0.6726\n",
      "Epoch 45/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.3692 - accuracy: 0.54 - ETA: 0s - loss: 7.5906 - accuracy: 0.52 - 0s 291us/step - loss: 8.2803 - accuracy: 0.4846 - val_loss: 5.8482 - val_accuracy: 0.6372\n",
      "Epoch 46/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.0334 - accuracy: 0.56 - ETA: 0s - loss: 7.8328 - accuracy: 0.51 - 0s 314us/step - loss: 8.3318 - accuracy: 0.4803 - val_loss: 9.9847 - val_accuracy: 0.3805\n",
      "Epoch 47/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.0333 - accuracy: 0.62 - ETA: 0s - loss: 7.9276 - accuracy: 0.50 - 0s 288us/step - loss: 7.6541 - accuracy: 0.5241 - val_loss: 10.1273 - val_accuracy: 0.3717\n",
      "Epoch 48/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.7013 - accuracy: 0.52 - ETA: 0s - loss: 8.2086 - accuracy: 0.48 - 0s 301us/step - loss: 8.0398 - accuracy: 0.5000 - val_loss: 10.1273 - val_accuracy: 0.3717\n",
      "Epoch 49/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.0554 - accuracy: 0.50 - ETA: 0s - loss: 8.3796 - accuracy: 0.47 - 0s 276us/step - loss: 8.0778 - accuracy: 0.4978 - val_loss: 10.1273 - val_accuracy: 0.3717\n",
      "Epoch 50/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 10.0592 - accuracy: 0.375 - ETA: 0s - loss: 8.3057 - accuracy: 0.483 - ETA: 0s - loss: 8.2999 - accuracy: 0.48 - 0s 338us/step - loss: 8.1796 - accuracy: 0.4912 - val_loss: 10.1273 - val_accuracy: 0.3717\n",
      "Epoch 51/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 10.3840 - accuracy: 0.354 - ETA: 0s - loss: 8.4587 - accuracy: 0.474 - ETA: 0s - loss: 7.9983 - accuracy: 0.50 - 0s 350us/step - loss: 7.8980 - accuracy: 0.5088 - val_loss: 9.9847 - val_accuracy: 0.3805\n",
      "Epoch 52/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.0370 - accuracy: 0.56 - ETA: 0s - loss: 7.5413 - accuracy: 0.53 - 0s 299us/step - loss: 7.7597 - accuracy: 0.5175 - val_loss: 9.9847 - val_accuracy: 0.3805\n",
      "Epoch 53/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.3802 - accuracy: 0.47 - ETA: 0s - loss: 8.7646 - accuracy: 0.45 - 0s 290us/step - loss: 8.5335 - accuracy: 0.4693 - val_loss: 9.9847 - val_accuracy: 0.3805\n",
      "Epoch 54/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.0371 - accuracy: 0.50 - ETA: 0s - loss: 7.7071 - accuracy: 0.51 - 0s 293us/step - loss: 7.9347 - accuracy: 0.5044 - val_loss: 7.5598 - val_accuracy: 0.5310\n",
      "Epoch 55/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.7014 - accuracy: 0.45 - ETA: 0s - loss: 7.8327 - accuracy: 0.51 - ETA: 0s - loss: 8.0707 - accuracy: 0.49 - 0s 313us/step - loss: 7.9979 - accuracy: 0.5022 - val_loss: 1.8527 - val_accuracy: 0.8850\n",
      "Epoch 56/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.6977 - accuracy: 0.45 - ETA: 0s - loss: 7.8582 - accuracy: 0.51 - 0s 296us/step - loss: 7.9065 - accuracy: 0.5066 - val_loss: 1.7085 - val_accuracy: 0.8938\n",
      "Epoch 57/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.0150 - accuracy: 0.62 - ETA: 0s - loss: 7.0267 - accuracy: 0.56 - 0s 296us/step - loss: 7.1519 - accuracy: 0.5548 - val_loss: 1.8527 - val_accuracy: 0.8850\n",
      "Epoch 58/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 6.7012 - accuracy: 0.58 - ETA: 0s - loss: 8.1435 - accuracy: 0.49 - 0s 274us/step - loss: 7.7889 - accuracy: 0.5154 - val_loss: 2.2807 - val_accuracy: 0.8584\n",
      "Epoch 59/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.3692 - accuracy: 0.47 - ETA: 0s - loss: 7.6909 - accuracy: 0.52 - 0s 264us/step - loss: 7.4277 - accuracy: 0.5373 - val_loss: 1.5659 - val_accuracy: 0.9027\n",
      "Epoch 60/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 9.6977 - accuracy: 0.39 - ETA: 0s - loss: 8.3047 - accuracy: 0.48 - 0s 259us/step - loss: 8.1688 - accuracy: 0.4912 - val_loss: 1.7039 - val_accuracy: 0.8938\n",
      "Epoch 61/10000\n",
      "456/456 [==============================] - ETA: 0s - loss: 8.0407 - accuracy: 0.50 - ETA: 0s - loss: 7.6380 - accuracy: 0.52 - 0s 273us/step - loss: 7.5322 - accuracy: 0.5307 - val_loss: 1.9860 - val_accuracy: 0.8761\n",
      "model type is NNClassifier\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-01 08:38:26,897] Finished trial#1 with value: 5.039400526441193 with parameters: {'input_dropout': 0.6458941130666561, 'hidden_layers': 1, 'hidden_units': 320.0, 'hidden_dropout': 0.05671297731744318, 'batch_norm': 'before_act', 'batch_size': 48.0}. Best is trial#1 with value: 5.039400526441193.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_dropout': 0.6458941130666561,\n",
       " 'hidden_layers': 1,\n",
       " 'hidden_units': 320.0,\n",
       " 'hidden_dropout': 0.05671297731744318,\n",
       " 'batch_norm': 'before_act',\n",
       " 'batch_size': 48.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials = 3\n",
    "n_jobs=-1\n",
    "random_state=0\n",
    "obj = Objective(NNClassifier(), X, y)\n",
    "optuna_search(obj, n_trials, n_jobs, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from utils import Paramset\n",
    "from neuralnetwork import NNClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "def obj(trial):\n",
    "    early_stopping_rounds = 10\n",
    "    n_splits = 3\n",
    "    random_state = 0\n",
    "    paramset = Paramset(NNClassifier())\n",
    "    paramset.swiching_lr('params_search')\n",
    "    PARAMS = paramset.generate_params()\n",
    "    \n",
    "    SPACE = {\n",
    "        \"input_dropout\": trial.suggest_uniform(\n",
    "            \"input_dropout\", 0.0, 1.0),\n",
    "        \"hidden_layers\": trial.suggest_int(\n",
    "            \"hidden_layers\", 1, 3),\n",
    "        'hidden_units': int(trial.suggest_discrete_uniform(\n",
    "            'hidden_units', 64, 1024, 64)),\n",
    "        'hidden_dropout': trial.suggest_uniform(\n",
    "            'hidden_dropout', 0.0, 1.0),\n",
    "        'batch_norm': trial.suggest_categorical(\n",
    "        'batch_norm', ['before_act', 'non']),\n",
    "        'batch_size': int(trial.suggest_discrete_uniform(\n",
    "            'batch_size', 16, 96, 16))\n",
    "    }\n",
    "    PARAMS.update(SPACE)\n",
    "    PARAMS['input_shape'] = x.shape[1]\n",
    "    print(PARAMS)\n",
    "    # cross validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits,\n",
    "    random_state=random_state, shuffle=True)\n",
    "    LOGLOSS = []\n",
    "    for tr_idx, va_idx in skf.split(x, y):\n",
    "        clf = Trainer(NNClassifier(**PARAMS))\n",
    "        clf.fit(\n",
    "            x[tr_idx],\n",
    "            y[tr_idx],\n",
    "            x[va_idx],\n",
    "            y[va_idx],\n",
    "            early_stopping_rounds\n",
    "        )\n",
    "        y_pred = clf.predict_proba(x[va_idx])\n",
    "        logloss = clf.get_model().history.history[\"val_loss\"][-(early_stopping_rounds+1)]\n",
    "        LOGLOSS.append(logloss)\n",
    "    return np.mean(LOGLOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.5488135039273248, 'hidden_layers': 2, 'hidden_units': 896, 'hidden_dropout': 0.8579456176227568, 'batch_norm': 'non', 'batch_size': 48, 'epochs': 10000}{'learning_rate': 0.05, 'input_shape': 30, 'input_dropout': 0.6458941130666561, 'hidden_layers': 1, 'hidden_units': 320, 'hidden_dropout': 0.05671297731744318, 'batch_norm': 'before_act', 'batch_size': 48, 'epochs': 10000}\n",
      "\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kurosaki/opt/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "379/379 [==============================] - ETA: 2s - loss: 1.2222 - accuracy: 0.39 - ETA: 0s - loss: 2.6618 - accuracy: 0.69 - 1s 1ms/step - loss: 2.7279 - accuracy: 0.7256 - val_loss: 0.6089 - val_accuracy: 0.9579\n",
      "Epoch 2/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.91 - ETA: 0s - loss: 2.0995 - accuracy: 0.86 - 0s 318us/step - loss: 2.0174 - accuracy: 0.8681 - val_loss: 0.7579 - val_accuracy: 0.9526\n",
      "Epoch 3/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.9965 - accuracy: 0.87 - ETA: 0s - loss: 1.7322 - accuracy: 0.8917 - ETA: 4s - loss: 0.6928 - accuracy: 0.60 - 0s 367us/step - loss: 1.5956 - accuracy: 0.8997 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 4/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.0037 - accuracy: 0.93 - ETA: 0s - loss: 1.6151 - accuracy: 0.89 - 0s 315us/step - loss: 1.5146 - accuracy: 0.9050 - val_loss: 1.0542 - val_accuracy: 0.9316\n",
      "Epoch 5/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.6716 - accuracy: 0.89 - ETA: 0s - loss: 1.8739 - accuracy: 0.88 - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8654 - val_loss: 0.2487 - val_accuracy: 0.9158\n",
      "379/379 [==============================] - 0s 371us/step - loss: 1.6535 - accuracy: 0.8971 - val_loss: 0.9774 - val_accuracy: 0.9368\n",
      "Epoch 6/10000\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.6680 - accuracy: 0.8958Epoch 2/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 2.0952 - accuracy: 0.86 - 0s 228us/step - loss: 0.2359 - accuracy: 0.9261 - val_loss: 0.2429 - val_accuracy: 0.9632\n",
      "Epoch 3/10000\n",
      " - 0s 448us/step - loss: 1.8765 - accuracy: 0.8813 - val_loss: 0.8455 - val_accuracy: 0.9474\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000Epoch 7/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.89 - ETA: 0s - loss: 0.1608 - accuracy: 0.95 - ETA: 0s - loss: 1.2596 - accuracy: 0. - 0s 331us/step - loss: 0.1557 - accuracy: 0.9525 - val_loss: 0.2195 - val_accuracy: 0.9579\n",
      "336/379 [=========================>....] - ETA: 0s - loss: 1.3887 - accuracy: 0.9107Epoch 4/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.95 - 0s 444us/step - loss: 1.4420 - accuracy: 0.9077 - val_loss: 0.8201 - val_accuracy: 0.9474\n",
      "Epoch 8/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 1.0001 - accuracy: 0.9375 - 0s 176us/step - loss: 0.2505 - accuracy: 0.9103 - val_loss: 0.1501 - val_accuracy: 0.9632\n",
      "Epoch 5/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.93 - ETA: 0s - loss: 1.3359 - accuracy: 0.91 - 0s 172us/step - loss: 0.1976 - accuracy: 0.9261 - val_loss: 0.1323 - val_accuracy: 0.9474\n",
      "Epoch 6/10000\n",
      "379/379 [==============================] - 0s 410us/step - loss: 1.4371 - accuracy: 0.9103 - val_loss: 0.8437 - val_accuracy: 0.9474\n",
      "Epoch 9/10000 48/379 [==>...........................]\n",
      "379/379 [==============================]9792 - ETA: 0s - loss: 1.0113 - accuracy: 0.93 - 0s 182us/step - loss: 0.1425 - accuracy: 0.9499 - val_loss: 0.1749 - val_accuracy: 0.9684\n",
      "240/379 [=================>............]\n",
      " 48/379 [==>...........................]9250 - ETA: 0s - loss: 0.1227 - accuracy: 0.379/379 [==============================] - 0s 413us/step - loss: 1.3888 - accuracy: 0.9129 - val_loss: 0.5892 - val_accuracy: 0.9632\n",
      "379/379 [==============================] - 0s 198us/step - loss: 0.1337 - accuracy: 0.9393 - val_loss: 0.1669 - val_accuracy: 0.9684\n",
      "Epoch 10/10000Epoch 8/10000\n",
      "\n",
      " - 0s 167us/step - loss: 0.1857 - accuracy: 0.9129 - val_loss: 0.1515 - val_accuracy: 0.95260s - loss: 1.0037 - accuracy: 0.\n",
      "192/379 [==============>...............] - ETA: 0s - loss: 1.5805 - accuracy: 0.9010Epoch 9/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.91 - ETA: 0s - loss: 1.4735 - accuracy: 0.90 - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - 0s 433us/step - loss: 1.3905 - accuracy: 0.9129 - val_loss: 0.5892 - val_accuracy: 0.9632\n",
      "Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.3249 - accuracy: 0.85 - 0s 311us/step - loss: 0.1767 - accuracy: 0.9261 - val_loss: 0.1340 - val_accuracy: 0.9632\n",
      "Epoch 10/10000\n",
      "379/379 [==============================]8917 48/379 [==>...........................] - ETA: 0s - loss: 0.0495 - accuracy: 1.00 - ETA: 0s - loss: 0.1466 - accuracy: 0.94 - 0s 356us/step - loss: 1.7307 - accuracy: 0.8918 - val_loss: 0.8409 - val_accuracy: 0.9474\n",
      "Epoch 12/10000\n",
      " - 0s 227us/step - loss: 0.1431 - accuracy: 0.9393 - val_loss: 0.1309 - val_accuracy: 0.9579\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 2.3323 - accuracy: 0.8542Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.95 - ETA: 0s - loss: 2.1662 - accuracy: 0.86 - 0s 227us/step - loss: 0.1505 - accuracy: 0.9393 - val_loss: 0.1292 - val_accuracy: 0.9579\n",
      "Epoch 12/10000336/379 [=========================>....]\n",
      "379/379 [==============================]8571 - ETA: 0s - loss: 0.0982 - accuracy: 0.95 - 0s 430us/step - loss: 2.2789 - accuracy: 0.8575 - val_loss: 0.8409 - val_accuracy: 0.9474\n",
      "Epoch 13/10000\n",
      " - 0s 167us/step - loss: 0.2032 - accuracy: 0.9340 - val_loss: 0.1359 - val_accuracy: 0.9632\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.9965 - accuracy: 0.8750Epoch 13/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 1.9315 - accuracy: 0.87 - 0s 187us/step - loss: 0.1511 - accuracy: 0.9420 - val_loss: 0.1398 - val_accuracy: 0.9579\n",
      "Epoch 14/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.91 - 0s 374us/step - loss: 1.9195 - accuracy: 0.8786 - val_loss: 0.8351 - val_accuracy: 0.9474\n",
      "Epoch 14/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 0.6679 - accuracy: 0.9583 - 0s 158us/step - loss: 0.1637 - accuracy: 0.9393 - val_loss: 0.1376 - val_accuracy: 0.9526\n",
      "Epoch 15/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.83 - ETA: 0s - loss: 1.9359 - accuracy: 0.87 - 0s 169us/step - loss: 0.1977 - accuracy: 0.9103 - val_loss: 0.1438 - val_accuracy: 0.9526\n",
      "Epoch 16/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.97 - 0s 416us/step - loss: 1.6475 - accuracy: 0.8971 - val_loss: 0.6750 - val_accuracy: 0.9579\n",
      "Epoch 15/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 1.3322 - accuracy: 0.9167 - 0s 170us/step - loss: 0.2316 - accuracy: 0.8945 - val_loss: 0.1413 - val_accuracy: 0.9579\n",
      "Epoch 17/10000\n",
      "192/379 [==============>...............] - ETA: 0s - loss: 0.2186 - accuracy: 0.89 - ETA: 0s - loss: 1.6707 - accuracy: 0.336/379 [=========================>....]379/379 [==============================] - ETA: 0s - loss: 1.4766 - accuracy: 0.9077 - 0s 214us/step - loss: 0.1812 - accuracy: 0.9050 - val_loss: 0.1385 - val_accuracy: 0.9474\n",
      "Epoch 18/10000\n",
      "379/379 [==============================] - 0s 449us/step - loss: 1.4358 - accuracy: 0.9103 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 16/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.0037 - accuracy: 0.93 - 0s 164us/step - loss: 0.1400 - accuracy: 0.9525 - val_loss: 0.1360 - val_accuracy: 0.9526\n",
      "192/379 [==============>...............]\n",
      "379/379 [==============================]8958 - ETA: 0s - loss: 0.1393 - accuracy: 0.95 - ETA: 0s - loss: 1.6221 - accuracy: 0.89 - ETA: 0s - loss: 0.2141 - accuracy: 0.91 - 0s 450us/step - loss: 1.6077 - accuracy: 0.8997 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 17/10000\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.0001 - accuracy: 0.9375379/379 [==============================] - 0s 335us/step - loss: 0.1856 - accuracy: 0.9288 - val_loss: 0.1436 - val_accuracy: 0.9526\n",
      "Epoch 20/10000\n",
      "240/379 [=================>............] - ETA: 0s - loss: 0.1511 - accuracy: 0.91 - ETA: 0s - loss: 1.8030 - accuracy: 0.88336/379 [=========================>....]379/379 [==============================] - ETA: 0s - loss: 1.6237 - accuracy: 0.8988 - 0s 207us/step - loss: 0.1578 - accuracy: 0.9314 - val_loss: 0.1528 - val_accuracy: 0.9579\n",
      "Epoch 21/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.93 - 0s 432us/step - loss: 1.6086 - accuracy: 0.8997 - val_loss: 0.8446 - val_accuracy: 0.9474\n",
      "Epoch 18/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.6790 - accuracy: 0.83 - 0s 157us/step - loss: 0.1759 - accuracy: 0.9208 - val_loss: 0.1529 - val_accuracy: 0.9474\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.4285 - accuracy: 0.90 - 0s 395us/step - loss: 1.6257 - accuracy: 0.8971 - val_loss: 0.7598 - val_accuracy: 0.9526\n",
      "Epoch 19/10000\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 2.3359 - accuracy: 0.8542model type is NNClassifier\n",
      "None\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.8023 - accuracy: 0.88 - 0s 353us/step - loss: 1.6493 - accuracy: 0.8971 - val_loss: 0.7589 - val_accuracy: 0.9526\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "Train on 379 samples, validate on 190 samples\n",
      "Epoch 1/10000\n",
      "379/379 [==============================] - ETA: 3s - loss: 0.7040 - accuracy: 0.66 - ETA: 0s - loss: 2.8724 - accuracy: 0.74 - 1s 2ms/step - loss: 2.8814 - accuracy: 0.7599 - val_loss: 0.9142 - val_accuracy: 0.9368\n",
      "Epoch 2/10000\n",
      "379/379 [==============================]9028TA: 0s - loss: 0.3358 - accuracy: 0.97 48/379 [==>...........................] - ETA: 4s - loss: 0.7246 - accuracy: 0.60 - 0s 318us/step - loss: 1.6461 - accuracy: 0.8971 - val_loss: 1.5113 - val_accuracy: 0.9053\n",
      "Epoch 3/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.91 - ETA: 0s - loss: 2.1276 - accuracy: 0.86 - 0s 329us/step - loss: 2.1641 - accuracy: 0.8628 - val_loss: 1.3434 - val_accuracy: 0.9158\n",
      "Epoch 4/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.6571 - accuracy: 0.83 - ETA: 0s - loss: 1.9087 - accuracy: 0.87 - 0s 346us/step - loss: 1.7261 - accuracy: 0.8892 - val_loss: 1.0945 - val_accuracy: 0.9316\n",
      "379/379 [==============================]\n",
      " - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8575 - val_loss: 0.2120 - val_accuracy: 0.9632\n",
      "240/379 [=================>............] - ETA: 0s - loss: 2.3359 - accuracy: 0.85 - ETA: 0s - loss: 1.8680 - accuracy: 0.8833Epoch 2/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.93 - 0s 360us/step - loss: 1.6900 - accuracy: 0.8945 - val_loss: 1.0945 - val_accuracy: 0.9316\n",
      "Epoch 6/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.8518 - accuracy: 0.87 - 0s 179us/step - loss: 0.3738 - accuracy: 0.9208 - val_loss: 0.3937 - val_accuracy: 0.9421\n",
      "Epoch 3/10000\n",
      "379/379 [==============================]9000 48/379 [==>...........................] - ETA: 0s - loss: 0.3481 - accuracy: 0.89 - ETA: 0s - loss: 0.2350 - accuracy: 0.93 - 0s 384us/step - loss: 1.9661 - accuracy: 0.8760 - val_loss: 1.0087 - val_accuracy: 0.9368\n",
      "Epoch 7/10000\n",
      "379/379 [==============================] - 0s 234us/step - loss: 0.2233 - accuracy: 0.9367 - val_loss: 0.0930 - val_accuracy: 0.9579\n",
      " 48/379 [==>...........................] - ETA: 0s - loss: 1.3537 - accuracy: 0.8958Epoch 4/10000\n",
      " - ETA: 0s - loss: 1.5725 - accuracy: 0.8988TA: 0s - loss: 0.1717 - accuracy: 0.91 - ETA: 0s - loss: 1.6697 - accuracy: 0.89 - ETA: 0s - loss: 0.4202 - accuracy: 0.8336/379 [=========================>....]379/379 [==============================] - 0s 277us/step - loss: 0.3954 - accuracy: 0.8707 - val_loss: 0.1959 - val_accuracy: 0.9474\n",
      "Epoch 5/10000\n",
      "379/379 [==============================] ETA: 0s - loss: 0.2152 - accuracy: 0.8958 - 0s 445us/step - loss: 1.7727 - accuracy: 0.8865 - val_loss: 1.9034 - val_accuracy: 0.8789\n",
      "Epoch 8/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 2.6571 - accuracy: 0.83 - 0s 202us/step - loss: 0.1988 - accuracy: 0.9340 - val_loss: 0.1111 - val_accuracy: 0.9474\n",
      "Epoch 6/10000192/379 [==============>...............] - ETA: 0s - loss: 2.2419 - accuracy: 0.8594\n",
      " - 0s 451us/step - loss: 2.3565 - accuracy: 0.8522 - val_loss: 2.0986 - val_accuracy: 0.8684 - loss: 2.4683 - accuracy: 0.84 - ETA: 0s - loss: 0.2106 - accuracy: 0.91\n",
      "379/379 [==============================] - 0s 278us/step - loss: 0.1895 - accuracy: 0.9261 - val_loss: 0.0853 - val_accuracy: 0.9684\n",
      "Epoch 9/10000\n",
      "Epoch 7/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.8958 - ETA: 0s - loss: 3.9856 - accuracy: 0. - ETA: 0s - loss: 3.1562 - accuracy: 0.8021 - 0s 178us/step - loss: 0.2034 - accuracy: 0.9103 - val_loss: 0.0659 - val_accuracy: 0.9842\n",
      "Epoch 8/10000\n",
      " - ETA: 0s - loss: 0.2812 - accuracy: 0.8958336/379 [=========================>....] - ETA: 0s - loss: 2.9897 - accuracy: 0.8288/379 [=====================>........]379/379 [==============================] - 0s 455us/step - loss: 2.9029 - accuracy: 0.8179 - val_loss: 2.2664 - val_accuracy: 0.8579\n",
      "Epoch 10/10000\n",
      "379/379 [==============================] - 0s 233us/step - loss: 0.2673 - accuracy: 0.9024 - val_loss: 0.0972 - val_accuracy: 0.9526\n",
      " 48/379 [==>...........................]\n",
      "379/379 [==============================]8125 - ETA: 0s - loss: 0.2852 - accuracy: 0.89192/379 [==============>...............]336/379 [=========================>....] - ETA: 0s - loss: 2.8240 - accuracy: 0.8229 - ETA: 0s - loss: 0.1802 - accuracy: 0.94 - 0s 275us/step - loss: 0.1860 - accuracy: 0.9393 - val_loss: 0.0692 - val_accuracy: 0.9789\n",
      "Epoch 10/100\n",
      "379/379 [==============================] - 0s 410us/step - loss: 2.5678 - accuracy: 0.8391 - val_loss: 2.0986 - val_accuracy: 0.8684\n",
      "Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9375 - ETA: 0s - loss: 1.3285 - accuracy: 0.91 - 0s 152us/step - loss: 0.1941 - accuracy: 0.9156 - val_loss: 0.0713 - val_accuracy: 0.9789\n",
      "Epoch 11/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 1.3304 - accuracy: 0.9167 - ETA: 0s - loss: 0.1482 - accuracy: 0.8336/379 [=========================>....] - ETA: 0s - loss: 1.9959 - accuracy: 0.8750 - 0s 161us/step - loss: 0.1759 - accuracy: 0.9288 - val_loss: 0.0775 - val_accuracy: 0.9737\n",
      "Epoch 12/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.89 - 0s 430us/step - loss: 2.0223 - accuracy: 0.8734 - val_loss: 1.8469 - val_accuracy: 0.8842\n",
      "379/379 [==============================] - 0s 171us/step - loss: 0.1784 - accuracy: 0.9235 - val_loss: 0.0741 - val_accuracy: 0.9737\n",
      "Epoch 13/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.93 - 0s 103us/step - loss: 0.1996 - accuracy: 0.9446 - val_loss: 0.0774 - val_accuracy: 0.9632\n",
      "Epoch 14/10000\n",
      "model type is NNClassifier.............] - ETA: 0s - loss: 0.2161 - accuracy: 0.93379/379 [==============================]\n",
      "None - 0s 110us/step - loss: 0.1368 - accuracy: 0.9551 - val_loss: 0.0813 - val_accuracy: 0.9632\n",
      "\n",
      "Epoch 15/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.97 - 0s 107us/step - loss: 0.2270 - accuracy: 0.9340 - val_loss: 0.0852 - val_accuracy: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.95 - 0s 96us/step - loss: 0.1475 - accuracy: 0.9446 - val_loss: 0.0877 - val_accuracy: 0.9526\n",
      "Epoch 17/10000\n",
      "379/379 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.93 - 0s 99us/step - loss: 0.1794 - accuracy: 0.9208 - val_loss: 0.0788 - val_accuracy: 0.9684\n",
      "model type is NNClassifier\n",
      "None\n",
      "Train on 380 samples, validate on 189 samples\n",
      "Epoch 1/10000\n",
      "Train on 380 samples, validate on 189 samples\n",
      "Epoch 1/10000..........................] - ETA: 2s - loss: 0.8423 - accuracy: 0.58288/380 [=====================>........]\n",
      "380/380 [==============================]69 - 1s 2ms/step - loss: 2.9047 - accuracy: 0.7342 - val_loss: 1.0175 - val_accuracy: 0.9312\n",
      "Epoch 2/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.3323 - accuracy: 0.85 - ETA: 0s - loss: 1.8304 - accuracy: 0.88 - 0s 309us/step - loss: 1.8916 - accuracy: 0.8816 - val_loss: 0.9540 - val_accuracy: 0.9365\n",
      "Epoch 3/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3325 - accuracy: 0.91 - ETA: 0s - loss: 2.0513 - accuracy: 0.87 - 0s 307us/step - loss: 2.0581 - accuracy: 0.8711 - val_loss: 0.9107 - val_accuracy: 0.9365\n",
      "Epoch 4/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.6644 - accuracy: 0.83 - ETA: 0s - loss: 2.7919 - accuracy: 0.82 - 0s 318us/step - loss: 2.5189 - accuracy: 0.8421 - val_loss: 1.0150 - val_accuracy: 0.9365\n",
      "Epoch 5/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.3286 - accuracy: 0.85 - ETA: 0s - loss: 2.1300 - accuracy: 0.86 - 0s 312us/step - loss: 1.9755 - accuracy: 0.8763 - val_loss: 1.0150 - val_accuracy: 0.9365\n",
      "Epoch 6/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.6686 - accuracy: 0.89 - ETA: 0s - loss: 2.0329 - accuracy: 0.87 - 0s 334us/step - loss: 2.2092 - accuracy: 0.8605 - val_loss: 1.1474 - val_accuracy: 0.9259\n",
      "Epoch 7/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.9865 - accuracy: 0.93 - ETA: 0s - loss: 1.7332 - accuracy: 0.8917 - ETA: 6s - loss: 0.6956 - accuracy: 0.66 - 0s 333us/step - loss: 1.7075 - accuracy: 0.8921 - val_loss: 1.1040 - val_accuracy: 0.9312\n",
      "Epoch 8/10000\n",
      "380/380 [==============================]9167336/380 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.87 - ETA: 0s - loss: 1.1680 - accuracy: 0.92 - 0s 356us/step - loss: 1.4524 - accuracy: 0.9079 - val_loss: 1.1040 - val_accuracy: 0.9312\n",
      "Epoch 9/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 2.0038 - accuracy: 0.87 - ETA: 0s - loss: 2.0709 - accuracy: 0.87 - 0s 337us/step - loss: 1.9829 - accuracy: 0.8763 - val_loss: 1.1031 - val_accuracy: 0.9312\n",
      "Epoch 10/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.95 - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8789 - val_loss: 0.1529 - val_accuracy: 0.9577\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.91 - 0s 349us/step - loss: 1.5163 - accuracy: 0.9053 - val_loss: 1.1031 - val_accuracy: 0.9312\n",
      "Epoch 11/10000\n",
      " 48/380 [==>...........................] - ETA: 0s - loss: 1.6643 - accuracy: 0.8958Epoch 2/10000\n",
      " - 0s 400us/step - loss: 1.5960 - accuracy: 0.9000 - val_loss: 1.1031 - val_accuracy: 0.9312 - loss: 1.5269 - accuracy: 0.90 - ETA: 0s - loss: 0.2673 - accuracy: 0.9380/380 [==============================]\n",
      "380/380 [==============================] - 0s 263us/step - loss: 0.3067 - accuracy: 0.9184 - val_loss: 0.1311 - val_accuracy: 0.9577\n",
      "Epoch 12/10000\n",
      "Epoch 3/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.9167 - ETA: 0s - loss: 0.2689 - accuracy: 0.91 - ETA: 0s - loss: 1.9180 - accuracy: 0.88 - ETA: 0s - loss: 0.3191 - accuracy: 0. - 0s 270us/step - loss: 0.3183 - accuracy: 0.9079 - val_loss: 0.0967 - val_accuracy: 0.9577\n",
      "336/380 [=========================>....] - ETA: 0s - loss: 1.8614 - accuracy: 0.8839Epoch 4/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.81 - 0s 449us/step - loss: 1.9045 - accuracy: 0.8789 - val_loss: 1.1031 - val_accuracy: 0.9312\n",
      "Epoch 13/10000\n",
      "336/380 [=========================>....] - ETA: 0s - loss: 2.3359 - accuracy: 0.85 - ETA: 0s - loss: 0.1759 - accuracy: 0.92240/380 [=================>............]380/380 [==============================] - ETA: 0s - loss: 1.7381 - accuracy: 0.8917 - 0s 329us/step - loss: 0.1748 - accuracy: 0.9289 - val_loss: 0.1017 - val_accuracy: 0.9683\n",
      "Epoch 5/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.89 - 0s 378us/step - loss: 1.7704 - accuracy: 0.8895 - val_loss: 1.1874 - val_accuracy: 0.9259\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.94 - 0s 238us/step - loss: 0.1374 - accuracy: 0.9447 - val_loss: 0.0894 - val_accuracy: 0.9630\n",
      "Epoch 6/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.89 - 0s 84us/step - loss: 0.1468 - accuracy: 0.9526 - val_loss: 0.0769 - val_accuracy: 0.9788\n",
      "Epoch 7/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.91 - 0s 102us/step - loss: 0.1960 - accuracy: 0.9342 - val_loss: 0.0735 - val_accuracy: 0.9735\n",
      "Epoch 8/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.93 - 0s 98us/step - loss: 0.1951 - accuracy: 0.9211 - val_loss: 0.0828 - val_accuracy: 0.9630\n",
      "Epoch 9/10000\n",
      " 48/380 [==>...........................]\n",
      "None - ETA: 0s - loss: 0.1798 - accuracy: 0.8958\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1796 - accuracy: 0.9263 - val_loss: 0.0823 - val_accuracy: 0.9630\n",
      "Epoch 10/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.93 - 0s 104us/step - loss: 0.1277 - accuracy: 0.9632 - val_loss: 0.0771 - val_accuracy: 0.9683\n",
      "Epoch 11/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.91 - 0s 101us/step - loss: 0.2122 - accuracy: 0.9105 - val_loss: 0.0868 - val_accuracy: 0.9735\n",
      "Epoch 12/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 1.00 - 0s 111us/step - loss: 0.1840 - accuracy: 0.9211 - val_loss: 0.0841 - val_accuracy: 0.9683\n",
      "Epoch 13/10000\n",
      "144/380 [==========>...................] - ETA: 0s - loss: 0.1392 - accuracy: 0.91 - ETA: 0s - loss: 0.1014 - accuracy: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-30 16:04:46,752] Finished trial#0 with value: 0.8047021689104478 with parameters: {'input_dropout': 0.5488135039273248, 'hidden_layers': 2, 'hidden_units': 896.0, 'hidden_dropout': 0.8579456176227568, 'batch_norm': 'non', 'batch_size': 48.0}. Best is trial#0 with value: 0.8047021689104478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 400us/step - loss: 0.1599 - accuracy: 0.9474 - val_loss: 0.0844 - val_accuracy: 0.9630\n",
      "Epoch 14/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.91 - 0s 66us/step - loss: 0.1946 - accuracy: 0.9237 - val_loss: 0.0781 - val_accuracy: 0.9683\n",
      "Epoch 15/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.89 - 0s 89us/step - loss: 0.1685 - accuracy: 0.9263 - val_loss: 0.0841 - val_accuracy: 0.9630\n",
      "Epoch 16/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.91 - 0s 98us/step - loss: 0.1839 - accuracy: 0.9237 - val_loss: 0.0849 - val_accuracy: 0.9735\n",
      "Epoch 17/10000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.97 - 0s 90us/step - loss: 0.1828 - accuracy: 0.9289 - val_loss: 0.0878 - val_accuracy: 0.9683\n",
      "model type is NNClassifier\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-30 16:04:47,267] Finished trial#1 with value: 0.08951741930276812 with parameters: {'input_dropout': 0.6458941130666561, 'hidden_layers': 1, 'hidden_units': 320.0, 'hidden_dropout': 0.05671297731744318, 'batch_norm': 'before_act', 'batch_size': 48.0}. Best is trial#1 with value: 0.08951741930276812.\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from utils import Paramset\n",
    "from neuralnetwork import NNClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "brest_c = load_breast_cancer()\n",
    "x = brest_c['data']\n",
    "y = brest_c['target']\n",
    "\n",
    "\n",
    "n_trials = 2\n",
    "n_jobs=-1\n",
    "random_state=0\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=random_state))\n",
    "study.optimize(obj, n_trials=n_trials, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
