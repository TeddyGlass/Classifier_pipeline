{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サンプルデータの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "brest_c = load_breast_cancer()\n",
    "X = brest_c['data']\n",
    "y = brest_c['target']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "NAMES = ['X', 'X_test', 'y', 'y_test']\n",
    "for name, data in zip(NAMES, [X_train, X_valid, y_train, y_valid]):\n",
    "    pd.DataFrame(data).to_csv(f'../data/{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/kurosaki/opt/miniconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/kurosaki/opt/miniconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d97f9bea7130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munder_sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_and_emsemble_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptuna_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParamset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNNClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/Classifier_pipeline/src/optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNNClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/kurosaki/opt/miniconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/kurosaki/opt/miniconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "from processing import under_sampling\n",
    "from trainer import Trainer, cv_and_emsemble_predict\n",
    "from optimizer import Objective, optuna_search\n",
    "from utils import Paramset, load, save\n",
    "from neuralnetwork import NNClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# とりあえずOptimizeのパイプライン\n",
    "NNのベイズ最適化をjupyter上で行うとIOStream.flush timed outが出るけど、zshで直接行えば問題なし。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimizer(n_trials, n_jobs, random_state):\n",
    "    LGB_PARAMS = []\n",
    "    XGB_PARAMS = []\n",
    "    NN_PARAMS = []\n",
    "    if PIPELINE_PARAMS['optimize']==True:\n",
    "        print('Run Optimizer.')\n",
    "        flag_inputtype = type(X).__name__\n",
    "        if flag_inputtype == 'list':\n",
    "            print(f' Data type of X is list type.')\n",
    "            print(f' Running optimization for all data sets. Please waite....')\n",
    "            for x, y in tqdm(zip(X, Y)):\n",
    "                obj_lgb = Objective(LGBMClassifier(), x, y)\n",
    "                obj_xgb = Objective(XGBClassifier(), x, y)\n",
    "                obj_nn = Objective(NNClassifier(), x, y)\n",
    "                if PIPELINE_PARAMS['LGB']==True:\n",
    "                    lgb_params = optuna_search(obj_lgb, n_trials, n_jobs, random_state)\n",
    "                    LGB_PARAMS.append(lgb_params)\n",
    "                if PIPELINE_PARAMS['XGB']==True:\n",
    "                    xgb_params = optuna_search(obj_xgb, n_trials, n_jobs, random_state)\n",
    "                    XGB_PARAMS.append(xgb_params)\n",
    "                if PIPELINE_PARAMS['NN']==True:\n",
    "                    nn_params = optuna_search(obj_nn, n_trials, n_jobs, random_state)\n",
    "                    NN_PARAMS.append(nn_params)  \n",
    "        elif flag_inputtype == 'ndarray':\n",
    "            print(f' Data type of X is ndarray.')\n",
    "            print(f' Running optimization for a data sets.')\n",
    "            obj_lgb = Objective(LGBMClassifier(), X, Y)\n",
    "            obj_xgb = Objective(XGBClassifier(), X, Y)\n",
    "            obj_nn = Objective(NNClassifier(), X, Y)\n",
    "            if PIPELINE_PARAMS['LGB']==True:\n",
    "                lgb_params = optuna_search(obj_lgb, n_trials, n_jobs, random_state)\n",
    "                LGB_PARAMS.append(lgb_params)\n",
    "            if PIPELINE_PARAMS['XGB']==True:\n",
    "                xgb_params = optuna_search(obj_xgb, n_trials, n_jobs, random_state)\n",
    "                XGB_PARAMS.append(xgb_params)\n",
    "            if PIPELINE_PARAMS['NN']==True:\n",
    "                nn_params = optuna_search(obj_nn, n_trials, n_jobs, random_state)\n",
    "                NN_PARAMS.append(nn_params)\n",
    "    return LGB_PARAMS, XGB_PARAMS, NN_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "This dataset is balanced data.\n",
      "Run Optimizer.\n",
      " Data type of X is ndarray.\n",
      " Running optimization for a data sets.\n",
      "Train on 303 samples, validate on 152 samples\n",
      "Train on 303 samples, validate on 152 samples\n",
      "Epoch 1/10000\n",
      "Train on 303 samples, validate on 152 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "303/303 [==============================] - ETA: 5s - loss: 0.7015 - accuracy: 0.5625 - ETA: 5s - loss: 1.3766 - accuracy: 0.3750 - ETA: 6s - loss: 1.4774 - accuracy: 0.43 - 0s 1ms/step - loss: 0.7826 - accuracy: 0.7261 - val_loss: 0.2175 - val_accuracy: 0.9145\n",
      "Epoch 2/100\n",
      " - 0s 1ms/step - loss: 1.0359 - accuracy: 0.6271 - val_loss: 0.2198 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.1229 - accuracy: 1.0000Epoch 2/100\n",
      "303/303 [==============================] 16/303 [>.............................] - 0s 1ms/step - loss: 1.0161 - accuracy: 0.6766 - val_loss: 0.2462 - val_accuracy: 0.9342\n",
      " - ETA: 0s - loss: 1.1062 - accuracy: 0.68Epoch 2/10000\n",
      "303/303 [==============================] - 0s 181us/step - loss: 0.4981 - accuracy: 0.8284 - val_loss: 0.1675 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 1.2675 - accuracy: 0.7500Epoch 3/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.81 - 0s 215us/step - loss: 0.6212 - accuracy: 0.7558 - val_loss: 0.1785 - val_accuracy: 0.9408\n",
      "Epoch 3/10000\n",
      " - 0s 223us/step - loss: 0.5052 - accuracy: 0.8218 - val_loss: 0.1543 - val_accuracy: 0.9474 loss: 1.0548 - accuracy: 0.6875 - ETA: 0s - loss: 0.5872 - accuracy: 0.8303/303 [==============================]\n",
      "303/303 [==============================] - 0s 266us/step - loss: 0.5964 - accuracy: 0.7987 - val_loss: 0.3060 - val_accuracy: 0.8750\n",
      "Epoch 4/10000\n",
      "Epoch 3/10000\n",
      "303/303 [==============================]8750 16/303 [>.............................] - ETA: 0s - loss: 0.5627 - accuracy: 0.75 - 0s 225us/step - loss: 0.5469 - accuracy: 0.7888 - val_loss: 0.1840 - val_accuracy: 0.9342\n",
      "Epoch 4/10000\n",
      "303/303 [==============================]6875288/303 [===========================>..] - ETA: 0s - loss: 0.4483 - accuracy: 0.81 - 0s 217us/step - loss: 0.6818 - accuracy: 0.7624 - val_loss: 0.1905 - val_accuracy: 0.9211\n",
      "Epoch 5/10000\n",
      " - 0s 255us/step - loss: 0.4369 - accuracy: 0.8152 - val_loss: 0.2077 - val_accuracy: 0.9145\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.2548 - accuracy: 0.9375Epoch 4/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.87 - 0s 231us/step - loss: 0.4368 - accuracy: 0.8317 - val_loss: 0.1763 - val_accuracy: 0.9211\n",
      "Epoch 5/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.81 - 0s 214us/step - loss: 0.4748 - accuracy: 0.8152 - val_loss: 0.1251 - val_accuracy: 0.9539\n",
      "Epoch 6/10000303/303 [==============================] - 0s 208us/step - loss: 0.3747 - accuracy: 0.8713 - val_loss: 0.1575 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 5/10000 16/303 [>.............................]\n",
      "303/303 [==============================]7500 - ETA: 0s - loss: 0.1598 - accuracy: 0.93 - 0s 225us/step - loss: 0.5563 - accuracy: 0.8020 - val_loss: 0.1798 - val_accuracy: 0.9079\n",
      "Epoch 6/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.93 - 0s 215us/step - loss: 0.7015 - accuracy: 0.8185 - val_loss: 0.1778 - val_accuracy: 0.9408\n",
      "303/303 [==============================]\n",
      " - 0s 224us/step - loss: 0.5442 - accuracy: 0.8416 - val_loss: 0.1874 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................]Epoch 6/10000 - ETA: 0s - loss: 0.4728 - accuracy: 0.8125\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.75 - 0s 203us/step - loss: 0.4998 - accuracy: 0.8251 - val_loss: 0.1550 - val_accuracy: 0.9342\n",
      "Epoch 7/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.68 - 0s 210us/step - loss: 0.5507 - accuracy: 0.8086 - val_loss: 0.2415 - val_accuracy: 0.9211\n",
      "Epoch 8/10000\n",
      "303/303 [==============================] - 0s 219us/step - loss: 0.5564 - accuracy: 0.8086 - val_loss: 0.1340 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.4277 - accuracy: 0.8750Epoch 7/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.75 - 0s 242us/step - loss: 0.4821 - accuracy: 0.8284 - val_loss: 0.1697 - val_accuracy: 0.9276\n",
      "Epoch 8/10000\n",
      "303/303 [==============================]] - ETA: 0s - loss: 0.4488 - accuracy: 0.9375 - 0s 208us/step - loss: 0.6074 - accuracy: 0.8020 - val_loss: 0.1900 - val_accuracy: 0.9211\n",
      "Epoch 9/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - ETA: 0s - loss: 0.3140 - accuracy: 0.8125 - 0s 212us/step - loss: 0.5233 - accuracy: 0.8581 - val_loss: 0.1897 - val_accuracy: 0.9211\n",
      "Epoch 8/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.68 - 0s 213us/step - loss: 0.4332 - accuracy: 0.8449 - val_loss: 0.1801 - val_accuracy: 0.9276\n",
      "Epoch 9/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.81 - 0s 225us/step - loss: 0.7027 - accuracy: 0.7789 - val_loss: 0.2260 - val_accuracy: 0.9211\n",
      "Epoch 10/10000303/303 [==============================]\n",
      " - 0s 204us/step - loss: 0.4623 - accuracy: 0.8185 - val_loss: 0.1622 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.4412 - accuracy: 0.7500Epoch 9/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.87 - 0s 217us/step - loss: 0.3889 - accuracy: 0.8779 - val_loss: 0.1647 - val_accuracy: 0.9342\n",
      "Epoch 10/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - 0s 198us/step - loss: 0.5369 - accuracy: 0.7624 - val_loss: 0.1851 - val_accuracy: 0.9211\n",
      " - ETA: 0s - loss: 0.1370 - accuracy: 1.0000Epoch 11/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.3330 - accuracy: 0.8750303/303 [==============================] - 0s 224us/step - loss: 0.4000 - accuracy: 0.8383 - val_loss: 0.2354 - val_accuracy: 0.9211\n",
      "Epoch 10/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.81 - 0s 210us/step - loss: 0.4931 - accuracy: 0.8515 - val_loss: 0.1608 - val_accuracy: 0.9342\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 213us/step - loss: 0.4188 - accuracy: 0.8251 - val_loss: 0.1394 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.5254 - accuracy: 0.7500Epoch 12/10000\n",
      "303/303 [==============================]] - ETA: 0s - loss: 1.1539 - accuracy: 0.6250 - 0s 219us/step - loss: 0.5133 - accuracy: 0.8449 - val_loss: 0.2327 - val_accuracy: 0.9276\n",
      "Epoch 11/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.68 - 0s 209us/step - loss: 0.5798 - accuracy: 0.7756 - val_loss: 0.1559 - val_accuracy: 0.9276\n",
      "Epoch 12/10000\n",
      "303/303 [==============================] - 0s 214us/step - loss: 0.6718 - accuracy: 0.8251 - val_loss: 0.1726 - val_accuracy: 0.9342\n",
      " 16/303 [>............................ - ETA: 0s - loss: 0.3455 - accuracy: 0.8750Epoch 13/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.8334 - accuracy: 0.7847 - ETA: 0s - loss: 0.5270 - accuracy: 0.81 - 0s 269us/step - loss: 0.8072 - accuracy: 0.7855 - val_loss: 0.2261 - val_accuracy: 0.9276\n",
      "Epoch 12/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.93 - 0s 208us/step - loss: 0.5195 - accuracy: 0.8251 - val_loss: 0.1877 - val_accuracy: 0.9211\n",
      "Epoch 13/10000\n",
      "303/303 [==============================] - 0s 208us/step - loss: 0.7386 - accuracy: 0.8185 - val_loss: 0.1700 - val_accuracy: 0.9211\n",
      " 16/303 [>.............................]Epoch 14/10000 - ETA: 0s - loss: 0.5543 - accuracy: 0.8750\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.6891 - accuracy: 0.81303/303 [==============================]272/303 [=========================>....] - 0s 236us/step - loss: 0.7166 - accuracy: 0.8482 - val_loss: 0.1620 - val_accuracy: 0.9276\n",
      " - ETA: 0s - loss: 0.4448 - accuracy: 0.8125Epoch 13/100\n",
      "303/303 [==============================]8051 16/303 [>.............................] - ETA: 0s - loss: 0.1573 - accuracy: 1.00 - 0s 266us/step - loss: 0.4465 - accuracy: 0.8218 - val_loss: 0.2157 - val_accuracy: 0.8882\n",
      "Epoch 14/10000303/303 [==============================] - 0s 270us/step - loss: 0.8922 - accuracy: 0.8020 - val_loss: 0.1575 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 15/10000 16/303 [>.............................]\n",
      "303/303 [==============================]7500 - ETA: 0s - loss: 1.6035 - accuracy: 0.75 - 0s 203us/step - loss: 0.7362 - accuracy: 0.8284 - val_loss: 0.1677 - val_accuracy: 0.9211\n",
      "Epoch 14/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.303/303 [==============================]272/303 [=========================>....] - 0s 215us/step - loss: 0.3932 - accuracy: 0.8152 - val_loss: 0.2079 - val_accuracy: 0.8947\n",
      " - ETA: 0s - loss: 0.6038 - accuracy: 0.8456Epoch 15/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.62 - 0s 262us/step - loss: 0.6971 - accuracy: 0.8449 - val_loss: 0.1574 - val_accuracy: 0.9276\n",
      "Epoch 16/10000\n",
      " - ETA: 0s - loss: 0.7131 - accuracy: 0.6875303/303 [==============================] - 0s 215us/step - loss: 0.5646 - accuracy: 0.8284 - val_loss: 0.1814 - val_accuracy: 0.9276\n",
      "Epoch 15/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.87 - 0s 200us/step - loss: 0.7262 - accuracy: 0.7954 - val_loss: 0.2158 - val_accuracy: 0.8882\n",
      "Epoch 16/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.7586 - accuracy: 0.7500 - 0s 184us/step - loss: 0.4632 - accuracy: 0.8020 - val_loss: 0.1675 - val_accuracy: 0.9276\n",
      "Epoch 17/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 1.00 - 0s 225us/step - loss: 0.4930 - accuracy: 0.8218 - val_loss: 0.2001 - val_accuracy: 0.9145\n",
      "Epoch 16/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.87 - 0s 210us/step - loss: 0.5707 - accuracy: 0.8284 - val_loss: 0.2807 - val_accuracy: 0.9079\n",
      "Epoch 17/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.75 - 0s 207us/step - loss: 0.6617 - accuracy: 0.8515 - val_loss: 0.1512 - val_accuracy: 0.9276\n",
      "Epoch 18/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.0596 - accuracy: 0.93 - 0s 201us/step - loss: 0.4665 - accuracy: 0.8086 - val_loss: 0.1831 - val_accuracy: 0.9145\n",
      "Epoch 17/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.81 - 0s 205us/step - loss: 0.4962 - accuracy: 0.8053 - val_loss: 0.2860 - val_accuracy: 0.8684\n",
      "Epoch 18/10000303/303 [==============================]\n",
      " - 0s 183us/step - loss: 0.6212 - accuracy: 0.8317 - val_loss: 0.1405 - val_accuracy: 0.9342\n",
      " 16/303 [>.............................]Epoch 19/10000 - ETA: 0s - loss: 0.2573 - accuracy: 0.9375\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.3802 - accuracy: 0.75 - 0s 213us/step - loss: 0.6148 - accuracy: 0.8020 - val_loss: 0.2148 - val_accuracy: 0.9145\n",
      "Epoch 18/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.4094 - accuracy: 0.62 - 0s 191us/step - loss: 0.5054 - accuracy: 0.7888 - val_loss: 0.2502 - val_accuracy: 0.8684\n",
      "Epoch 19/10000303/303 [==============================]\n",
      " - 0s 211us/step - loss: 0.6092 - accuracy: 0.8383 - val_loss: 0.1440 - val_accuracy: 0.9211\n",
      " 16/303 [>.............................]Epoch 20/10000 - ETA: 0s - loss: 1.3412 - accuracy: 0.8125\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.1885 - accuracy: 0.75 - 0s 219us/step - loss: 0.5653 - accuracy: 0.7822 - val_loss: 0.1979 - val_accuracy: 0.9079\n",
      "Epoch 19/10000\n",
      " - 0s 214us/step - loss: 0.6529 - accuracy: 0.8185 - val_loss: 0.2794 - val_accuracy: 0.9013\n",
      "303/303 [==============================] - 0s 195us/step - loss: 0.8289 - accuracy: 0.7888 - val_loss: 0.1745 - val_accuracy: 0.9013\n",
      "Epoch 20/10000\n",
      "Epoch 21/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.7500 - ETA: 0s - loss: 0.2274 - accuracy: 0.93 - 0s 214us/step - loss: 0.5142 - accuracy: 0.8449 - val_loss: 0.1529 - val_accuracy: 0.9276\n",
      "Epoch 20/10000\n",
      " - 0s 207us/step - loss: 0.8138 - accuracy: 0.7921 - val_loss: 0.2029 - val_accuracy: 0.8882============================]\n",
      "303/303 [==============================] - 0s 202us/step - loss: 0.5661 - accuracy: 0.7954 - val_loss: 0.1682 - val_accuracy: 0.9211\n",
      "Epoch 21/10000\n",
      "Epoch 22/10000\n",
      "303/303 [==============================]7500 16/303 [>.............................] - ETA: 0s - loss: 0.1475 - accuracy: 1.00 - 0s 206us/step - loss: 0.6723 - accuracy: 0.8449 - val_loss: 0.1904 - val_accuracy: 0.9276\n",
      "Epoch 21/10000\n",
      " - 0s 214us/step - loss: 0.6115 - accuracy: 0.7987 - val_loss: 0.2653 - val_accuracy: 0.8618============================]\n",
      "303/303 [==============================] - 0s 216us/step - loss: 0.8099 - accuracy: 0.8449 - val_loss: 0.1442 - val_accuracy: 0.9342\n",
      "Epoch 22/10000\n",
      "Epoch 23/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - ETA: 0s - loss: 0.4764 - accuracy: 0.7500 - ETA: 0s - loss: 0.3543 - accuracy: 0.81 - 0s 223us/step - loss: 0.5367 - accuracy: 0.8185 - val_loss: 0.2387 - val_accuracy: 0.9342\n",
      " - 0s 194us/step - loss: 0.7780 - accuracy: 0.8218 - val_loss: 0.2312 - val_accuracy: 0.9276\n",
      "\n",
      "303/303 [==============================] - 0s 204us/step - loss: 0.6007 - accuracy: 0.7723 - val_loss: 0.2218 - val_accuracy: 0.8882\n",
      "Epoch 24/10000 16/303 [>.............................]\n",
      "Epoch 23/10000 - ETA: 0s - loss: 1.7002 - accuracy: 0.6875\n",
      " - 0s 219us/step - loss: 0.6626 - accuracy: 0.7987 - val_loss: 0.1748 - val_accuracy: 0.9276 loss: 0.2980 - accuracy: 0.8750 - ETA: 0s - loss: 0.3980 - accuracy: 0.6303/303 [==============================]\n",
      "303/303 [============================= - 0s 211us/step - loss: 0.5396 - accuracy: 0.8185 - val_loss: 0.1812 - val_accuracy: 0.9342\n",
      "Epoch 23/10000303/303 [==============================]\n",
      "Epoch 25/10000 - 0s 218us/step - loss: 0.7258 - accuracy: 0.7822 - val_loss: 0.5618 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 24/10000 16/303 [>.............................] 16/303 [>.............................]\n",
      "303/303 [==============================]9375 - ETA: 0s - loss: 0.5259 - accuracy: 0.7500 - ETA: 0s - loss: 1.0486 - accuracy: 0. - 0s 198us/step - loss: 0.3656 - accuracy: 0.8680 - val_loss: 0.1777 - val_accuracy: 0.9211\n",
      " - 0s 198us/step - loss: 0.7647 - accuracy: 0.7888 - val_loss: 0.1947 - val_accuracy: 0.9276\n",
      "Epoch 24/100\n",
      " - 0s 212us/step - loss: 0.8748 - accuracy: 0.7558 - val_loss: 0.2352 - val_accuracy: 0.8553\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.4901 - accuracy: 0.8750Epoch 25/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.1159 - accuracy: 0.87 - 0s 179us/step - loss: 0.4800 - accuracy: 0.8416 - val_loss: 0.1709 - val_accuracy: 0.9145\n",
      "Epoch 25/10000\n",
      " - 0s 176us/step - loss: 0.6681 - accuracy: 0.7987 - val_loss: 0.3376 - val_accuracy: 0.8684\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.2548 - accuracy: 0.8750Epoch 26/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.87 - 0s 172us/step - loss: 0.5483 - accuracy: 0.8317 - val_loss: 0.1620 - val_accuracy: 0.9211\n",
      "Epoch 26/10000303/303 [==============================]\n",
      " - 0s 165us/step - loss: 0.5608 - accuracy: 0.7855 - val_loss: 0.3534 - val_accuracy: 0.8750\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.0894 - accuracy: 0.93 - 0s 177us/step - loss: 0.5097 - accuracy: 0.8152 - val_loss: 0.1849 - val_accuracy: 0.9013\n",
      "Train on 303 samples, validate on 152 samples\n",
      "Epoch 1/10000\n",
      "Train on 303 samples, validate on 152 samples\n",
      "Train on 303 samples, validate on 152 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      "303/303 [==============================] - ETA: 6s - loss: 2.1071 - accuracy: 0.4375 - ETA: 6s - loss: 0.6250 - accuracy: 0.75 - 0s 2ms/step - loss: 1.0063 - accuracy: 0.7294 - val_loss: 0.1639 - val_accuracy: 0.9474\n",
      " 16/303 [>.............................] - ETA: 6s - loss: 1.7099 - accuracy: 0.2500Epoch 2/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.3223 - accuracy: 0.81 - 0s 158us/step - loss: 1.1884 - accuracy: 0.7558 - val_loss: 0.1510 - val_accuracy: 0.9671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.62 - 1s 2ms/step - loss: 0.9162 - accuracy: 0.7426 - val_loss: 0.3820 - val_accuracy: 0.9013\n",
      "303/303 [==============================] - 0s 157us/step - loss: 0.7458 - accuracy: 0.7426 - val_loss: 0.1521 - val_accuracy: 0.9605\n",
      "Epoch 4/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.8328 - accuracy: 0.7500Epoch 2/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.8332 - accuracy: 0.75 - 0s 163us/step - loss: 0.6894 - accuracy: 0.7657 - val_loss: 0.2511 - val_accuracy: 0.9539\n",
      "Epoch 5/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.4939 - accuracy: 0.7500 - 1s 2ms/step - loss: 0.9748 - accuracy: 0.6106 - val_loss: 0.1846 - val_accuracy: 0.9408\n",
      "303/303 [==============================] - 0s 210us/step - loss: 0.8976 - accuracy: 0.7789 - val_loss: 0.1808 - val_accuracy: 0.9408\n",
      "Epoch 3/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.5673 - accuracy: 0.9375Epoch 2/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.68 - 0s 254us/step - loss: 0.6454 - accuracy: 0.7525 - val_loss: 0.2500 - val_accuracy: 0.9408\n",
      "Epoch 6/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.3344 - accuracy: 0.75303/303 [==============================]256/303 [========================>.....] - 0s 242us/step - loss: 0.6425 - accuracy: 0.8284 - val_loss: 0.1567 - val_accuracy: 0.9276\n",
      " - ETA: 0s - loss: 0.5385 - accuracy: 0.7891Epoch 4/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.75 - ETA: 0s - loss: 0.4367 - accuracy: 0.81 - 0s 305us/step - loss: 0.5376 - accuracy: 0.7822 - val_loss: 0.1276 - val_accuracy: 0.9539\n",
      "Epoch 3/10000\n",
      " - ETA: 0s - loss: 0.3478 - accuracy: 0.7500303/303 [==============================] - 0s 327us/step - loss: 0.4558 - accuracy: 0.7987 - val_loss: 0.1289 - val_accuracy: 0.9474\n",
      "Epoch 7/10000\n",
      " 16/303 [>.............................] - 0s 248us/step - loss: 0.6848 - accuracy: 0.7822 - val_loss: 0.2315 - val_accuracy: 0.8882\n",
      " - ETA: 0s - loss: 0.2936 - accuracy: 0.7500Epoch 5/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.87 - ETA: 0s - loss: 0.5412 - accuracy: 0.76 - ETA: 0s - loss: 0.3889 - accuracy: 0.8 - 0s 307us/step - loss: 0.5322 - accuracy: 0.7624 - val_loss: 0.1251 - val_accuracy: 0.9539\n",
      "272/303 [=========================>....] - ETA: 0s - loss: 0.7663 - accuracy: 0.7684Epoch 4/10000\n",
      " - 0s 293us/step - loss: 0.7585 - accuracy: 0.7756 - val_loss: 0.1557 - val_accuracy: 0.9408============================]\n",
      "303/303 [==============================] - 0s 337us/step - loss: 0.3982 - accuracy: 0.8317 - val_loss: 0.1571 - val_accuracy: 0.9671\n",
      "Epoch 6/10000Epoch 8/10000\n",
      "\n",
      " - 0s 297us/step - loss: 0.7475 - accuracy: 0.7921 - val_loss: 0.2134 - val_accuracy: 0.9276[>.............................] - ETA: 0s - loss: 0.6105 - accuracy: 0.87 - ETA: 0s - loss: 0.7302 - accuracy: 0.303/303 [==============================]208/303 [===================>..........]\n",
      "272/303 [=========================>....] - ETA: 0s - loss: 0.4940 - accuracy: 0.8365 - ETA: 0s - loss: 0.5242 - accuracy: 0.8162Epoch 5/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0. - 0s 314us/step - loss: 0.5262 - accuracy: 0.8152 - val_loss: 0.2138 - val_accuracy: 0.9276\n",
      "303/303 [==============================]Epoch 7/10000 - 0s 329us/step - loss: 0.4687 - accuracy: 0.8284 - val_loss: 0.1553 - val_accuracy: 0.9408\n",
      "\n",
      " 16/303 [>.............................]Epoch 9/10000 - ETA: 0s - loss: 0.2000 - accuracy: 0.9375\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.81 - 0s 231us/step - loss: 0.5223 - accuracy: 0.7855 - val_loss: 0.1256 - val_accuracy: 0.9474\n",
      "Epoch 6/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.6026 - accuracy: 0.75 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - 0s 233us/step - loss: 0.5902 - accuracy: 0.8020 - val_loss: 0.2041 - val_accuracy: 0.9408\n",
      "Epoch 8/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.3330 - accuracy: 0.240/303 [======================>.......]303/303 [==============================] - 0s 306us/step - loss: 0.3501 - accuracy: 0.8482 - val_loss: 0.1017 - val_accuracy: 0.9474\n",
      " - ETA: 0s - loss: 0.5882 - accuracy: 0.8250Epoch 10/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.3299 - accuracy: 0.7303/303 [==============================] - 0s 322us/step - loss: 0.5954 - accuracy: 0.8317 - val_loss: 0.1157 - val_accuracy: 0.9539\n",
      "224/303 [=====================>........] - ETA: 0s - loss: 0.5691 - accuracy: 0.7589Epoch 7/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.81 - ETA: 0s - loss: 0.5474 - accuracy: 0.83 - 0s 322us/step - loss: 0.5776 - accuracy: 0.7789 - val_loss: 0.2404 - val_accuracy: 0.9145\n",
      "Epoch 9/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - 0s 290us/step - loss: 0.5525 - accuracy: 0.8251 - val_loss: 0.2438 - val_accuracy: 0.9474\n",
      " - ETA: 0s - loss: 1.0221 - accuracy: 0.6875Epoch 11/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.81 - 0s 244us/step - loss: 0.7864 - accuracy: 0.7789 - val_loss: 0.1913 - val_accuracy: 0.9145\n",
      "Epoch 8/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.75 - ETA: 0s - loss: 0.6129 - accuracy: 0.74 - 0s 265us/step - loss: 0.6583 - accuracy: 0.7393 - val_loss: 0.3702 - val_accuracy: 0.9013\n",
      "Epoch 10/10000\n",
      " - 0s 245us/step - loss: 0.6126 - accuracy: 0.7822 - val_loss: 0.1657 - val_accuracy: 0.9211\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.3284 - accuracy: 0.8750Epoch 12/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.62 - 0s 233us/step - loss: 0.6440 - accuracy: 0.7723 - val_loss: 0.1641 - val_accuracy: 0.9276\n",
      "Epoch 9/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 1.00 - ETA: 0s - loss: 0.5089 - accuracy: 0.81 - 0s 234us/step - loss: 0.5802 - accuracy: 0.8086 - val_loss: 0.2979 - val_accuracy: 0.9276\n",
      "Epoch 11/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.5130 - accuracy: 0.75 - 0s 293us/step - loss: 0.5384 - accuracy: 0.8152 - val_loss: 0.1429 - val_accuracy: 0.9605\n",
      "303/303 [==============================]Epoch 13/10000 - 0s 215us/step - loss: 0.4238 - accuracy: 0.8185 - val_loss: 0.1362 - val_accuracy: 0.9342\n",
      "\n",
      "Epoch 10/10000 16/303 [>.............................]\n",
      "303/303 [==============================]7500 - ETA: 0s - loss: 0.9513 - accuracy: 0.56 - 0s 251us/step - loss: 0.6389 - accuracy: 0.7525 - val_loss: 0.2150 - val_accuracy: 0.9408\n",
      "Epoch 12/10000256/303 [========================>.....] - ETA: 0s - loss: 0.7133 - accuracy: 0.7500\n",
      "303/303 [==============================] 16/303 [>.............................] - 0s 224us/step - loss: 0.4862 - accuracy: 0.8152 - val_loss: 0.1836 - val_accuracy: 0.9539\n",
      " - ETA: 0s - loss: 0.3044 - accuracy: 0.8750Epoch 14/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.81 - 0s 287us/step - loss: 0.7626 - accuracy: 0.7459 - val_loss: 0.1401 - val_accuracy: 0.9342\n",
      "Epoch 11/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.81 - 0s 227us/step - loss: 0.5895 - accuracy: 0.7624 - val_loss: 0.2836 - val_accuracy: 0.9079\n",
      "Epoch 13/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - 0s 227us/step - loss: 0.4769 - accuracy: 0.8152 - val_loss: 0.2171 - val_accuracy: 0.8947\n",
      "Epoch 15/10000oss: 1.7389 - accuracy: 0.62240/303 [======================>.......]\n",
      " 16/303 [>.............................]7208 - ETA: 0s - loss: 0.2755 - accuracy: 0.81256/303 [========================>.....]303/303 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8086 - 0s 316us/step - loss: 0.5773 - accuracy: 0.7228 - val_loss: 0.2026 - val_accuracy: 0.9342\n",
      "Epoch 12/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - ETA: 0s - loss: 0.9019 - accuracy: 0.8750 - ETA: 0s - loss: 0.5102 - accuracy: 0.77 - 0s 261us/step - loss: 0.4527 - accuracy: 0.8119 - val_loss: 0.1640 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/10000\n",
      "303/303 [==============================] - 0s 280us/step - loss: 0.5037 - accuracy: 0.7756 - val_loss: 0.2525 - val_accuracy: 0.8882\n",
      " 16/303 [>.............................]Epoch 16/10000 - ETA: 0s - loss: 0.2892 - accuracy: 0.8125\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.87 - 0s 211us/step - loss: 0.6953 - accuracy: 0.7624 - val_loss: 0.2030 - val_accuracy: 0.9342\n",
      "Epoch 13/100\n",
      "303/303 [==============================]8056 16/303 [>.............................] - ETA: 0s - loss: 0.5804 - accuracy: 0.56 - ETA: 0s - loss: 0.4373 - accuracy: 0.82 - 0s 274us/step - loss: 0.5667 - accuracy: 0.8086 - val_loss: 0.1362 - val_accuracy: 0.9474\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 303us/step - loss: 0.4356 - accuracy: 0.8218 - val_loss: 0.2096 - val_accuracy: 0.9276\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.4807 - accuracy: 0.8125Epoch 17/10000\n",
      "303/303 [==============================]] - ETA: 0s - loss: 0.8611 - accuracy: 0.7500 - 0s 229us/step - loss: 0.5557 - accuracy: 0.7591 - val_loss: 1.0682 - val_accuracy: 0.6382\n",
      "Epoch 14/10000\n",
      " - 0s 327us/step - loss: 0.5603 - accuracy: 0.8119 - val_loss: 0.2488 - val_accuracy: 0.9539 loss: 0.4976 - accuracy: 0.8008 - ETA: 0s - loss: 0.5105 - accuracy: 0.7256/303 [========================>.... - ETA: 0s - loss: 0.6682 - accuracy: 0.7422\n",
      "303/303 [==============================] - 0s 290us/step - loss: 0.5223 - accuracy: 0.7855 - val_loss: 0.2532 - val_accuracy: 0.8289\n",
      "Epoch 16/10000Epoch 18/10000\n",
      "\n",
      "303/303 [==============================]0000 16/303 [>.............................] - ETA: 0s - loss: 0.5584 - accuracy: 0.81 - 0s 307us/step - loss: 0.6289 - accuracy: 0.7624 - val_loss: 0.1753 - val_accuracy: 0.9737\n",
      "Epoch 15/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.7288/303 [===========================>..] - ETA: 0s - loss: 0.4631 - accuracy: 0.8194 - ETA: 0s - loss: 0.4103 - accuracy: 0.79 - 0s 266us/step - loss: 0.4478 - accuracy: 0.8251 - val_loss: 0.1906 - val_accuracy: 0.9342\n",
      "Epoch 17/10000240/303 [======================>.......]\n",
      " 16/303 [>.............................]841 - ETA: 0s - loss: 0.5426 - accuracy: 0.7500303/303 [==============================] - 0s 310us/step - loss: 0.4004 - accuracy: 0.7954 - val_loss: 0.1431 - val_accuracy: 0.9342\n",
      "Epoch 19/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.87 - 0s 330us/step - loss: 0.4598 - accuracy: 0.8383 - val_loss: 0.1580 - val_accuracy: 0.9474\n",
      "Epoch 16/10000\n",
      " - ETA: 0s - loss: 0.4812 - accuracy: 0.7773: 0s - loss: 0.6353 - accuracy: 0.562256/303 [========================>.....]303/303 [==============================] - 0s 231us/step - loss: 0.6014 - accuracy: 0.7756 - val_loss: 0.1668 - val_accuracy: 0.9211\n",
      "Epoch 18/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.8483 - accuracy: 0.8125 - 0s 271us/step - loss: 0.5089 - accuracy: 0.7657 - val_loss: 0.1704 - val_accuracy: 0.9276\n",
      "288/303 [===========================>..]\n",
      "303/303 [==============================]7951 - ETA: 0s - loss: 0.8198 - accuracy: 0. - 0s 301us/step - loss: 0.4727 - accuracy: 0.8020 - val_loss: 0.2224 - val_accuracy: 0.9408\n",
      "272/303 [=========================>....] - ETA: 0s - loss: 0.5163 - accuracy: 0.8199Epoch 17/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.2967 - accuracy: 0.8750 - ETA: 0s - loss: 0.6332 - accuracy: 0.76 - 0s 300us/step - loss: 0.5111 - accuracy: 0.8218 - val_loss: 0.1822 - val_accuracy: 0.9474\n",
      "Epoch 19/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.3651 - accuracy: 0.8750 - 0s 288us/step - loss: 0.6601 - accuracy: 0.7723 - val_loss: 0.1934 - val_accuracy: 0.9539\n",
      "Epoch 21/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8 - 0s 269us/step - loss: 0.7104 - accuracy: 0.7492 - val_loss: 0.1663 - val_accuracy: 0.9211\n",
      "224/303 [=====================>........] - ETA: 0s - loss: 0.4794 - accuracy: 0.8527Epoch 18/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.2083 - accuracy: 0.56 - ETA: 0s - loss: 0.7783 - accuracy: 0.79 - 0s 298us/step - loss: 0.5277 - accuracy: 0.8416 - val_loss: 0.1862 - val_accuracy: 0.9474\n",
      "Epoch 20/10000\n",
      "272/303 [=========================>....] - 0s 310us/step - loss: 0.7116 - accuracy: 0.7921 - val_loss: 0.1784 - val_accuracy: 0.9474\n",
      " - ETA: 0s - loss: 0.6337 - accuracy: 0.8051Epoch 22/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.87 - 0s 291us/step - loss: 0.6493 - accuracy: 0.8086 - val_loss: 0.1610 - val_accuracy: 0.9474\n",
      "Epoch 19/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.4153 - accuracy: 0.7500 - 0s 217us/step - loss: 0.5174 - accuracy: 0.8515 - val_loss: 0.2159 - val_accuracy: 0.9539\n",
      "Epoch 21/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.9692 - accuracy: 0.62 - 0s 238us/step - loss: 0.5101 - accuracy: 0.7921 - val_loss: 0.2726 - val_accuracy: 0.9474\n",
      "Epoch 23/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3592 - accuracy: 0. - 0s 235us/step - loss: 0.4795 - accuracy: 0.8449 - val_loss: 0.1661 - val_accuracy: 0.9474\n",
      "272/303 [=========================>....]Epoch 20/10000\n",
      "303/303 [==============================]8346 - ETA: 0s - loss: 1.6739 - accuracy: 0.75 - ETA: 0s - loss: 0.6796 - accuracy: 0.73 - 0s 283us/step - loss: 0.4990 - accuracy: 0.8317 - val_loss: 0.2003 - val_accuracy: 0.9671\n",
      "Epoch 22/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.8252 - accuracy: 0.62303/303 [==============================]288/303 [===========================>..] - 0s 294us/step - loss: 0.6559 - accuracy: 0.7360 - val_loss: 0.2445 - val_accuracy: 0.9276\n",
      " - ETA: 0s - loss: 0.8797 - accuracy: 0.7778Epoch 24/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.87 - 0s 250us/step - loss: 0.8574 - accuracy: 0.7756 - val_loss: 0.1653 - val_accuracy: 0.9408\n",
      "Epoch 21/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0. - 0s 224us/step - loss: 0.6703 - accuracy: 0.8185 - val_loss: 0.1728 - val_accuracy: 0.9474\n",
      "288/303 [===========================>..]Epoch 23/10000 - ETA: 0s - loss: 0.6904 - accuracy: 0.7951\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0. - 0s 186us/step - loss: 0.5407 - accuracy: 0.8053 - val_loss: 0.2637 - val_accuracy: 0.9605\n",
      "303/303 [==============================]Epoch 22/10000 - 0s 279us/step - loss: 0.6764 - accuracy: 0.7987 - val_loss: 0.3680 - val_accuracy: 0.9276\n",
      "\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.4484 - accuracy: 0.7500Epoch 25/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.93 - 0s 227us/step - loss: 0.6996 - accuracy: 0.8218 - val_loss: 0.1681 - val_accuracy: 0.9539\n",
      "Epoch 24/10000\n",
      " 16/303 [>.............................]303/303 [==============================] - ETA: 0s - loss: 1.4846 - accuracy: 0.6875 - 0s 196us/step - loss: 0.5904 - accuracy: 0.7954 - val_loss: 0.2486 - val_accuracy: 0.9276\n",
      "Epoch 23/10000\n",
      "303/303 [==============================] - 0s 211us/step - loss: 0.6245 - accuracy: 0.7822 - val_loss: 0.1836 - val_accuracy: 0.9474\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.3121 - accuracy: 0.8750Epoch 26/10000\n",
      " 16/303 [>.............................] - ETA: 0s - loss: 0.5951 - accuracy: 0.303/303 [==============================]303/303 [==============================] - 0s 165us/step - loss: 0.4528 - accuracy: 0.8350 - val_loss: 0.1949 - val_accuracy: 0.9474\n",
      " - 0s 229us/step - loss: 0.6620 - accuracy: 0.7954 - val_loss: 0.1806 - val_accuracy: 0.9408\n",
      "Epoch 24/10000Epoch 25/100\n",
      "\n",
      "303/303 [==============================]8125 16/303 [>.............................] 16/303 [>.............................] - ETA: 0s - loss: 0.4208 - accuracy: 0.75 - 0s 222us/step - loss: 0.7183 - accuracy: 0.7954 - val_loss: 0.1957 - val_accuracy: 0.9474\n",
      "Epoch 27/10000\n",
      "303/303 [==============================] ETA: 0s - loss: 0.3294 - accuracy: 0.87 - 0s 163us/step - loss: 0.6264 - accuracy: 0.8284 - val_loss: 0.1836 - val_accuracy: 0.9474\n",
      "288/303 [===========================>..]Epoch 25/10000\n",
      "303/303 [==============================]8090 - ETA: 0s - loss: 0.2421 - accuracy: 0.81 - 0s 288us/step - loss: 0.5337 - accuracy: 0.7987 - val_loss: 0.2787 - val_accuracy: 0.8750\n",
      "Epoch 26/10000\n",
      " 16/303 [>.............................]303/303 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.93 - 0s 224us/step - loss: 0.6304 - accuracy: 0.7921 - val_loss: 0.1308 - val_accuracy: 0.9539\n",
      "303/303 [==============================] - 0s 183us/step - loss: 0.7472 - accuracy: 0.8185 - val_loss: 0.1713 - val_accuracy: 0.9474\n",
      "Epoch 28/10000\n",
      "Epoch 26/10000\n",
      "303/303 [==============================] 16/303 [>.............................] - ETA: 0s - loss: 0.4120 - accuracy: 0.8750 - ETA: 0s - loss: 0.3691 - accuracy: 0.81 - 0s 190us/step - loss: 0.5303 - accuracy: 0.7855 - val_loss: 0.2475 - val_accuracy: 0.8947\n",
      "Epoch 27/100\n",
      "303/303 [==============================] 16/303 [>.............................] - ETA: 0s - loss: 1.2510 - accuracy: 0.8125 - ETA: 0s - loss: 0.5770 - accuracy: 0.79 - 0s 197us/step - loss: 0.7510 - accuracy: 0.8020 - val_loss: 0.2583 - val_accuracy: 0.9276\n",
      "303/303 [==============================] - 0s 278us/step - loss: 0.5993 - accuracy: 0.7954 - val_loss: 0.1586 - val_accuracy: 0.9342\n",
      "Epoch 29/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.68 - 0s 187us/step - loss: 0.7339 - accuracy: 0.7723 - val_loss: 0.2097 - val_accuracy: 0.9079\n",
      "Epoch 28/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.62 - 0s 211us/step - loss: 0.7511 - accuracy: 0.7426 - val_loss: 0.1911 - val_accuracy: 0.9539\n",
      "303/303 [==============================] - 0s 188us/step - loss: 0.5207 - accuracy: 0.7558 - val_loss: 0.2451 - val_accuracy: 0.8882\n",
      "Epoch 29/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.87 - 0s 175us/step - loss: 0.5183 - accuracy: 0.7723 - val_loss: 0.2166 - val_accuracy: 0.8882\n",
      "Epoch 30/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.81 - 0s 164us/step - loss: 0.5353 - accuracy: 0.7525 - val_loss: 0.2717 - val_accuracy: 0.8947\n",
      "Epoch 31/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.81 - 0s 193us/step - loss: 0.5392 - accuracy: 0.7558 - val_loss: 0.3000 - val_accuracy: 0.9079\n",
      "Epoch 32/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.62 - 0s 174us/step - loss: 0.7901 - accuracy: 0.7261 - val_loss: 0.1195 - val_accuracy: 0.9474\n",
      "Epoch 33/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.87 - 0s 165us/step - loss: 0.5621 - accuracy: 0.7591 - val_loss: 0.0943 - val_accuracy: 0.9474\n",
      "Epoch 34/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.93 - 0s 214us/step - loss: 0.9054 - accuracy: 0.7756 - val_loss: 0.1157 - val_accuracy: 0.9408\n",
      "Epoch 35/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.81 - 0s 204us/step - loss: 0.7036 - accuracy: 0.7426 - val_loss: 0.2640 - val_accuracy: 0.9342\n",
      "Epoch 36/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.75 - 0s 180us/step - loss: 0.5786 - accuracy: 0.7327 - val_loss: 0.1541 - val_accuracy: 0.9342\n",
      "Epoch 37/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.68 - 0s 174us/step - loss: 0.5963 - accuracy: 0.7657 - val_loss: 0.1517 - val_accuracy: 0.9342\n",
      "Epoch 38/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.93 - 0s 176us/step - loss: 0.6256 - accuracy: 0.7855 - val_loss: 0.1245 - val_accuracy: 0.9474\n",
      "Epoch 39/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.81 - 0s 180us/step - loss: 1.0786 - accuracy: 0.7459 - val_loss: 0.1912 - val_accuracy: 0.9342\n",
      "Epoch 40/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.81 - 0s 162us/step - loss: 0.7968 - accuracy: 0.7624 - val_loss: 0.2502 - val_accuracy: 0.9145\n",
      "Epoch 41/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.68 - 0s 161us/step - loss: 0.5370 - accuracy: 0.7756 - val_loss: 0.3161 - val_accuracy: 0.9145\n",
      "Epoch 42/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.3050 - accuracy: 0.68 - 0s 203us/step - loss: 1.0069 - accuracy: 0.7657 - val_loss: 0.3301 - val_accuracy: 0.9145\n",
      "Epoch 43/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.75 - 0s 171us/step - loss: 1.2058 - accuracy: 0.7261 - val_loss: 0.4515 - val_accuracy: 0.9145\n",
      "Epoch 44/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.4269 - accuracy: 0.50 - 0s 179us/step - loss: 1.1550 - accuracy: 0.7129 - val_loss: 0.1711 - val_accuracy: 0.9145\n",
      "Epoch 45/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.1862 - accuracy: 0.68 - 0s 166us/step - loss: 0.8796 - accuracy: 0.6634 - val_loss: 0.1740 - val_accuracy: 0.9145\n",
      "Epoch 46/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.75 - 0s 193us/step - loss: 0.7600 - accuracy: 0.7063 - val_loss: 0.1687 - val_accuracy: 0.9013\n",
      "Epoch 47/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.81 - 0s 177us/step - loss: 0.7254 - accuracy: 0.6733 - val_loss: 0.2070 - val_accuracy: 0.9079\n",
      "Epoch 48/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.68 - 0s 168us/step - loss: 0.9383 - accuracy: 0.6832 - val_loss: 0.2435 - val_accuracy: 0.9211\n",
      "Epoch 49/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.75 - 0s 185us/step - loss: 0.9404 - accuracy: 0.6964 - val_loss: 0.2169 - val_accuracy: 0.9474\n",
      "Epoch 50/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.81 - 0s 180us/step - loss: 0.9738 - accuracy: 0.7459 - val_loss: 0.1703 - val_accuracy: 0.9539\n",
      "Epoch 51/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.81 - 0s 180us/step - loss: 1.2297 - accuracy: 0.7162 - val_loss: 0.1585 - val_accuracy: 0.9539\n",
      "Epoch 52/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.3130 - accuracy: 0.68 - 0s 198us/step - loss: 0.9869 - accuracy: 0.6832 - val_loss: 0.1854 - val_accuracy: 0.9408\n",
      "Epoch 53/10000\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.2955 - accuracy: 0.87 - 0s 195us/step - loss: 1.2262 - accuracy: 0.6766 - val_loss: 0.1949 - val_accuracy: 0.8355\n",
      "Train on 304 samples, validate on 151 samples\n",
      "Train on 304 samples, validate on 151 samples\n",
      "Epoch 1/10000\n",
      "Epoch 1/10000\n",
      " 16/304 [>.............................] - ETA: 6s - loss: 1.6348 - accuracy: 0.5000Train on 304 samples, validate on 151 samples\n",
      "304/304 [==============================] - ETA: 6s - loss: 1.9572 - accuracy: 0.31 - 0s 2ms/step - loss: 1.0318 - accuracy: 0.7171 - val_loss: 0.1833 - val_accuracy: 0.9338\n",
      "Epoch 1/10000\n",
      "Epoch 2/10000\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.4838 - accuracy: 0.7304/304 [==============================] - 1s 2ms/step - loss: 1.2064 - accuracy: 0.6974 - val_loss: 0.2071 - val_accuracy: 0.9139\n",
      "304/304 [==============================] - 0s 158us/step - loss: 0.4473 - accuracy: 0.8092 - val_loss: 0.1395 - val_accuracy: 0.9470\n",
      "Epoch 3/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.75 - 0s 140us/step - loss: 0.4028 - accuracy: 0.8651 - val_loss: 0.1603 - val_accuracy: 0.9536\n",
      "Epoch 4/10000\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.5602 - accuracy: 0.8750Epoch 2/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 1.2905 - accuracy: 0.75 - 0s 232us/step - loss: 0.5210 - accuracy: 0.8421 - val_loss: 0.1632 - val_accuracy: 0.9338\n",
      "Epoch 5/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.81 - 0s 248us/step - loss: 0.6265 - accuracy: 0.7730 - val_loss: 0.1551 - val_accuracy: 0.9404\n",
      "Epoch 3/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.75 - 0s 237us/step - loss: 0.6078 - accuracy: 0.8026 - val_loss: 0.1470 - val_accuracy: 0.9404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8125 - ETA: 0s - loss: 0.2374 - accuracy: 0.81 - 0s 284us/step - loss: 0.4993 - accuracy: 0.8224 - val_loss: 0.1387 - val_accuracy: 0.9404\n",
      "Epoch 4/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.93 - ETA: 0s - loss: 0.6042 - accuracy: 0. - 0s 311us/step - loss: 0.5692 - accuracy: 0.8355 - val_loss: 0.1823 - val_accuracy: 0.9470\n",
      "272/304 [=========================>....] - ETA: 0s - loss: 0.5668 - accuracy: 0.8088Epoch 7/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.81 - 0s 290us/step - loss: 0.5904 - accuracy: 0.8059 - val_loss: 0.1681 - val_accuracy: 0.9404\n",
      "Epoch 5/10000\n",
      "256/304 [========================>.....] - ETA: 0s - loss: 0.4652 - accuracy: 0.87 - ETA: 0s - loss: 0.5082 - accuracy: 0.78288/304 [===========================>..]304/304 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.8056 - 0s 315us/step - loss: 0.5017 - accuracy: 0.7763 - val_loss: 0.1850 - val_accuracy: 0.9272\n",
      "Epoch 8/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.62 - 0s 280us/step - loss: 0.5829 - accuracy: 0.8125 - val_loss: 0.1364 - val_accuracy: 0.9470\n",
      "Epoch 6/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.87 - ETA: 0s - loss: 0.5378 - accuracy: 0.7852 - ETA: 10s - loss: 1.5583 - accuracy: 0.5256/304 [========================>.....] - ETA: 0s - loss: 0.4989 - accuracy: 0.8242 - 0s 329us/step - loss: 0.5444 - accuracy: 0.7862 - val_loss: 0.2665 - val_accuracy: 0.9073\n",
      "Epoch 9/10000\n",
      "304/304 [==============================]176/304 [================>.............] - ETA: 0s - loss: 0.5727 - accuracy: 0.7500 - ETA: 0s - loss: 1.3734 - accuracy: 0.625 - 0s 343us/step - loss: 0.4863 - accuracy: 0.8224 - val_loss: 0.1442 - val_accuracy: 0.9470\n",
      "Epoch 7/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 1.7803 - accuracy: 0.68 - ETA: 0s - loss: 0.5128 - accuracy: 0.78 - 0s 291us/step - loss: 0.5724 - accuracy: 0.7467 - val_loss: 0.1716 - val_accuracy: 0.9338\n",
      "Epoch 10/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.93 - 0s 235us/step - loss: 0.5913 - accuracy: 0.8322 - val_loss: 0.1553 - val_accuracy: 0.9470\n",
      "Epoch 8/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.93 - ETA: 0s - loss: 0.4858 - accuracy: 0.84 - 1s 3ms/step - loss: 1.1481 - accuracy: 0.6875 - val_loss: 0.1782 - val_accuracy: 0.9272\n",
      "304/304 [==============================] - 0s 301us/step - loss: 0.4949 - accuracy: 0.8224 - val_loss: 0.1820 - val_accuracy: 0.9272\n",
      "Epoch 11/10000\n",
      "304/304 [==============================] 16/304 [>.............................] - 0s 239us/step - loss: 0.4818 - accuracy: 0.8586 - val_loss: 0.1540 - val_accuracy: 0.9404\n",
      " - ETA: 0s - loss: 0.9261 - accuracy: 0.7500Epoch 9/10000\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.7146 - accuracy: 0.7500Epoch 2/10000\n",
      " - 0s 291us/step - loss: 0.7239 - accuracy: 0.7697 - val_loss: 0.2092 - val_accuracy: 0.93380s - loss: 0.7203 - accuracy: 0.78 - ETA: 0s - loss: 0.5599 - accuracy: 0.\n",
      "304/304 [==============================] ETA: 0s - loss: 0.7199 - accuracy: 0.7852Epoch 12/10000\n",
      " - 0s 316us/step - loss: 0.5445 - accuracy: 0.7961 - val_loss: 0.1934 - val_accuracy: 0.9205\n",
      " 16/304 [>.............................]Epoch 10/10000 - ETA: 0s - loss: 0.4537 - accuracy: 0.6250\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.81 - 0s 308us/step - loss: 0.6818 - accuracy: 0.7796 - val_loss: 0.1776 - val_accuracy: 0.9272\n",
      "Epoch 3/10000\n",
      "304/304 [==============================]8750272/304 [=========================>....] - ETA: 0s - loss: 0.4795 - accuracy: 0.77 - ETA: 0s - loss: 0.3899 - accuracy: 0.80 - 0s 303us/step - loss: 0.4569 - accuracy: 0.7895 - val_loss: 0.1851 - val_accuracy: 0.9338\n",
      "272/304 [=========================>...Epoch 13/10000\n",
      " - ETA: 0s - loss: 0.5547 - accuracy: 0.8051304/304 [==============================] - 0s 317us/step - loss: 0.3820 - accuracy: 0.8059 - val_loss: 0.1898 - val_accuracy: 0.9205\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.4947 - accuracy: 0.6250Epoch 11/10000\n",
      "304/304 [==============================] ETA: 0s - loss: 0.2453 - accuracy: 0.9375 - 0s 276us/step - loss: 0.5397 - accuracy: 0.8059 - val_loss: 0.2103 - val_accuracy: 0.9404\n",
      "Epoch 4/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.8359 ETA: 0s - loss: 0.3214 - accuracy: 0.85 - ETA: 0s - loss: 0.4495 - accuracy: 0. - 0s 325us/step - loss: 0.3414 - accuracy: 0.8421 - val_loss: 0.2183 - val_accuracy: 0.9338\n",
      "Epoch 14/10000\n",
      " - 0s 314us/step - loss: 0.4292 - accuracy: 0.8289 - val_loss: 0.1805 - val_accuracy: 0.9404\n",
      " 16/304 [>.............................]Epoch 12/10000 - ETA: 0s - loss: 1.0189 - accuracy: 0.6875\n",
      " - ETA: 0s - loss: 0.2751 - accuracy: 0.9375304/304 [==============================] - 0s 297us/step - loss: 0.6024 - accuracy: 0.8322 - val_loss: 0.1832 - val_accuracy: 0.9272\n",
      "Epoch 5/10000\n",
      " - ETA: 0s - loss: 0.3941 - accuracy: 0.8477TA: 0s - loss: 0.2495 - accuracy: 0.87 - ETA: 0s - loss: 0.5222 - accuracy: 0.83 - ETA: 0s - loss: 0.4004 - accuracy: 0.8256/304 [========================>.....]304/304 [==============================] - 0s 295us/step - loss: 0.5589 - accuracy: 0.8257 - val_loss: 0.2852 - val_accuracy: 0.9073\n",
      "Epoch 15/10000\n",
      "304/304 [==============================] 16/304 [>.............................] - 0s 286us/step - loss: 0.3771 - accuracy: 0.8520 - val_loss: 0.2050 - val_accuracy: 0.9139\n",
      " - ETA: 0s - loss: 1.3272 - accuracy: 0.6875Epoch 13/10000\n",
      " - ETA: 0s - loss: 0.4126 - accuracy: 0.7500304/304 [==============================] - 0s 286us/step - loss: 0.3770 - accuracy: 0.8454 - val_loss: 0.1882 - val_accuracy: 0.9404\n",
      "Epoch 6/10000\n",
      " - ETA: 0s - loss: 0.4019 - accuracy: 0.8269TA: 0s - loss: 0.6226 - accuracy: 0.93 - ETA: 0s - loss: 0.9702 - accuracy: 0.77 - ETA: 0s - loss: 0.4860 - accuracy: 0.8208/304 [===================>..........]304/304 [==============================] - 0s 312us/step - loss: 0.8520 - accuracy: 0.7928 - val_loss: 0.2490 - val_accuracy: 0.9272\n",
      "Epoch 16/10000\n",
      " - 0s 306us/step - loss: 0.4984 - accuracy: 0.8289 - val_loss: 0.1786 - val_accuracy: 0.9536\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.6239 - accuracy: 0.8125Epoch 14/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.93 - 0s 341us/step - loss: 0.4455 - accuracy: 0.8289 - val_loss: 0.1840 - val_accuracy: 0.9404\n",
      "Epoch 7/10000\n",
      " - 0s 292us/step - loss: 0.5259 - accuracy: 0.8421 - val_loss: 0.1757 - val_accuracy: 0.9404 - loss: 0.5417 - accuracy: 0.84 - ETA: 0s - loss: 0.5190 - accuracy: 0.\n",
      "256/304 [========================>.....] - ETA: 0s - loss: 0.5197 - accuracy: 0.82Epoch 17/10000\n",
      "304/304 [==============================] - 0s 292us/step - loss: 0.5477 - accuracy: 0.8224 - val_loss: 0.1928 - val_accuracy: 0.9536\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.0779 - accuracy: 1.0000Epoch 15/10000\n",
      "304/304 [==============================] ETA: 0s - loss: 1.0822 - accuracy: 0.9375 - 0s 289us/step - loss: 0.5229 - accuracy: 0.8224 - val_loss: 0.1927 - val_accuracy: 0.9404\n",
      "Epoch 8/10000\n",
      " - ETA: 0s - loss: 0.5470 - accuracy: 0.8382TA: 0s - loss: 0.2498 - accuracy: 0.8272/304 [=========================>....]304/304 [==============================] - 0s 238us/step - loss: 0.5057 - accuracy: 0.8454 - val_loss: 0.1687 - val_accuracy: 0.9338\n",
      "Epoch 18/10000\n",
      " - ETA: 0s - loss: 0.5164 - accuracy: 0.6875 - ETA: 0s - loss: 0.5149 - accuracy: 0.8272304/304 [==============================] - 0s 291us/step - loss: 0.5394 - accuracy: 0.8421 - val_loss: 0.1916 - val_accuracy: 0.9205\n",
      "Epoch 16/10000\n",
      "304/304 [==============================] ETA: 0s - loss: 0.7529 - accuracy: 0.7500 - 0s 276us/step - loss: 0.4937 - accuracy: 0.8257 - val_loss: 0.1768 - val_accuracy: 0.9404\n",
      "Epoch 9/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.7774 - accuracy: 0. - 0s 216us/step - loss: 0.5965 - accuracy: 0.8092 - val_loss: 0.1671 - val_accuracy: 0.9404\n",
      "288/304 [===========================>..]Epoch 19/10000 - ETA: 0s - loss: 0.3950 - accuracy: 0.8681\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.7535 - accuracy: 0.75 - 0s 278us/step - loss: 0.4420 - accuracy: 0.8618 - val_loss: 0.1636 - val_accuracy: 0.9272\n",
      "Epoch 17/10000\n",
      "304/304 [==============================] - 0s 211us/step - loss: 0.8575 - accuracy: 0.7566 - val_loss: 0.1881 - val_accuracy: 0.9603\n",
      " 16/304 [>.............................]Epoch 10/10000 - ETA: 0s - loss: 0.2353 - accuracy: 0.8750\n",
      "304/304 [==============================] 16/304 [>.............................] - ETA: 0s - loss: 0.3855 - accuracy: 0.8125 - ETA: 0s - loss: 0.6878 - accuracy: 0. - 0s 288us/step - loss: 0.6317 - accuracy: 0.8059 - val_loss: 0.2145 - val_accuracy: 0.9272\n",
      "288/304 [===========================>..] - ETA: 0s - loss: 0.5525 - accuracy: 0.8125Epoch 20/10000\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 1.3096 - accuracy: 0.81304/304 [==============================]304/304 [==============================] - 0s 232us/step - loss: 0.6049 - accuracy: 0.7961 - val_loss: 0.1842 - val_accuracy: 0.9272\n",
      " - 0s 261us/step - loss: 0.5390 - accuracy: 0.8158 - val_loss: 0.1707 - val_accuracy: 0.9073\n",
      "Epoch 11/10000Epoch 18/10000\n",
      "\n",
      "304/304 [==============================]8125 16/304 [>.............................] - ETA: 0s - loss: 0.2123 - accuracy: 1.00 - ETA: 0s - loss: 0.5778 - accuracy: 0.288/304 [===========================>..]208/304 [===================>..........] - ETA: 0s - loss: 0.6323 - accuracy: 0.7917 - ETA: 0s - loss: 0.5791 - accuracy: 0.86 - 0s 318us/step - loss: 0.5701 - accuracy: 0.8191 - val_loss: 0.2327 - val_accuracy: 0.9272\n",
      "Epoch 21/10000\n",
      "304/304 [==============================] - 0s 273us/step - loss: 0.6373 - accuracy: 0.7928 - val_loss: 0.2037 - val_accuracy: 0.9338\n",
      " 16/304 [>.............................]Epoch 12/10000 - ETA: 0s - loss: 1.3119 - accuracy: 0.7500\n",
      " - ETA: 0s - loss: 0.2268 - accuracy: 0.9375304/304 [==============================] - 0s 320us/step - loss: 0.6278 - accuracy: 0.8520 - val_loss: 0.1735 - val_accuracy: 0.9338\n",
      "Epoch 19/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.81 - 0s 220us/step - loss: 0.7800 - accuracy: 0.7599 - val_loss: 0.2602 - val_accuracy: 0.9272\n",
      "Epoch 22/10000304/304 [==============================]\n",
      " - 0s 227us/step - loss: 0.6388 - accuracy: 0.8224 - val_loss: 0.2102 - val_accuracy: 0.9338\n",
      " 16/304 [>............................ - ETA: 0s - loss: 0.3824 - accuracy: 0.8125Epoch 13/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.8229 - ETA: 0s - loss: 0.3771 - accuracy: 0.75 - 0s 300us/step - loss: 0.5368 - accuracy: 0.8224 - val_loss: 0.1809 - val_accuracy: 0.9338\n",
      "Epoch 20/10000\n",
      " 16/304 [>............................ - ETA: 0s - loss: 0.1755 - accuracy: 0.937304/304 [==============================] - 0s 222us/step - loss: 0.6518 - accuracy: 0.7664 - val_loss: 0.1991 - val_accuracy: 0.8940\n",
      "304/304 [==============================] - 0s 209us/step - loss: 0.4470 - accuracy: 0.8158 - val_loss: 0.1713 - val_accuracy: 0.9272\n",
      "Epoch 14/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.81 - 0s 221us/step - loss: 0.5358 - accuracy: 0.8421 - val_loss: 0.2475 - val_accuracy: 0.9272\n",
      "Epoch 21/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.87 - ETA: 0s - loss: 0.4852 - accuracy: 0.79 - 0s 271us/step - loss: 0.5279 - accuracy: 0.7993 - val_loss: 0.1698 - val_accuracy: 0.9272\n",
      "Epoch 15/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.93 - 0s 199us/step - loss: 0.5528 - accuracy: 0.8322 - val_loss: 0.1865 - val_accuracy: 0.9338\n",
      "Epoch 22/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.87 - ETA: 0s - loss: 0.3604 - accuracy: 0.86 - 0s 287us/step - loss: 0.3485 - accuracy: 0.8553 - val_loss: 0.1544 - val_accuracy: 0.9404\n",
      "Epoch 16/10000\n",
      "304/304 [==============================] - 0s 236us/step - loss: 0.5516 - accuracy: 0.8158 - val_loss: 0.1715 - val_accuracy: 0.9272\n",
      " 16/304 [>.............................]Epoch 23/10000 - ETA: 0s - loss: 0.4616 - accuracy: 0.8125\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.56 - ETA: 0s - loss: 0.4476 - accuracy: 0.78 - 0s 232us/step - loss: 0.5943 - accuracy: 0.8388 - val_loss: 0.1628 - val_accuracy: 0.9470\n",
      "Epoch 17/10000\n",
      " - ETA: 4s - loss: 0.2903 - accuracy: 0.8750304/304 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7829 - val_loss: 0.1723 - val_accuracy: 0.9205\n",
      "Epoch 24/10000\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.5883 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-01 18:49:52,827] Finished trial#0 with value: 0.12973128967991276 with parameters: {'input_dropout': 0.6390508031418598, 'hidden_layers': 2, 'hidden_units': 56.0, 'hidden_dropout': 0.8863564940982054, 'batch_norm': 'non', 'batch_size': 32.0}. Best is trial#0 with value: 0.12973128967991276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.8125 - val_loss: 0.1902 - val_accuracy: 0.9272\n",
      "304/304 [==============================]\n",
      " - 0s 210us/step - loss: 0.5149 - accuracy: 0.7993 - val_loss: 0.1778 - val_accuracy: 0.9272\n",
      "Epoch 25/10000 16/304 [>.............................]\n",
      "304/304 [==============================]6875 - ETA: 0s - loss: 0.4556 - accuracy: 0. - 0s 210us/step - loss: 0.5276 - accuracy: 0.7895 - val_loss: 0.1823 - val_accuracy: 0.9338\n",
      "304/304 [==============================]Epoch 19/10000 - 0s 207us/step - loss: 0.6447 - accuracy: 0.7796 - val_loss: 0.1410 - val_accuracy: 0.9536\n",
      "\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.81 - 0s 182us/step - loss: 0.3907 - accuracy: 0.8158 - val_loss: 0.1904 - val_accuracy: 0.9007\n",
      "Epoch 20/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.81 - 0s 184us/step - loss: 0.6150 - accuracy: 0.7829 - val_loss: 0.1886 - val_accuracy: 0.9272\n",
      "Epoch 21/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.81 - 0s 160us/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.2410 - val_accuracy: 0.9272\n",
      "Epoch 22/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.68 - 0s 155us/step - loss: 0.6599 - accuracy: 0.7368 - val_loss: 0.2361 - val_accuracy: 0.9272\n",
      "Epoch 23/10000\n",
      " 16/304 [>.............................] - ETA: 0s - loss: 0.4550 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-01 18:49:53,472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Finished trial#2 with value: 0.12105200598168951 with parameters: {'input_dropout': 0.8333800304661316, 'hidden_layers': 2, 'hidden_units': 32.0, 'hidden_dropout': 0.5142278368806639, 'batch_norm': 'non', 'batch_size': 16.0}. Best is trial#2 with value: 0.12105200598168951."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 0s 968us/step - loss: 0.6773 - accuracy: 0.7632 - val_loss: 0.2380 - val_accuracy: 0.9205\n",
      "Epoch 24/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 1.2893 - accuracy: 0.75 - 0s 121us/step - loss: 0.6368 - accuracy: 0.7862 - val_loss: 0.2278 - val_accuracy: 0.9205\n",
      "Epoch 25/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.93 - 0s 137us/step - loss: 1.0064 - accuracy: 0.7204 - val_loss: 0.3658 - val_accuracy: 0.8874\n",
      "Epoch 26/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.56 - 0s 140us/step - loss: 0.8147 - accuracy: 0.7730 - val_loss: 0.3288 - val_accuracy: 0.9139\n",
      "Epoch 27/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 1.00 - 0s 142us/step - loss: 0.7451 - accuracy: 0.7730 - val_loss: 0.2579 - val_accuracy: 0.9007\n",
      "Epoch 28/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 1.3435 - accuracy: 0.81 - 0s 142us/step - loss: 0.5765 - accuracy: 0.7796 - val_loss: 0.3860 - val_accuracy: 0.9272\n",
      "Epoch 29/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 1.7543 - accuracy: 0.75 - 0s 135us/step - loss: 0.7241 - accuracy: 0.7500 - val_loss: 0.3007 - val_accuracy: 0.9205\n",
      "Epoch 30/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.75 - 0s 125us/step - loss: 0.4132 - accuracy: 0.8158 - val_loss: 0.2796 - val_accuracy: 0.9073\n",
      "Epoch 31/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.75 - 0s 117us/step - loss: 0.5775 - accuracy: 0.7664 - val_loss: 0.2859 - val_accuracy: 0.9205\n",
      "Epoch 32/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.75 - 0s 123us/step - loss: 0.6016 - accuracy: 0.7697 - val_loss: 0.3027 - val_accuracy: 0.9272\n",
      "Epoch 33/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.68 - 0s 131us/step - loss: 0.6297 - accuracy: 0.7796 - val_loss: 0.3036 - val_accuracy: 0.9338\n",
      "Epoch 34/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.68 - 0s 135us/step - loss: 0.9008 - accuracy: 0.7566 - val_loss: 0.2997 - val_accuracy: 0.9272\n",
      "Epoch 35/10000\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.8122 - accuracy: 0.75 - 0s 130us/step - loss: 0.7006 - accuracy: 0.7862 - val_loss: 0.3333 - val_accuracy: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-01 18:49:54,410] Finished trial#1 with value: 0.1345668229604153 with parameters: {'input_dropout': 0.7167152904533249, 'hidden_layers': 1, 'hidden_units': 24.0, 'hidden_dropout': 0.24537038185395454, 'batch_norm': 'before_act', 'batch_size': 32.0}. Best is trial#2 with value: 0.12105200598168951.\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_PARAMS = {\n",
    "    'X_path': '../data/X.csv',\n",
    "    'y_path': '../data/y.csv',\n",
    "    'X_test_path': '../data/X_test.csv',\n",
    "    'under_sampling': True,\n",
    "    'optimize': True,\n",
    "    'LGB': False,\n",
    "    'XGB': False,\n",
    "    'NN': True,\n",
    "}\n",
    "\n",
    "\n",
    "X = np.array(pd.read_csv(PIPELINE_PARAMS['X_path']).iloc[:,1:])\n",
    "Y = np.array(pd.read_csv(PIPELINE_PARAMS['y_path']).iloc[:,1:]).flatten()\n",
    "X_test = np.array(pd.read_csv(PIPELINE_PARAMS['X_test_path']).iloc[:,1:])\n",
    "print(X.shape)\n",
    "# Y[:200] = 0\n",
    "if PIPELINE_PARAMS['under_sampling']==True:\n",
    "    X, Y = under_sampling(X, Y)\n",
    "\n",
    "### Optimizing Phase\n",
    "n_trials = 3\n",
    "n_jobs = -1\n",
    "random_state = 0\n",
    "LGB_PARAMS, XGB_PARAMS, NN_PARAMS = Optimizer(n_trials, n_jobs, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_dropout': 0.6390508031418598,\n",
       "  'hidden_layers': 2,\n",
       "  'hidden_units': 56.0,\n",
       "  'hidden_dropout': 0.8863564940982054,\n",
       "  'batch_norm': 'non',\n",
       "  'batch_size': 32.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set default paramseters\n"
     ]
    }
   ],
   "source": [
    "### Training Phase\n",
    "print('Set default paramseters')\n",
    "paramset_lgb = Paramset(LGBMClassifier())\n",
    "paramset_lgb.swiching_lr('train')\n",
    "lgb_params = paramset_lgb.generate_params()\n",
    "paramset_xgb = Paramset(XGBClassifier())\n",
    "paramset_xgb.swiching_lr('train')\n",
    "xgb_params = paramset_xgb.generate_params()\n",
    "paramset_nn = Paramset(NNClassifier())\n",
    "paramset_nn.swiching_lr('train')\n",
    "nn_params = paramset_nn.generate_params()\n",
    "\n",
    "\n",
    "\n",
    "def Ensembler(n_splits, early_stopping_rounds, random_state):\n",
    "    LGB_PREFDS = []\n",
    "    XGB_PREFDS = []\n",
    "    NN_PREFDS = []\n",
    "    flag_inputtype = type(X).__name__\n",
    "    if flag_inputtype == 'list':\n",
    "        for i, x, y in zip(np.arange(len(X)), X, Y):\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            if len(LGB_PARAMS) != 0:\n",
    "                print('LGB params were optimized')\n",
    "                lgb_params.update(LGB_PARAMS[i])\n",
    "                lgb_params['min_child_samples'] = int(LGB_PARAMS[i]['min_child_samples'])\n",
    "            else:\n",
    "                print('LGB params were not optimized')\n",
    "            if len(XGB_PARAMS) != 0:\n",
    "                print('XGB params were optimized')\n",
    "                xgb_params.update(XGB_PARAMS[i])\n",
    "            else:\n",
    "                print('XGB params were not optimized')\n",
    "            if len(NN_PARAMS) != 0:\n",
    "                nn_params.update(NN_PARAMS[i])\n",
    "                nn_params['hidden_units'] = int(NN_PARAMS[i]['hidden_units'])\n",
    "                nn_params['batch_size'] = int(NN_PARAMS[i]['batch_size'])\n",
    "                print('NN params were optimized')\n",
    "            else:\n",
    "                print('NN params were not optimized')         \n",
    "            if PIPELINE_PARAMS['LGB']==True:\n",
    "                print('-----------------------------------------------------------------------------------------------------')\n",
    "                print(f'LGB: {lgb_params}')\n",
    "                print('-----------------------------------------------------------------------------------------------------')\n",
    "                va_pred_lgb, te_preds_lgb = cv_and_emsemble_predict(\n",
    "                    LGBMClassifier(**lgb_params),\n",
    "                    x,\n",
    "                    y,\n",
    "                    X_test,\n",
    "                    n_splits,\n",
    "                    early_stopping_rounds,\n",
    "                    random_state\n",
    "                )\n",
    "                LGB_PREFDS.append([va_pred_lgb, te_preds_lgb])\n",
    "            if PIPELINE_PARAMS['XGB']==True:\n",
    "                print('-----------------------------------------------------------------------------------------------------')\n",
    "                print(f'XGB: {xgb_params}')\n",
    "                print('-----------------------------------------------------------------------------------------------------')\n",
    "                va_pred_xgb, te_preds_xgb = cv_and_emsemble_predict(\n",
    "                    XGBClassifier(**xgb_params),\n",
    "                    x,\n",
    "                    y,\n",
    "                    X_test,\n",
    "                    n_splits,\n",
    "                    early_stopping_rounds,\n",
    "                    random_state\n",
    "                )\n",
    "                XGB_PREFDS.append([va_pred_xgb, te_preds_xgb])\n",
    "            if PIPELINE_PARAMS['NN']==True:\n",
    "                nn_params['input_shape'] = x.shape[1]\n",
    "                print('-----------------------------------------------------------------------------------------------------')\n",
    "                print(f'NN: {nn_params}')\n",
    "                print('-----------------------------------------------------------------------------------------------------')\n",
    "                va_pred_nn, te_preds_nn = cv_and_emsemble_predict(\n",
    "                    NNClassifier(**nn_params),\n",
    "                    x,\n",
    "                    y,\n",
    "                    X_test,\n",
    "                    n_splits,\n",
    "                    early_stopping_rounds,\n",
    "                    random_state\n",
    "                )\n",
    "                NN_PREFDS.append([va_pred_nn, te_preds_nn])\n",
    "    elif flag_inputtype == 'ndarray':\n",
    "        # parameters \n",
    "        if len(LGB_PARAMS) != 0:\n",
    "            print('LGB params were optimized')\n",
    "            lgb_params.update(LGB_PARAMS[0])\n",
    "            lgb_params['min_child_samples'] = int(LGB_PARAMS[0]['min_child_samples'])\n",
    "        else:\n",
    "            print('LGB params were not optimized')\n",
    "        if len(XGB_PARAMS) != 0:\n",
    "            print('XGB params were optimized')\n",
    "            xgb_params.update(XGB_PARAMS[0])\n",
    "        else:\n",
    "            print('XGB params were not optimized')\n",
    "        if len(NN_PARAMS) != 0:\n",
    "            nn_params.update(NN_PARAMS[0])\n",
    "            nn_params['hidden_units'] = int(NN_PARAMS[0]['hidden_units'])\n",
    "            nn_params['batch_size'] = int(NN_PARAMS[0]['batch_size'])\n",
    "            print('NN params were optimized')\n",
    "        else:\n",
    "            print('NN params were not optimized')\n",
    "        # training\n",
    "        if PIPELINE_PARAMS['LGB']==True:\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            print(f'LGB: {lgb_params}')\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            va_pred_lgb, te_preds_lgb = cv_and_emsemble_predict(\n",
    "                LGBMClassifier(**lgb_params),\n",
    "                X,\n",
    "                Y,\n",
    "                X_test,\n",
    "                n_splits,\n",
    "                early_stopping_rounds,\n",
    "                random_state\n",
    "            )\n",
    "            LGB_PREFDS.append([va_pred_lgb, te_preds_lgb])\n",
    "        if PIPELINE_PARAMS['XGB']==True:\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            print(f'XGB: {xgb_params}')\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            va_pred_xgb, te_preds_xgb = cv_and_emsemble_predict(\n",
    "                XGBClassifier(**xgb_params),\n",
    "                X,\n",
    "                Y,\n",
    "                X_test,\n",
    "                n_splits,\n",
    "                early_stopping_rounds,\n",
    "                random_state\n",
    "            )\n",
    "            XGB_PREFDS.append([va_pred_xgb, te_preds_xgb])\n",
    "        if PIPELINE_PARAMS['NN']==True:\n",
    "            nn_params['input_shape'] = X.shape[1]\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            print(f'NN: {nn_params}')\n",
    "            print('-----------------------------------------------------------------------------------------------------')\n",
    "            va_pred_nn, te_preds_nn = cv_and_emsemble_predict(\n",
    "                NNClassifier(**nn_params),\n",
    "                X,\n",
    "                Y,\n",
    "                X_test,\n",
    "                n_splits,\n",
    "                early_stopping_rounds,\n",
    "                random_state\n",
    "            )\n",
    "            NN_PREFDS.append([va_pred_nn, te_preds_nn])\n",
    "    return LGB_PREFDS, XGB_PREFDS, NN_PREFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB params were not optimized\n",
      "XGB params were not optimized\n",
      "NN params were optimized\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "NN: {'learning_rate': 0.001, 'input_shape': 30, 'input_dropout': 0.8333800304661316, 'hidden_layers': 2, 'hidden_units': 32, 'hidden_dropout': 0.5142278368806639, 'batch_norm': 'non', 'batch_size': 16, 'epochs': 10000}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/10000\n",
      "364/364 [==============================] - ETA: 6s - loss: 0.8391 - accuracy: 0.56 - 0s 1ms/step - loss: 1.3036 - accuracy: 0.5440 - val_loss: 0.3878 - val_accuracy: 0.9341\n",
      "Epoch 2/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.0655 - accuracy: 0.37 - 0s 108us/step - loss: 0.9465 - accuracy: 0.6264 - val_loss: 0.3506 - val_accuracy: 0.9341\n",
      "Epoch 3/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9058 - accuracy: 0.56 - 0s 115us/step - loss: 0.9987 - accuracy: 0.6209 - val_loss: 0.3275 - val_accuracy: 0.9560\n",
      "Epoch 4/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.0765 - accuracy: 0.68 - 0s 107us/step - loss: 0.7126 - accuracy: 0.6703 - val_loss: 0.3097 - val_accuracy: 0.9341\n",
      "Epoch 5/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.68 - 0s 109us/step - loss: 0.7469 - accuracy: 0.7060 - val_loss: 0.2924 - val_accuracy: 0.9560\n",
      "Epoch 6/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7521 - accuracy: 0.56 - 0s 125us/step - loss: 0.7394 - accuracy: 0.6566 - val_loss: 0.2824 - val_accuracy: 0.9670\n",
      "Epoch 7/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7510 - accuracy: 0.62 - 0s 126us/step - loss: 0.5978 - accuracy: 0.7225 - val_loss: 0.2730 - val_accuracy: 0.9560\n",
      "Epoch 8/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.93 - 0s 126us/step - loss: 0.6226 - accuracy: 0.7308 - val_loss: 0.2653 - val_accuracy: 0.9560\n",
      "Epoch 9/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.62 - 0s 125us/step - loss: 0.6845 - accuracy: 0.7143 - val_loss: 0.2632 - val_accuracy: 0.9451\n",
      "Epoch 10/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.68 - 0s 122us/step - loss: 0.5714 - accuracy: 0.7473 - val_loss: 0.2581 - val_accuracy: 0.9560\n",
      "Epoch 11/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.87 - 0s 121us/step - loss: 0.5888 - accuracy: 0.7610 - val_loss: 0.2527 - val_accuracy: 0.9451\n",
      "Epoch 12/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8609 - accuracy: 0.62 - 0s 120us/step - loss: 0.5667 - accuracy: 0.7555 - val_loss: 0.2506 - val_accuracy: 0.9560\n",
      "Epoch 13/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.87 - 0s 108us/step - loss: 0.5668 - accuracy: 0.7582 - val_loss: 0.2503 - val_accuracy: 0.9560\n",
      "Epoch 14/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.87 - 0s 107us/step - loss: 0.5441 - accuracy: 0.7445 - val_loss: 0.2491 - val_accuracy: 0.9560\n",
      "Epoch 15/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.62 - 0s 115us/step - loss: 0.4762 - accuracy: 0.7637 - val_loss: 0.2406 - val_accuracy: 0.9560\n",
      "Epoch 16/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.50 - 0s 109us/step - loss: 0.5452 - accuracy: 0.7555 - val_loss: 0.2351 - val_accuracy: 0.9560\n",
      "Epoch 17/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.81 - 0s 105us/step - loss: 0.5030 - accuracy: 0.7747 - val_loss: 0.2306 - val_accuracy: 0.9560\n",
      "Epoch 18/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.68 - 0s 122us/step - loss: 0.4606 - accuracy: 0.8077 - val_loss: 0.2264 - val_accuracy: 0.9560\n",
      "Epoch 19/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9153 - accuracy: 0.68 - 0s 119us/step - loss: 0.5357 - accuracy: 0.7555 - val_loss: 0.2239 - val_accuracy: 0.9560\n",
      "Epoch 20/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.81 - 0s 111us/step - loss: 0.4513 - accuracy: 0.8104 - val_loss: 0.2194 - val_accuracy: 0.9560\n",
      "Epoch 21/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.75 - 0s 106us/step - loss: 0.6019 - accuracy: 0.7665 - val_loss: 0.2168 - val_accuracy: 0.9560\n",
      "Epoch 22/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.81 - 0s 114us/step - loss: 0.4839 - accuracy: 0.7885 - val_loss: 0.2157 - val_accuracy: 0.9560\n",
      "Epoch 23/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.81 - 0s 111us/step - loss: 0.4317 - accuracy: 0.8159 - val_loss: 0.2140 - val_accuracy: 0.9560\n",
      "Epoch 24/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.62 - 0s 106us/step - loss: 0.5171 - accuracy: 0.7747 - val_loss: 0.2155 - val_accuracy: 0.9560\n",
      "Epoch 25/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.81 - 0s 112us/step - loss: 0.4257 - accuracy: 0.8159 - val_loss: 0.2102 - val_accuracy: 0.9560\n",
      "Epoch 26/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7723 - accuracy: 0.75 - 0s 118us/step - loss: 0.4176 - accuracy: 0.8132 - val_loss: 0.2093 - val_accuracy: 0.9670\n",
      "Epoch 27/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.62 - 0s 115us/step - loss: 0.3953 - accuracy: 0.8022 - val_loss: 0.2044 - val_accuracy: 0.9670\n",
      "Epoch 28/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.68 - 0s 113us/step - loss: 0.4283 - accuracy: 0.8297 - val_loss: 0.1996 - val_accuracy: 0.9670\n",
      "Epoch 29/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.81 - 0s 116us/step - loss: 0.4183 - accuracy: 0.8187 - val_loss: 0.1974 - val_accuracy: 0.9560\n",
      "Epoch 30/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 1.00 - 0s 122us/step - loss: 0.3878 - accuracy: 0.8407 - val_loss: 0.1958 - val_accuracy: 0.9560\n",
      "Epoch 31/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.62 - 0s 129us/step - loss: 0.3705 - accuracy: 0.8297 - val_loss: 0.1935 - val_accuracy: 0.9560\n",
      "Epoch 32/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.93 - 0s 135us/step - loss: 0.4263 - accuracy: 0.8242 - val_loss: 0.1919 - val_accuracy: 0.9560\n",
      "Epoch 33/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7133 - accuracy: 0.62 - 0s 127us/step - loss: 0.4333 - accuracy: 0.8352 - val_loss: 0.1936 - val_accuracy: 0.9560\n",
      "Epoch 34/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.0210 - accuracy: 0.56 - 0s 129us/step - loss: 0.4210 - accuracy: 0.8214 - val_loss: 0.1949 - val_accuracy: 0.9560\n",
      "Epoch 35/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.62 - 0s 150us/step - loss: 0.3735 - accuracy: 0.8407 - val_loss: 0.1915 - val_accuracy: 0.9560\n",
      "Epoch 36/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 1.00 - 0s 118us/step - loss: 0.4103 - accuracy: 0.8324 - val_loss: 0.1867 - val_accuracy: 0.9560\n",
      "Epoch 37/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.87 - 0s 154us/step - loss: 0.4102 - accuracy: 0.8214 - val_loss: 0.1872 - val_accuracy: 0.9670\n",
      "Epoch 38/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.87 - 0s 132us/step - loss: 0.3512 - accuracy: 0.8846 - val_loss: 0.1861 - val_accuracy: 0.9560\n",
      "Epoch 39/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.87 - 0s 134us/step - loss: 0.3856 - accuracy: 0.8214 - val_loss: 0.1878 - val_accuracy: 0.9670\n",
      "Epoch 40/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.93 - 0s 151us/step - loss: 0.3246 - accuracy: 0.8571 - val_loss: 0.1869 - val_accuracy: 0.9670\n",
      "Epoch 41/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.93 - 0s 128us/step - loss: 0.3717 - accuracy: 0.8242 - val_loss: 0.1859 - val_accuracy: 0.9670\n",
      "Epoch 42/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 1.00 - 0s 128us/step - loss: 0.3774 - accuracy: 0.8242 - val_loss: 0.1854 - val_accuracy: 0.9670\n",
      "Epoch 43/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.75 - 0s 108us/step - loss: 0.3896 - accuracy: 0.8324 - val_loss: 0.1848 - val_accuracy: 0.9670\n",
      "Epoch 44/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.87 - 0s 107us/step - loss: 0.3481 - accuracy: 0.8709 - val_loss: 0.1849 - val_accuracy: 0.9670\n",
      "Epoch 45/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.87 - 0s 111us/step - loss: 0.3671 - accuracy: 0.8544 - val_loss: 0.1838 - val_accuracy: 0.9670\n",
      "Epoch 46/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.81 - 0s 115us/step - loss: 0.3327 - accuracy: 0.8736 - val_loss: 0.1843 - val_accuracy: 0.9670\n",
      "Epoch 47/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.87 - 0s 106us/step - loss: 0.3445 - accuracy: 0.8599 - val_loss: 0.1827 - val_accuracy: 0.9670\n",
      "Epoch 48/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.87 - 0s 110us/step - loss: 0.3187 - accuracy: 0.8434 - val_loss: 0.1775 - val_accuracy: 0.9670\n",
      "Epoch 49/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.81 - 0s 100us/step - loss: 0.3178 - accuracy: 0.8407 - val_loss: 0.1744 - val_accuracy: 0.9670\n",
      "Epoch 50/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 1.00 - 0s 106us/step - loss: 0.3360 - accuracy: 0.8709 - val_loss: 0.1739 - val_accuracy: 0.9670\n",
      "Epoch 51/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.81 - 0s 107us/step - loss: 0.3009 - accuracy: 0.8791 - val_loss: 0.1715 - val_accuracy: 0.9560\n",
      "Epoch 52/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.68 - 0s 101us/step - loss: 0.3280 - accuracy: 0.8599 - val_loss: 0.1691 - val_accuracy: 0.9560\n",
      "Epoch 53/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.93 - 0s 106us/step - loss: 0.3027 - accuracy: 0.8764 - val_loss: 0.1670 - val_accuracy: 0.9560\n",
      "Epoch 54/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.87 - 0s 105us/step - loss: 0.3509 - accuracy: 0.8489 - val_loss: 0.1684 - val_accuracy: 0.9560\n",
      "Epoch 55/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.93 - 0s 112us/step - loss: 0.3524 - accuracy: 0.8516 - val_loss: 0.1689 - val_accuracy: 0.9560\n",
      "Epoch 56/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.75 - 0s 107us/step - loss: 0.2971 - accuracy: 0.8626 - val_loss: 0.1687 - val_accuracy: 0.9560\n",
      "Epoch 57/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.93 - 0s 113us/step - loss: 0.3524 - accuracy: 0.8901 - val_loss: 0.1655 - val_accuracy: 0.9560\n",
      "Epoch 58/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.81 - 0s 111us/step - loss: 0.3441 - accuracy: 0.8489 - val_loss: 0.1655 - val_accuracy: 0.9560\n",
      "Epoch 59/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 1.00 - 0s 113us/step - loss: 0.3631 - accuracy: 0.8489 - val_loss: 0.1665 - val_accuracy: 0.9560\n",
      "Epoch 60/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.87 - 0s 113us/step - loss: 0.2974 - accuracy: 0.8791 - val_loss: 0.1677 - val_accuracy: 0.9560\n",
      "Epoch 61/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.87 - 0s 112us/step - loss: 0.3401 - accuracy: 0.8654 - val_loss: 0.1663 - val_accuracy: 0.9560\n",
      "Epoch 62/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8035 - accuracy: 0.81 - 0s 112us/step - loss: 0.4189 - accuracy: 0.8297 - val_loss: 0.1684 - val_accuracy: 0.9560\n",
      "Epoch 63/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.93 - 0s 118us/step - loss: 0.3065 - accuracy: 0.8819 - val_loss: 0.1666 - val_accuracy: 0.9670\n",
      "Epoch 64/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.93 - 0s 114us/step - loss: 0.3453 - accuracy: 0.8599 - val_loss: 0.1658 - val_accuracy: 0.9670\n",
      "Epoch 65/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.75 - 0s 117us/step - loss: 0.3363 - accuracy: 0.8544 - val_loss: 0.1661 - val_accuracy: 0.9670\n",
      "Epoch 66/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.87 - 0s 114us/step - loss: 0.3062 - accuracy: 0.8791 - val_loss: 0.1647 - val_accuracy: 0.9670\n",
      "Epoch 67/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.93 - 0s 108us/step - loss: 0.2904 - accuracy: 0.8791 - val_loss: 0.1610 - val_accuracy: 0.9670\n",
      "Epoch 68/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.75 - 0s 108us/step - loss: 0.3087 - accuracy: 0.8544 - val_loss: 0.1605 - val_accuracy: 0.9670\n",
      "Epoch 69/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.87 - 0s 107us/step - loss: 0.3260 - accuracy: 0.8626 - val_loss: 0.1590 - val_accuracy: 0.9670\n",
      "Epoch 70/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.87 - 0s 107us/step - loss: 0.3643 - accuracy: 0.8709 - val_loss: 0.1623 - val_accuracy: 0.9670\n",
      "Epoch 71/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.93 - 0s 113us/step - loss: 0.3377 - accuracy: 0.8736 - val_loss: 0.1632 - val_accuracy: 0.9670\n",
      "Epoch 72/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.87 - 0s 111us/step - loss: 0.3150 - accuracy: 0.8709 - val_loss: 0.1654 - val_accuracy: 0.9670\n",
      "Epoch 73/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.87 - 0s 106us/step - loss: 0.2823 - accuracy: 0.8736 - val_loss: 0.1622 - val_accuracy: 0.9670\n",
      "Epoch 74/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.81 - 0s 112us/step - loss: 0.2847 - accuracy: 0.8819 - val_loss: 0.1588 - val_accuracy: 0.9670\n",
      "Epoch 75/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 1.00 - 0s 118us/step - loss: 0.3120 - accuracy: 0.8791 - val_loss: 0.1602 - val_accuracy: 0.9670\n",
      "Epoch 76/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.81 - 0s 118us/step - loss: 0.2986 - accuracy: 0.8571 - val_loss: 0.1599 - val_accuracy: 0.9670\n",
      "Epoch 77/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - 0s 115us/step - loss: 0.3221 - accuracy: 0.8709 - val_loss: 0.1586 - val_accuracy: 0.9670\n",
      "Epoch 78/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.93 - 0s 121us/step - loss: 0.2898 - accuracy: 0.8544 - val_loss: 0.1577 - val_accuracy: 0.9670\n",
      "Epoch 79/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.93 - 0s 114us/step - loss: 0.3221 - accuracy: 0.8626 - val_loss: 0.1578 - val_accuracy: 0.9670\n",
      "Epoch 80/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.68 - 0s 124us/step - loss: 0.2994 - accuracy: 0.8599 - val_loss: 0.1586 - val_accuracy: 0.9560\n",
      "Epoch 81/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.87 - 0s 125us/step - loss: 0.2992 - accuracy: 0.8681 - val_loss: 0.1588 - val_accuracy: 0.9560\n",
      "Epoch 82/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.93 - 0s 114us/step - loss: 0.2957 - accuracy: 0.8764 - val_loss: 0.1579 - val_accuracy: 0.9560\n",
      "Epoch 83/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 1.00 - 0s 114us/step - loss: 0.2973 - accuracy: 0.8544 - val_loss: 0.1570 - val_accuracy: 0.9560\n",
      "Epoch 84/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - 0s 116us/step - loss: 0.2830 - accuracy: 0.8791 - val_loss: 0.1568 - val_accuracy: 0.9560\n",
      "Epoch 85/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.93 - 0s 114us/step - loss: 0.2676 - accuracy: 0.8764 - val_loss: 0.1556 - val_accuracy: 0.9560\n",
      "Epoch 86/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.81 - 0s 104us/step - loss: 0.3107 - accuracy: 0.8819 - val_loss: 0.1543 - val_accuracy: 0.9560\n",
      "Epoch 87/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.75 - 0s 111us/step - loss: 0.2962 - accuracy: 0.8736 - val_loss: 0.1552 - val_accuracy: 0.9560\n",
      "Epoch 88/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.68 - 0s 109us/step - loss: 0.3068 - accuracy: 0.8736 - val_loss: 0.1557 - val_accuracy: 0.9670\n",
      "Epoch 89/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6523 - accuracy: 0.87 - 0s 105us/step - loss: 0.3306 - accuracy: 0.8571 - val_loss: 0.1569 - val_accuracy: 0.9670\n",
      "Epoch 90/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 1.00 - 0s 110us/step - loss: 0.2909 - accuracy: 0.8764 - val_loss: 0.1566 - val_accuracy: 0.9670\n",
      "Epoch 91/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.87 - 0s 111us/step - loss: 0.3170 - accuracy: 0.8736 - val_loss: 0.1601 - val_accuracy: 0.9560\n",
      "Epoch 92/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.93 - 0s 109us/step - loss: 0.2640 - accuracy: 0.8929 - val_loss: 0.1607 - val_accuracy: 0.9560\n",
      "Epoch 93/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.81 - 0s 107us/step - loss: 0.3402 - accuracy: 0.8516 - val_loss: 0.1623 - val_accuracy: 0.9560\n",
      "Epoch 94/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.93 - 0s 105us/step - loss: 0.2781 - accuracy: 0.8929 - val_loss: 0.1624 - val_accuracy: 0.9670\n",
      "Epoch 95/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.75 - 0s 110us/step - loss: 0.3185 - accuracy: 0.8791 - val_loss: 0.1607 - val_accuracy: 0.9670\n",
      "Epoch 96/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.81 - 0s 102us/step - loss: 0.2880 - accuracy: 0.8544 - val_loss: 0.1597 - val_accuracy: 0.9670\n",
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/10000\n",
      "364/364 [==============================] - ETA: 6s - loss: 1.1812 - accuracy: 0.68 - 0s 1ms/step - loss: 1.2495 - accuracy: 0.5192 - val_loss: 0.6356 - val_accuracy: 0.6703\n",
      "Epoch 2/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.0609 - accuracy: 0.56 - 0s 96us/step - loss: 1.0961 - accuracy: 0.5220 - val_loss: 0.5468 - val_accuracy: 0.8352\n",
      "Epoch 3/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.0016 - accuracy: 0.50 - 0s 105us/step - loss: 0.8642 - accuracy: 0.5879 - val_loss: 0.4989 - val_accuracy: 0.8681\n",
      "Epoch 4/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.1380 - accuracy: 0.56 - 0s 110us/step - loss: 0.8806 - accuracy: 0.6016 - val_loss: 0.4664 - val_accuracy: 0.8791\n",
      "Epoch 5/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8555 - accuracy: 0.62 - 0s 109us/step - loss: 0.8574 - accuracy: 0.6209 - val_loss: 0.4324 - val_accuracy: 0.8901\n",
      "Epoch 6/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.68 - 0s 117us/step - loss: 0.7654 - accuracy: 0.6044 - val_loss: 0.4045 - val_accuracy: 0.9011\n",
      "Epoch 7/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7420 - accuracy: 0.68 - 0s 128us/step - loss: 0.8875 - accuracy: 0.6209 - val_loss: 0.3848 - val_accuracy: 0.9231\n",
      "Epoch 8/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.56 - 0s 122us/step - loss: 0.7573 - accuracy: 0.6346 - val_loss: 0.3637 - val_accuracy: 0.9231\n",
      "Epoch 9/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.87 - 0s 111us/step - loss: 0.6159 - accuracy: 0.7170 - val_loss: 0.3498 - val_accuracy: 0.9341\n",
      "Epoch 10/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.62 - 0s 120us/step - loss: 0.7130 - accuracy: 0.6923 - val_loss: 0.3405 - val_accuracy: 0.9341\n",
      "Epoch 11/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.75 - 0s 113us/step - loss: 0.5456 - accuracy: 0.7335 - val_loss: 0.3280 - val_accuracy: 0.9451\n",
      "Epoch 12/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.68 - 0s 122us/step - loss: 0.5674 - accuracy: 0.7280 - val_loss: 0.3171 - val_accuracy: 0.9341\n",
      "Epoch 13/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.62 - 0s 121us/step - loss: 0.5480 - accuracy: 0.7637 - val_loss: 0.3045 - val_accuracy: 0.9451\n",
      "Epoch 14/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.75 - 0s 127us/step - loss: 0.6943 - accuracy: 0.6511 - val_loss: 0.2956 - val_accuracy: 0.9451\n",
      "Epoch 15/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.68 - 0s 126us/step - loss: 0.5275 - accuracy: 0.7225 - val_loss: 0.2865 - val_accuracy: 0.9341\n",
      "Epoch 16/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7361 - accuracy: 0.50 - 0s 125us/step - loss: 0.5534 - accuracy: 0.7500 - val_loss: 0.2761 - val_accuracy: 0.9451\n",
      "Epoch 17/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7459 - accuracy: 0.75 - 0s 123us/step - loss: 0.5728 - accuracy: 0.7308 - val_loss: 0.2717 - val_accuracy: 0.9451\n",
      "Epoch 18/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.62 - 0s 123us/step - loss: 0.5326 - accuracy: 0.7665 - val_loss: 0.2660 - val_accuracy: 0.9451\n",
      "Epoch 19/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7821 - accuracy: 0.62 - 0s 128us/step - loss: 0.5509 - accuracy: 0.7582 - val_loss: 0.2625 - val_accuracy: 0.9451\n",
      "Epoch 20/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9241 - accuracy: 0.62 - 0s 129us/step - loss: 0.5387 - accuracy: 0.7885 - val_loss: 0.2600 - val_accuracy: 0.9451\n",
      "Epoch 21/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.62 - 0s 116us/step - loss: 0.5093 - accuracy: 0.7775 - val_loss: 0.2545 - val_accuracy: 0.9451\n",
      "Epoch 22/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.81 - 0s 117us/step - loss: 0.5348 - accuracy: 0.8077 - val_loss: 0.2502 - val_accuracy: 0.9451\n",
      "Epoch 23/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.81 - 0s 122us/step - loss: 0.4968 - accuracy: 0.7637 - val_loss: 0.2430 - val_accuracy: 0.9451\n",
      "Epoch 24/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.75 - 0s 129us/step - loss: 0.4583 - accuracy: 0.7885 - val_loss: 0.2361 - val_accuracy: 0.9451\n",
      "Epoch 25/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.2236 - accuracy: 0.68 - 0s 135us/step - loss: 0.4706 - accuracy: 0.8077 - val_loss: 0.2342 - val_accuracy: 0.9560\n",
      "Epoch 26/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8235 - accuracy: 0.62 - 0s 144us/step - loss: 0.5035 - accuracy: 0.8022 - val_loss: 0.2299 - val_accuracy: 0.9560\n",
      "Epoch 27/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.75 - 0s 165us/step - loss: 0.4750 - accuracy: 0.7775 - val_loss: 0.2255 - val_accuracy: 0.9560\n",
      "Epoch 28/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.87 - 0s 156us/step - loss: 0.4201 - accuracy: 0.8269 - val_loss: 0.2228 - val_accuracy: 0.9560\n",
      "Epoch 29/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7115 - accuracy: 0.68 - 0s 138us/step - loss: 0.4368 - accuracy: 0.7967 - val_loss: 0.2189 - val_accuracy: 0.9560\n",
      "Epoch 30/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.87 - 0s 124us/step - loss: 0.4569 - accuracy: 0.8049 - val_loss: 0.2143 - val_accuracy: 0.9451\n",
      "Epoch 31/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.81 - 0s 126us/step - loss: 0.4649 - accuracy: 0.8104 - val_loss: 0.2137 - val_accuracy: 0.9451\n",
      "Epoch 32/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.68 - 0s 119us/step - loss: 0.4355 - accuracy: 0.8214 - val_loss: 0.2131 - val_accuracy: 0.9451\n",
      "Epoch 33/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.81 - 0s 126us/step - loss: 0.4612 - accuracy: 0.7995 - val_loss: 0.2118 - val_accuracy: 0.9560\n",
      "Epoch 34/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.68 - 0s 130us/step - loss: 0.4431 - accuracy: 0.8049 - val_loss: 0.2082 - val_accuracy: 0.9560\n",
      "Epoch 35/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4504 - accuracy: 0.68 - 0s 133us/step - loss: 0.3668 - accuracy: 0.8324 - val_loss: 0.2017 - val_accuracy: 0.9560\n",
      "Epoch 36/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 1.00 - 0s 126us/step - loss: 0.4141 - accuracy: 0.8297 - val_loss: 0.1978 - val_accuracy: 0.9451\n",
      "Epoch 37/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.87 - 0s 127us/step - loss: 0.3939 - accuracy: 0.8379 - val_loss: 0.1973 - val_accuracy: 0.9451\n",
      "Epoch 38/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.56 - 0s 123us/step - loss: 0.4163 - accuracy: 0.8269 - val_loss: 0.1932 - val_accuracy: 0.9451\n",
      "Epoch 39/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.81 - 0s 143us/step - loss: 0.4091 - accuracy: 0.8132 - val_loss: 0.1900 - val_accuracy: 0.9451\n",
      "Epoch 40/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.81 - 0s 154us/step - loss: 0.4050 - accuracy: 0.8379 - val_loss: 0.1872 - val_accuracy: 0.9451\n",
      "Epoch 41/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8589 - accuracy: 0.81 - 0s 147us/step - loss: 0.4542 - accuracy: 0.8297 - val_loss: 0.1865 - val_accuracy: 0.9451\n",
      "Epoch 42/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.81 - 0s 152us/step - loss: 0.4227 - accuracy: 0.8407 - val_loss: 0.1854 - val_accuracy: 0.9451\n",
      "Epoch 43/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.87 - 0s 150us/step - loss: 0.3708 - accuracy: 0.8489 - val_loss: 0.1840 - val_accuracy: 0.9451\n",
      "Epoch 44/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.87 - 0s 157us/step - loss: 0.3542 - accuracy: 0.8324 - val_loss: 0.1785 - val_accuracy: 0.9451\n",
      "Epoch 45/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.87 - 0s 158us/step - loss: 0.3429 - accuracy: 0.8379 - val_loss: 0.1744 - val_accuracy: 0.9451\n",
      "Epoch 46/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.87 - ETA: 0s - loss: 0.3750 - accuracy: 0.83 - 0s 200us/step - loss: 0.3713 - accuracy: 0.8489 - val_loss: 0.1717 - val_accuracy: 0.9451\n",
      "Epoch 47/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.81 - 0s 158us/step - loss: 0.3587 - accuracy: 0.8599 - val_loss: 0.1725 - val_accuracy: 0.9451\n",
      "Epoch 48/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.81 - ETA: 0s - loss: 0.4095 - accuracy: 0.82 - 0s 191us/step - loss: 0.4154 - accuracy: 0.8214 - val_loss: 0.1752 - val_accuracy: 0.9451\n",
      "Epoch 49/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.93 - 0s 151us/step - loss: 0.3364 - accuracy: 0.8489 - val_loss: 0.1747 - val_accuracy: 0.9451\n",
      "Epoch 50/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.1751 - accuracy: 0.68 - 0s 145us/step - loss: 0.3629 - accuracy: 0.8544 - val_loss: 0.1743 - val_accuracy: 0.9451\n",
      "Epoch 51/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.93 - ETA: 0s - loss: 0.3178 - accuracy: 0.86 - 0s 204us/step - loss: 0.3264 - accuracy: 0.8599 - val_loss: 0.1699 - val_accuracy: 0.9451\n",
      "Epoch 52/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.93 - 0s 161us/step - loss: 0.3004 - accuracy: 0.8846 - val_loss: 0.1660 - val_accuracy: 0.9451\n",
      "Epoch 53/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - ETA: 0s - loss: 0.3471 - accuracy: 0.86 - 0s 192us/step - loss: 0.3533 - accuracy: 0.8571 - val_loss: 0.1631 - val_accuracy: 0.9451\n",
      "Epoch 54/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.81 - 0s 146us/step - loss: 0.3141 - accuracy: 0.8544 - val_loss: 0.1592 - val_accuracy: 0.9451\n",
      "Epoch 55/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.93 - 0s 144us/step - loss: 0.3898 - accuracy: 0.8462 - val_loss: 0.1603 - val_accuracy: 0.9451\n",
      "Epoch 56/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - 0s 157us/step - loss: 0.3328 - accuracy: 0.8489 - val_loss: 0.1582 - val_accuracy: 0.9451\n",
      "Epoch 57/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.87 - 0s 157us/step - loss: 0.3686 - accuracy: 0.8434 - val_loss: 0.1578 - val_accuracy: 0.9451\n",
      "Epoch 58/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.93 - 0s 154us/step - loss: 0.3409 - accuracy: 0.8819 - val_loss: 0.1570 - val_accuracy: 0.9451\n",
      "Epoch 59/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.81 - 0s 148us/step - loss: 0.3281 - accuracy: 0.8709 - val_loss: 0.1591 - val_accuracy: 0.9451\n",
      "Epoch 60/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.68 - 0s 139us/step - loss: 0.3331 - accuracy: 0.8736 - val_loss: 0.1579 - val_accuracy: 0.9451\n",
      "Epoch 61/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.87 - 0s 137us/step - loss: 0.3829 - accuracy: 0.8736 - val_loss: 0.1585 - val_accuracy: 0.9451\n",
      "Epoch 62/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.87 - 0s 135us/step - loss: 0.3587 - accuracy: 0.8544 - val_loss: 0.1594 - val_accuracy: 0.9451\n",
      "Epoch 63/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5717 - accuracy: 0.81 - 0s 140us/step - loss: 0.3623 - accuracy: 0.8434 - val_loss: 0.1567 - val_accuracy: 0.9451\n",
      "Epoch 64/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.87 - 0s 158us/step - loss: 0.3460 - accuracy: 0.8736 - val_loss: 0.1586 - val_accuracy: 0.9451\n",
      "Epoch 65/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.81 - 0s 143us/step - loss: 0.3551 - accuracy: 0.8709 - val_loss: 0.1564 - val_accuracy: 0.9451\n",
      "Epoch 66/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.56 - 0s 139us/step - loss: 0.3520 - accuracy: 0.8489 - val_loss: 0.1562 - val_accuracy: 0.9451\n",
      "Epoch 67/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.87 - 0s 137us/step - loss: 0.3461 - accuracy: 0.8269 - val_loss: 0.1559 - val_accuracy: 0.9451\n",
      "Epoch 68/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.75 - 0s 128us/step - loss: 0.3556 - accuracy: 0.8516 - val_loss: 0.1541 - val_accuracy: 0.9451\n",
      "Epoch 69/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.93 - 0s 130us/step - loss: 0.3295 - accuracy: 0.8571 - val_loss: 0.1503 - val_accuracy: 0.9451\n",
      "Epoch 70/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.87 - 0s 143us/step - loss: 0.3007 - accuracy: 0.8819 - val_loss: 0.1477 - val_accuracy: 0.9451\n",
      "Epoch 71/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.87 - 0s 128us/step - loss: 0.3291 - accuracy: 0.8846 - val_loss: 0.1498 - val_accuracy: 0.9451\n",
      "Epoch 72/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.87 - 0s 123us/step - loss: 0.3616 - accuracy: 0.8571 - val_loss: 0.1496 - val_accuracy: 0.9560\n",
      "Epoch 73/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.93 - 0s 125us/step - loss: 0.3044 - accuracy: 0.8846 - val_loss: 0.1490 - val_accuracy: 0.9560\n",
      "Epoch 74/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 1.00 - 0s 123us/step - loss: 0.3425 - accuracy: 0.8764 - val_loss: 0.1492 - val_accuracy: 0.9560\n",
      "Epoch 75/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.81 - 0s 116us/step - loss: 0.3469 - accuracy: 0.8544 - val_loss: 0.1522 - val_accuracy: 0.9451\n",
      "Epoch 76/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.87 - 0s 125us/step - loss: 0.3868 - accuracy: 0.8462 - val_loss: 0.1529 - val_accuracy: 0.9560\n",
      "Epoch 77/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - 0s 126us/step - loss: 0.3252 - accuracy: 0.8544 - val_loss: 0.1506 - val_accuracy: 0.9560\n",
      "Epoch 78/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.87 - 0s 133us/step - loss: 0.3378 - accuracy: 0.8654 - val_loss: 0.1495 - val_accuracy: 0.9560\n",
      "Epoch 79/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.87 - 0s 124us/step - loss: 0.3493 - accuracy: 0.8709 - val_loss: 0.1490 - val_accuracy: 0.9560\n",
      "Epoch 80/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.93 - 0s 124us/step - loss: 0.3160 - accuracy: 0.8709 - val_loss: 0.1500 - val_accuracy: 0.9560\n",
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/10000\n",
      "364/364 [==============================] - ETA: 6s - loss: 1.3040 - accuracy: 0.43 - 1s 1ms/step - loss: 1.0240 - accuracy: 0.5440 - val_loss: 0.5336 - val_accuracy: 0.8242\n",
      "Epoch 2/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.8443 - accuracy: 0.62 - 0s 113us/step - loss: 1.0294 - accuracy: 0.5769 - val_loss: 0.4715 - val_accuracy: 0.8571\n",
      "Epoch 3/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.1400 - accuracy: 0.56 - 0s 133us/step - loss: 0.8577 - accuracy: 0.6566 - val_loss: 0.4261 - val_accuracy: 0.8901\n",
      "Epoch 4/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.75 - 0s 126us/step - loss: 0.8171 - accuracy: 0.6264 - val_loss: 0.3929 - val_accuracy: 0.9011\n",
      "Epoch 5/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7654 - accuracy: 0.62 - 0s 119us/step - loss: 0.8308 - accuracy: 0.6264 - val_loss: 0.3748 - val_accuracy: 0.8901\n",
      "Epoch 6/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.4621 - accuracy: 0.43 - 0s 128us/step - loss: 0.7498 - accuracy: 0.6621 - val_loss: 0.3599 - val_accuracy: 0.8901\n",
      "Epoch 7/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.68 - 0s 128us/step - loss: 0.5816 - accuracy: 0.7115 - val_loss: 0.3445 - val_accuracy: 0.8901\n",
      "Epoch 8/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.81 - 0s 129us/step - loss: 0.6385 - accuracy: 0.7198 - val_loss: 0.3270 - val_accuracy: 0.8901\n",
      "Epoch 9/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6851 - accuracy: 0.75 - 0s 134us/step - loss: 0.7331 - accuracy: 0.6868 - val_loss: 0.3183 - val_accuracy: 0.9121\n",
      "Epoch 10/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.93 - 0s 133us/step - loss: 0.5496 - accuracy: 0.7390 - val_loss: 0.3076 - val_accuracy: 0.9231\n",
      "Epoch 11/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8225 - accuracy: 0.75 - 0s 125us/step - loss: 0.6276 - accuracy: 0.7198 - val_loss: 0.3000 - val_accuracy: 0.9231\n",
      "Epoch 12/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.75 - 0s 130us/step - loss: 0.6087 - accuracy: 0.7033 - val_loss: 0.2911 - val_accuracy: 0.9231\n",
      "Epoch 13/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.87 - 0s 147us/step - loss: 0.5368 - accuracy: 0.7170 - val_loss: 0.2829 - val_accuracy: 0.9231\n",
      "Epoch 14/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.93 - 0s 152us/step - loss: 0.5042 - accuracy: 0.7720 - val_loss: 0.2730 - val_accuracy: 0.9231\n",
      "Epoch 15/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.81 - 0s 147us/step - loss: 0.5376 - accuracy: 0.7582 - val_loss: 0.2663 - val_accuracy: 0.9231\n",
      "Epoch 16/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.87 - 0s 148us/step - loss: 0.4708 - accuracy: 0.7720 - val_loss: 0.2600 - val_accuracy: 0.9231\n",
      "Epoch 17/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.68 - 0s 156us/step - loss: 0.5088 - accuracy: 0.7747 - val_loss: 0.2512 - val_accuracy: 0.9231\n",
      "Epoch 18/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.62 - 0s 147us/step - loss: 0.4885 - accuracy: 0.7802 - val_loss: 0.2440 - val_accuracy: 0.9231\n",
      "Epoch 19/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.62 - 0s 136us/step - loss: 0.5476 - accuracy: 0.7418 - val_loss: 0.2387 - val_accuracy: 0.9231\n",
      "Epoch 20/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.81 - 0s 141us/step - loss: 0.4313 - accuracy: 0.8132 - val_loss: 0.2312 - val_accuracy: 0.9231\n",
      "Epoch 21/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.81 - 0s 142us/step - loss: 0.4200 - accuracy: 0.8214 - val_loss: 0.2233 - val_accuracy: 0.9231\n",
      "Epoch 22/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.0089 - accuracy: 0.62 - 0s 148us/step - loss: 0.5194 - accuracy: 0.7802 - val_loss: 0.2198 - val_accuracy: 0.9231\n",
      "Epoch 23/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.75 - 0s 149us/step - loss: 0.4710 - accuracy: 0.7940 - val_loss: 0.2190 - val_accuracy: 0.9231\n",
      "Epoch 24/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.75 - 0s 162us/step - loss: 0.4868 - accuracy: 0.7802 - val_loss: 0.2167 - val_accuracy: 0.9231\n",
      "Epoch 25/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.81 - 0s 148us/step - loss: 0.4214 - accuracy: 0.8132 - val_loss: 0.2141 - val_accuracy: 0.9231\n",
      "Epoch 26/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.81 - 0s 151us/step - loss: 0.4076 - accuracy: 0.8187 - val_loss: 0.2089 - val_accuracy: 0.9231\n",
      "Epoch 27/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7757 - accuracy: 0.68 - 0s 155us/step - loss: 0.4031 - accuracy: 0.8544 - val_loss: 0.2036 - val_accuracy: 0.9231\n",
      "Epoch 28/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.81 - 0s 155us/step - loss: 0.3985 - accuracy: 0.8297 - val_loss: 0.2006 - val_accuracy: 0.9231\n",
      "Epoch 29/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 1.00 - 0s 154us/step - loss: 0.4332 - accuracy: 0.8214 - val_loss: 0.1970 - val_accuracy: 0.9231\n",
      "Epoch 30/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.81 - 0s 149us/step - loss: 0.4321 - accuracy: 0.8352 - val_loss: 0.1930 - val_accuracy: 0.9231\n",
      "Epoch 31/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.62 - 0s 151us/step - loss: 0.3909 - accuracy: 0.8049 - val_loss: 0.1875 - val_accuracy: 0.9231\n",
      "Epoch 32/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5294 - accuracy: 0.87 - 0s 154us/step - loss: 0.4092 - accuracy: 0.8104 - val_loss: 0.1858 - val_accuracy: 0.9231\n",
      "Epoch 33/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 1.00 - 0s 152us/step - loss: 0.3676 - accuracy: 0.8681 - val_loss: 0.1838 - val_accuracy: 0.9231\n",
      "Epoch 34/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.87 - 0s 155us/step - loss: 0.4349 - accuracy: 0.8187 - val_loss: 0.1825 - val_accuracy: 0.9231\n",
      "Epoch 35/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 1.00 - 0s 148us/step - loss: 0.3609 - accuracy: 0.8352 - val_loss: 0.1796 - val_accuracy: 0.9231\n",
      "Epoch 36/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.75 - 0s 153us/step - loss: 0.4121 - accuracy: 0.8407 - val_loss: 0.1772 - val_accuracy: 0.9341\n",
      "Epoch 37/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.81 - 0s 147us/step - loss: 0.4181 - accuracy: 0.8269 - val_loss: 0.1781 - val_accuracy: 0.9341\n",
      "Epoch 38/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.93 - 0s 146us/step - loss: 0.3466 - accuracy: 0.8544 - val_loss: 0.1774 - val_accuracy: 0.9341\n",
      "Epoch 39/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.81 - 0s 150us/step - loss: 0.4123 - accuracy: 0.8297 - val_loss: 0.1761 - val_accuracy: 0.9341\n",
      "Epoch 40/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 1.00 - 0s 157us/step - loss: 0.3846 - accuracy: 0.8379 - val_loss: 0.1761 - val_accuracy: 0.9341\n",
      "Epoch 41/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 1.00 - 0s 162us/step - loss: 0.3944 - accuracy: 0.8489 - val_loss: 0.1758 - val_accuracy: 0.9341\n",
      "Epoch 42/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.81 - 0s 148us/step - loss: 0.3293 - accuracy: 0.8462 - val_loss: 0.1719 - val_accuracy: 0.9341\n",
      "Epoch 43/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.87 - 0s 148us/step - loss: 0.3840 - accuracy: 0.8352 - val_loss: 0.1696 - val_accuracy: 0.9341\n",
      "Epoch 44/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.93 - 0s 154us/step - loss: 0.3769 - accuracy: 0.8407 - val_loss: 0.1678 - val_accuracy: 0.9341\n",
      "Epoch 45/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.81 - 0s 151us/step - loss: 0.3881 - accuracy: 0.8407 - val_loss: 0.1685 - val_accuracy: 0.9341\n",
      "Epoch 46/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.81 - 0s 153us/step - loss: 0.3538 - accuracy: 0.8434 - val_loss: 0.1676 - val_accuracy: 0.9341\n",
      "Epoch 47/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 1.00 - 0s 152us/step - loss: 0.3576 - accuracy: 0.8489 - val_loss: 0.1677 - val_accuracy: 0.9341\n",
      "Epoch 48/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.81 - 0s 142us/step - loss: 0.3438 - accuracy: 0.8654 - val_loss: 0.1668 - val_accuracy: 0.9341\n",
      "Epoch 49/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.81 - 0s 147us/step - loss: 0.4042 - accuracy: 0.8159 - val_loss: 0.1656 - val_accuracy: 0.9341\n",
      "Epoch 50/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.87 - ETA: 0s - loss: 0.3314 - accuracy: 0.87 - 0s 202us/step - loss: 0.3411 - accuracy: 0.8736 - val_loss: 0.1631 - val_accuracy: 0.9341\n",
      "Epoch 51/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.81 - 0s 156us/step - loss: 0.3408 - accuracy: 0.8516 - val_loss: 0.1620 - val_accuracy: 0.9341\n",
      "Epoch 52/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.81 - 0s 151us/step - loss: 0.3003 - accuracy: 0.8709 - val_loss: 0.1582 - val_accuracy: 0.9341\n",
      "Epoch 53/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.93 - 0s 155us/step - loss: 0.3260 - accuracy: 0.8544 - val_loss: 0.1563 - val_accuracy: 0.9341\n",
      "Epoch 54/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.93 - 0s 155us/step - loss: 0.3381 - accuracy: 0.8681 - val_loss: 0.1551 - val_accuracy: 0.9341\n",
      "Epoch 55/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.81 - 0s 160us/step - loss: 0.3507 - accuracy: 0.8681 - val_loss: 0.1559 - val_accuracy: 0.9341\n",
      "Epoch 56/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 1.00 - 0s 164us/step - loss: 0.3390 - accuracy: 0.8654 - val_loss: 0.1518 - val_accuracy: 0.9341\n",
      "Epoch 57/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.81 - 0s 157us/step - loss: 0.4021 - accuracy: 0.8571 - val_loss: 0.1552 - val_accuracy: 0.9341\n",
      "Epoch 58/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.87 - 0s 165us/step - loss: 0.3431 - accuracy: 0.8736 - val_loss: 0.1581 - val_accuracy: 0.9341\n",
      "Epoch 59/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7251 - accuracy: 0.75 - 0s 162us/step - loss: 0.2849 - accuracy: 0.9038 - val_loss: 0.1564 - val_accuracy: 0.9341\n",
      "Epoch 60/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.87 - 0s 168us/step - loss: 0.3167 - accuracy: 0.8764 - val_loss: 0.1526 - val_accuracy: 0.9341\n",
      "Epoch 61/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.87 - 0s 156us/step - loss: 0.3287 - accuracy: 0.8819 - val_loss: 0.1519 - val_accuracy: 0.9341\n",
      "Epoch 62/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.87 - 0s 152us/step - loss: 0.3569 - accuracy: 0.8297 - val_loss: 0.1543 - val_accuracy: 0.9341\n",
      "Epoch 63/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.93 - 0s 158us/step - loss: 0.2791 - accuracy: 0.8764 - val_loss: 0.1520 - val_accuracy: 0.9341\n",
      "Epoch 64/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.87 - 0s 157us/step - loss: 0.3540 - accuracy: 0.8626 - val_loss: 0.1532 - val_accuracy: 0.9341\n",
      "Epoch 65/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7045 - accuracy: 0.68 - 0s 162us/step - loss: 0.3184 - accuracy: 0.8874 - val_loss: 0.1546 - val_accuracy: 0.9341\n",
      "Epoch 66/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.87 - 0s 155us/step - loss: 0.3370 - accuracy: 0.8681 - val_loss: 0.1560 - val_accuracy: 0.9341\n",
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/10000\n",
      "364/364 [==============================] - ETA: 7s - loss: 0.9856 - accuracy: 0.50 - 1s 2ms/step - loss: 1.6368 - accuracy: 0.4973 - val_loss: 0.5894 - val_accuracy: 0.6703\n",
      "Epoch 2/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8324 - accuracy: 0.56 - 0s 126us/step - loss: 1.0712 - accuracy: 0.5110 - val_loss: 0.4880 - val_accuracy: 0.8681\n",
      "Epoch 3/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.8073 - accuracy: 0.43 - 0s 159us/step - loss: 1.0274 - accuracy: 0.5824 - val_loss: 0.4475 - val_accuracy: 0.8571\n",
      "Epoch 4/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.87 - 0s 155us/step - loss: 0.8864 - accuracy: 0.6236 - val_loss: 0.4250 - val_accuracy: 0.8571\n",
      "Epoch 5/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 2.1363 - accuracy: 0.50 - 0s 154us/step - loss: 0.8114 - accuracy: 0.6099 - val_loss: 0.4099 - val_accuracy: 0.8571\n",
      "Epoch 6/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.62 - 0s 161us/step - loss: 0.8421 - accuracy: 0.5989 - val_loss: 0.3956 - val_accuracy: 0.8681\n",
      "Epoch 7/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.5048 - accuracy: 0.75 - 0s 164us/step - loss: 0.8294 - accuracy: 0.6401 - val_loss: 0.3879 - val_accuracy: 0.8791\n",
      "Epoch 8/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8942 - accuracy: 0.37 - 0s 163us/step - loss: 0.6962 - accuracy: 0.6346 - val_loss: 0.3808 - val_accuracy: 0.8791\n",
      "Epoch 9/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9544 - accuracy: 0.50 - 0s 150us/step - loss: 0.7054 - accuracy: 0.7005 - val_loss: 0.3759 - val_accuracy: 0.8791\n",
      "Epoch 10/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.75 - 0s 153us/step - loss: 0.6426 - accuracy: 0.6786 - val_loss: 0.3706 - val_accuracy: 0.8791\n",
      "Epoch 11/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.81 - 0s 169us/step - loss: 0.6207 - accuracy: 0.7170 - val_loss: 0.3626 - val_accuracy: 0.8791\n",
      "Epoch 12/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.75 - 0s 172us/step - loss: 0.5575 - accuracy: 0.7418 - val_loss: 0.3566 - val_accuracy: 0.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.75 - 0s 165us/step - loss: 0.5627 - accuracy: 0.7198 - val_loss: 0.3512 - val_accuracy: 0.8901\n",
      "Epoch 14/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5704 - accuracy: 0.68 - 0s 147us/step - loss: 0.5443 - accuracy: 0.7335 - val_loss: 0.3444 - val_accuracy: 0.9011\n",
      "Epoch 15/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.81 - 0s 138us/step - loss: 0.4824 - accuracy: 0.7610 - val_loss: 0.3387 - val_accuracy: 0.9011\n",
      "Epoch 16/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.7160 - accuracy: 0.50 - 0s 139us/step - loss: 0.6531 - accuracy: 0.7170 - val_loss: 0.3385 - val_accuracy: 0.9011\n",
      "Epoch 17/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.87 - 0s 137us/step - loss: 0.5478 - accuracy: 0.7473 - val_loss: 0.3325 - val_accuracy: 0.9011\n",
      "Epoch 18/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.87 - 0s 137us/step - loss: 0.4441 - accuracy: 0.7967 - val_loss: 0.3301 - val_accuracy: 0.9011\n",
      "Epoch 19/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.81 - 0s 139us/step - loss: 0.4303 - accuracy: 0.7967 - val_loss: 0.3228 - val_accuracy: 0.8901\n",
      "Epoch 20/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.62 - 0s 136us/step - loss: 0.4671 - accuracy: 0.7967 - val_loss: 0.3199 - val_accuracy: 0.8901\n",
      "Epoch 21/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.75 - 0s 141us/step - loss: 0.4717 - accuracy: 0.7885 - val_loss: 0.3180 - val_accuracy: 0.8791\n",
      "Epoch 22/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.87 - 0s 138us/step - loss: 0.4871 - accuracy: 0.7967 - val_loss: 0.3156 - val_accuracy: 0.8791\n",
      "Epoch 23/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.81 - 0s 137us/step - loss: 0.4042 - accuracy: 0.8022 - val_loss: 0.3140 - val_accuracy: 0.8791\n",
      "Epoch 24/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.81 - 0s 143us/step - loss: 0.4241 - accuracy: 0.8297 - val_loss: 0.3103 - val_accuracy: 0.9011\n",
      "Epoch 25/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.75 - 0s 141us/step - loss: 0.4420 - accuracy: 0.8049 - val_loss: 0.3042 - val_accuracy: 0.9011\n",
      "Epoch 26/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.75 - 0s 143us/step - loss: 0.3451 - accuracy: 0.8516 - val_loss: 0.2968 - val_accuracy: 0.8901\n",
      "Epoch 27/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.81 - 0s 142us/step - loss: 0.4604 - accuracy: 0.7995 - val_loss: 0.2958 - val_accuracy: 0.9011\n",
      "Epoch 28/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.81 - 0s 134us/step - loss: 0.3880 - accuracy: 0.8297 - val_loss: 0.2886 - val_accuracy: 0.8791\n",
      "Epoch 29/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.87 - 0s 140us/step - loss: 0.4047 - accuracy: 0.8187 - val_loss: 0.2854 - val_accuracy: 0.8791\n",
      "Epoch 30/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.68 - 0s 141us/step - loss: 0.3734 - accuracy: 0.8379 - val_loss: 0.2831 - val_accuracy: 0.8791\n",
      "Epoch 31/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.87 - 0s 144us/step - loss: 0.3590 - accuracy: 0.8407 - val_loss: 0.2819 - val_accuracy: 0.8901\n",
      "Epoch 32/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.93 - 0s 137us/step - loss: 0.3530 - accuracy: 0.8681 - val_loss: 0.2784 - val_accuracy: 0.8901\n",
      "Epoch 33/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.68 - 0s 143us/step - loss: 0.3838 - accuracy: 0.8297 - val_loss: 0.2752 - val_accuracy: 0.8901\n",
      "Epoch 34/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.81 - 0s 142us/step - loss: 0.3741 - accuracy: 0.8269 - val_loss: 0.2738 - val_accuracy: 0.8901\n",
      "Epoch 35/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.87 - 0s 137us/step - loss: 0.3626 - accuracy: 0.8489 - val_loss: 0.2698 - val_accuracy: 0.9011\n",
      "Epoch 36/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8199 - accuracy: 0.75 - 0s 141us/step - loss: 0.4738 - accuracy: 0.8269 - val_loss: 0.2690 - val_accuracy: 0.9121\n",
      "Epoch 37/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.81 - 0s 136us/step - loss: 0.3643 - accuracy: 0.8297 - val_loss: 0.2649 - val_accuracy: 0.9121\n",
      "Epoch 38/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.81 - 0s 134us/step - loss: 0.3569 - accuracy: 0.8434 - val_loss: 0.2586 - val_accuracy: 0.9121\n",
      "Epoch 39/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.75 - 0s 139us/step - loss: 0.3295 - accuracy: 0.8324 - val_loss: 0.2525 - val_accuracy: 0.9121\n",
      "Epoch 40/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.75 - 0s 151us/step - loss: 0.3573 - accuracy: 0.8516 - val_loss: 0.2518 - val_accuracy: 0.9121\n",
      "Epoch 41/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.87 - 0s 142us/step - loss: 0.3324 - accuracy: 0.8681 - val_loss: 0.2524 - val_accuracy: 0.9121\n",
      "Epoch 42/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.87 - 0s 153us/step - loss: 0.3242 - accuracy: 0.8984 - val_loss: 0.2535 - val_accuracy: 0.9121\n",
      "Epoch 43/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.93 - 0s 150us/step - loss: 0.3632 - accuracy: 0.8462 - val_loss: 0.2523 - val_accuracy: 0.9121\n",
      "Epoch 44/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 1.00 - 0s 152us/step - loss: 0.3564 - accuracy: 0.8544 - val_loss: 0.2526 - val_accuracy: 0.9121\n",
      "Epoch 45/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.87 - ETA: 0s - loss: 0.3546 - accuracy: 0.84 - 0s 193us/step - loss: 0.3515 - accuracy: 0.8462 - val_loss: 0.2479 - val_accuracy: 0.9121\n",
      "Epoch 46/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.93 - ETA: 0s - loss: 0.3312 - accuracy: 0.85 - 0s 205us/step - loss: 0.3456 - accuracy: 0.8407 - val_loss: 0.2431 - val_accuracy: 0.9121\n",
      "Epoch 47/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 1.00 - ETA: 0s - loss: 0.3236 - accuracy: 0.85 - 0s 223us/step - loss: 0.3061 - accuracy: 0.8654 - val_loss: 0.2391 - val_accuracy: 0.9121\n",
      "Epoch 48/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.87 - ETA: 0s - loss: 0.3348 - accuracy: 0.83 - 0s 212us/step - loss: 0.3142 - accuracy: 0.8434 - val_loss: 0.2396 - val_accuracy: 0.9121\n",
      "Epoch 49/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.93 - ETA: 0s - loss: 0.2721 - accuracy: 0.87 - 0s 216us/step - loss: 0.2923 - accuracy: 0.8654 - val_loss: 0.2400 - val_accuracy: 0.9121\n",
      "Epoch 50/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.81 - ETA: 0s - loss: 0.3002 - accuracy: 0.88 - 0s 199us/step - loss: 0.3009 - accuracy: 0.8791 - val_loss: 0.2428 - val_accuracy: 0.9121\n",
      "Epoch 51/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9535 - accuracy: 0.68 - ETA: 0s - loss: 0.3317 - accuracy: 0.83 - 0s 229us/step - loss: 0.3406 - accuracy: 0.8434 - val_loss: 0.2407 - val_accuracy: 0.9121\n",
      "Epoch 52/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.81 - ETA: 0s - loss: 0.3243 - accuracy: 0.84 - 0s 214us/step - loss: 0.3356 - accuracy: 0.8434 - val_loss: 0.2370 - val_accuracy: 0.9121\n",
      "Epoch 53/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.81 - ETA: 0s - loss: 0.2916 - accuracy: 0.86 - 0s 215us/step - loss: 0.2887 - accuracy: 0.8709 - val_loss: 0.2337 - val_accuracy: 0.9121\n",
      "Epoch 54/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.81 - ETA: 0s - loss: 0.3148 - accuracy: 0.84 - 0s 186us/step - loss: 0.3097 - accuracy: 0.8489 - val_loss: 0.2302 - val_accuracy: 0.9121\n",
      "Epoch 55/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.81 - ETA: 0s - loss: 0.3560 - accuracy: 0.86 - 0s 190us/step - loss: 0.3569 - accuracy: 0.8626 - val_loss: 0.2306 - val_accuracy: 0.9121\n",
      "Epoch 56/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.81 - 0s 170us/step - loss: 0.3579 - accuracy: 0.8681 - val_loss: 0.2309 - val_accuracy: 0.9121\n",
      "Epoch 57/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.87 - ETA: 0s - loss: 0.2878 - accuracy: 0.90 - 0s 190us/step - loss: 0.2830 - accuracy: 0.9011 - val_loss: 0.2294 - val_accuracy: 0.9121\n",
      "Epoch 58/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.81 - ETA: 0s - loss: 0.3178 - accuracy: 0.85 - 0s 196us/step - loss: 0.3150 - accuracy: 0.8626 - val_loss: 0.2299 - val_accuracy: 0.9121\n",
      "Epoch 59/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.81 - ETA: 0s - loss: 0.2912 - accuracy: 0.87 - 0s 188us/step - loss: 0.2941 - accuracy: 0.8681 - val_loss: 0.2293 - val_accuracy: 0.9121\n",
      "Epoch 60/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.75 - 0s 174us/step - loss: 0.3141 - accuracy: 0.8626 - val_loss: 0.2305 - val_accuracy: 0.9121\n",
      "Epoch 61/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.93 - 0s 168us/step - loss: 0.3122 - accuracy: 0.8709 - val_loss: 0.2347 - val_accuracy: 0.9121\n",
      "Epoch 62/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 1.00 - 0s 169us/step - loss: 0.3540 - accuracy: 0.8407 - val_loss: 0.2365 - val_accuracy: 0.9121\n",
      "Epoch 63/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.93 - 0s 163us/step - loss: 0.2692 - accuracy: 0.8791 - val_loss: 0.2329 - val_accuracy: 0.9121\n",
      "Epoch 64/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.87 - 0s 162us/step - loss: 0.3187 - accuracy: 0.8791 - val_loss: 0.2290 - val_accuracy: 0.9121\n",
      "Epoch 65/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.81 - 0s 146us/step - loss: 0.2825 - accuracy: 0.8956 - val_loss: 0.2243 - val_accuracy: 0.9121\n",
      "Epoch 66/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.87 - 0s 151us/step - loss: 0.2793 - accuracy: 0.8654 - val_loss: 0.2233 - val_accuracy: 0.9121\n",
      "Epoch 67/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.87 - 0s 157us/step - loss: 0.2701 - accuracy: 0.8819 - val_loss: 0.2236 - val_accuracy: 0.9121\n",
      "Epoch 68/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 1.00 - 0s 146us/step - loss: 0.3686 - accuracy: 0.8709 - val_loss: 0.2272 - val_accuracy: 0.9121\n",
      "Epoch 69/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.87 - 0s 144us/step - loss: 0.2652 - accuracy: 0.8929 - val_loss: 0.2280 - val_accuracy: 0.9121\n",
      "Epoch 70/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.87 - 0s 142us/step - loss: 0.3174 - accuracy: 0.8764 - val_loss: 0.2255 - val_accuracy: 0.9121\n",
      "Epoch 71/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.75 - 0s 151us/step - loss: 0.3129 - accuracy: 0.8984 - val_loss: 0.2233 - val_accuracy: 0.9121\n",
      "Epoch 72/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.93 - 0s 149us/step - loss: 0.2746 - accuracy: 0.9011 - val_loss: 0.2238 - val_accuracy: 0.9121\n",
      "Epoch 73/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 1.00 - 0s 149us/step - loss: 0.3334 - accuracy: 0.8764 - val_loss: 0.2229 - val_accuracy: 0.9121\n",
      "Epoch 74/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.93 - 0s 163us/step - loss: 0.2981 - accuracy: 0.8709 - val_loss: 0.2267 - val_accuracy: 0.9121\n",
      "Epoch 75/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8035 - accuracy: 0.81 - 0s 169us/step - loss: 0.2908 - accuracy: 0.8681 - val_loss: 0.2253 - val_accuracy: 0.9121\n",
      "Epoch 76/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.87 - 0s 163us/step - loss: 0.3095 - accuracy: 0.8736 - val_loss: 0.2257 - val_accuracy: 0.9121\n",
      "Epoch 77/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 1.00 - 0s 163us/step - loss: 0.2913 - accuracy: 0.8599 - val_loss: 0.2275 - val_accuracy: 0.9121\n",
      "Epoch 78/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.87 - 0s 161us/step - loss: 0.3196 - accuracy: 0.8984 - val_loss: 0.2243 - val_accuracy: 0.9121\n",
      "Epoch 79/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 165us/step - loss: 0.2791 - accuracy: 0.8791 - val_loss: 0.2252 - val_accuracy: 0.9121\n",
      "Epoch 80/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.87 - 0s 156us/step - loss: 0.2902 - accuracy: 0.8654 - val_loss: 0.2252 - val_accuracy: 0.9121\n",
      "Epoch 81/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - 0s 162us/step - loss: 0.3145 - accuracy: 0.8764 - val_loss: 0.2257 - val_accuracy: 0.9121\n",
      "Epoch 82/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.81 - 0s 165us/step - loss: 0.3194 - accuracy: 0.8654 - val_loss: 0.2252 - val_accuracy: 0.9121\n",
      "Epoch 83/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - 0s 159us/step - loss: 0.2616 - accuracy: 0.8709 - val_loss: 0.2265 - val_accuracy: 0.9121\n",
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/10000\n",
      "364/364 [==============================] - ETA: 7s - loss: 3.1623 - accuracy: 0.50 - 1s 2ms/step - loss: 1.3693 - accuracy: 0.5000 - val_loss: 0.6511 - val_accuracy: 0.6484\n",
      "Epoch 2/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.75 - ETA: 0s - loss: 1.0874 - accuracy: 0.57 - 0s 215us/step - loss: 1.0498 - accuracy: 0.5879 - val_loss: 0.5459 - val_accuracy: 0.7582\n",
      "Epoch 3/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.2397 - accuracy: 0.37 - ETA: 0s - loss: 0.8448 - accuracy: 0.59 - 0s 238us/step - loss: 0.8616 - accuracy: 0.5797 - val_loss: 0.4693 - val_accuracy: 0.8681\n",
      "Epoch 4/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.56 - ETA: 0s - loss: 0.9536 - accuracy: 0.58 - 0s 190us/step - loss: 0.9387 - accuracy: 0.5934 - val_loss: 0.4059 - val_accuracy: 0.9451\n",
      "Epoch 5/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.62 - ETA: 0s - loss: 0.8366 - accuracy: 0.61 - 0s 209us/step - loss: 0.8117 - accuracy: 0.6181 - val_loss: 0.3674 - val_accuracy: 0.9451\n",
      "Epoch 6/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.9817 - accuracy: 0.50 - ETA: 0s - loss: 0.8379 - accuracy: 0.63 - 0s 219us/step - loss: 0.8400 - accuracy: 0.6346 - val_loss: 0.3430 - val_accuracy: 0.9670\n",
      "Epoch 7/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7921 - accuracy: 0.68 - ETA: 0s - loss: 0.8063 - accuracy: 0.67 - 0s 230us/step - loss: 0.7985 - accuracy: 0.6758 - val_loss: 0.3278 - val_accuracy: 0.9670\n",
      "Epoch 8/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.75 - ETA: 0s - loss: 0.7387 - accuracy: 0.67 - 0s 189us/step - loss: 0.7322 - accuracy: 0.6758 - val_loss: 0.3151 - val_accuracy: 0.9670\n",
      "Epoch 9/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.62 - ETA: 0s - loss: 0.5878 - accuracy: 0.67 - 0s 192us/step - loss: 0.5849 - accuracy: 0.6703 - val_loss: 0.2997 - val_accuracy: 0.9670\n",
      "Epoch 10/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.81 - 0s 168us/step - loss: 0.6342 - accuracy: 0.7253 - val_loss: 0.2865 - val_accuracy: 0.9670\n",
      "Epoch 11/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - ETA: 0s - loss: 0.8432 - accuracy: 0.68 - ETA: 0s - loss: 0.5579 - accuracy: 0.75 - 0s 190us/step - loss: 0.5454 - accuracy: 0.7610 - val_loss: 0.2730 - val_accuracy: 0.9670\n",
      "Epoch 12/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.75 - ETA: 0s - loss: 0.5689 - accuracy: 0.73 - 0s 190us/step - loss: 0.5615 - accuracy: 0.7390 - val_loss: 0.2619 - val_accuracy: 0.9670\n",
      "Epoch 13/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.75 - 0s 161us/step - loss: 0.5502 - accuracy: 0.7225 - val_loss: 0.2524 - val_accuracy: 0.9670\n",
      "Epoch 14/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.56 - 0s 154us/step - loss: 0.5651 - accuracy: 0.7390 - val_loss: 0.2477 - val_accuracy: 0.9670\n",
      "Epoch 15/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.68 - 0s 156us/step - loss: 0.5656 - accuracy: 0.7500 - val_loss: 0.2394 - val_accuracy: 0.9780\n",
      "Epoch 16/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.81 - 0s 168us/step - loss: 0.5162 - accuracy: 0.7885 - val_loss: 0.2321 - val_accuracy: 0.9670\n",
      "Epoch 17/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.93 - 0s 165us/step - loss: 0.5295 - accuracy: 0.7747 - val_loss: 0.2265 - val_accuracy: 0.9780\n",
      "Epoch 18/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.81 - 0s 165us/step - loss: 0.5339 - accuracy: 0.7637 - val_loss: 0.2236 - val_accuracy: 0.9780\n",
      "Epoch 19/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.81 - 0s 160us/step - loss: 0.4876 - accuracy: 0.7940 - val_loss: 0.2207 - val_accuracy: 0.9780\n",
      "Epoch 20/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.68 - 0s 159us/step - loss: 0.5227 - accuracy: 0.7610 - val_loss: 0.2140 - val_accuracy: 0.9670\n",
      "Epoch 21/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.93 - 0s 150us/step - loss: 0.4978 - accuracy: 0.7500 - val_loss: 0.2111 - val_accuracy: 0.9670\n",
      "Epoch 22/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.81 - 0s 149us/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.2081 - val_accuracy: 0.9670\n",
      "Epoch 23/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.68 - 0s 167us/step - loss: 0.4335 - accuracy: 0.8214 - val_loss: 0.2031 - val_accuracy: 0.9670\n",
      "Epoch 24/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.68 - 0s 147us/step - loss: 0.4871 - accuracy: 0.7692 - val_loss: 0.1977 - val_accuracy: 0.9670\n",
      "Epoch 25/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.81 - 0s 138us/step - loss: 0.4311 - accuracy: 0.7747 - val_loss: 0.1918 - val_accuracy: 0.9780\n",
      "Epoch 26/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.62 - 0s 151us/step - loss: 0.4636 - accuracy: 0.8022 - val_loss: 0.1879 - val_accuracy: 0.9780\n",
      "Epoch 27/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.75 - 0s 144us/step - loss: 0.3891 - accuracy: 0.8214 - val_loss: 0.1815 - val_accuracy: 0.9780\n",
      "Epoch 28/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.68 - 0s 149us/step - loss: 0.4371 - accuracy: 0.7940 - val_loss: 0.1719 - val_accuracy: 0.9780\n",
      "Epoch 29/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.75 - 0s 156us/step - loss: 0.3982 - accuracy: 0.8516 - val_loss: 0.1666 - val_accuracy: 0.9780\n",
      "Epoch 30/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.87 - 0s 152us/step - loss: 0.4645 - accuracy: 0.8132 - val_loss: 0.1632 - val_accuracy: 0.9780\n",
      "Epoch 31/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.87 - 0s 150us/step - loss: 0.3607 - accuracy: 0.7995 - val_loss: 0.1598 - val_accuracy: 0.9780\n",
      "Epoch 32/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.87 - 0s 153us/step - loss: 0.4046 - accuracy: 0.8297 - val_loss: 0.1568 - val_accuracy: 0.9780\n",
      "Epoch 33/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.75 - 0s 146us/step - loss: 0.4652 - accuracy: 0.8214 - val_loss: 0.1562 - val_accuracy: 0.9780\n",
      "Epoch 34/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.87 - 0s 148us/step - loss: 0.3924 - accuracy: 0.8654 - val_loss: 0.1528 - val_accuracy: 0.9780\n",
      "Epoch 35/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.75 - 0s 143us/step - loss: 0.4372 - accuracy: 0.8104 - val_loss: 0.1493 - val_accuracy: 0.9780\n",
      "Epoch 36/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.87 - 0s 138us/step - loss: 0.3617 - accuracy: 0.8379 - val_loss: 0.1439 - val_accuracy: 0.9780\n",
      "Epoch 37/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.93 - 0s 151us/step - loss: 0.3239 - accuracy: 0.8626 - val_loss: 0.1379 - val_accuracy: 0.9780\n",
      "Epoch 38/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.93 - 0s 146us/step - loss: 0.3700 - accuracy: 0.8297 - val_loss: 0.1359 - val_accuracy: 0.9780\n",
      "Epoch 39/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.68 - 0s 159us/step - loss: 0.3435 - accuracy: 0.8571 - val_loss: 0.1323 - val_accuracy: 0.9780\n",
      "Epoch 40/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.81 - 0s 159us/step - loss: 0.3881 - accuracy: 0.8379 - val_loss: 0.1311 - val_accuracy: 0.9780\n",
      "Epoch 41/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.75 - 0s 145us/step - loss: 0.3869 - accuracy: 0.8269 - val_loss: 0.1292 - val_accuracy: 0.9780\n",
      "Epoch 42/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.87 - 0s 153us/step - loss: 0.4214 - accuracy: 0.8049 - val_loss: 0.1298 - val_accuracy: 0.9780\n",
      "Epoch 43/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - 0s 160us/step - loss: 0.3597 - accuracy: 0.8462 - val_loss: 0.1294 - val_accuracy: 0.9780\n",
      "Epoch 44/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.68 - 0s 149us/step - loss: 0.3145 - accuracy: 0.8599 - val_loss: 0.1265 - val_accuracy: 0.9780\n",
      "Epoch 45/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.81 - 0s 148us/step - loss: 0.3698 - accuracy: 0.8516 - val_loss: 0.1248 - val_accuracy: 0.9780\n",
      "Epoch 46/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.81 - 0s 149us/step - loss: 0.3252 - accuracy: 0.8709 - val_loss: 0.1227 - val_accuracy: 0.9780\n",
      "Epoch 47/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.81 - 0s 153us/step - loss: 0.3329 - accuracy: 0.8462 - val_loss: 0.1217 - val_accuracy: 0.9670\n",
      "Epoch 48/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.81 - 0s 161us/step - loss: 0.3453 - accuracy: 0.8599 - val_loss: 0.1227 - val_accuracy: 0.9670\n",
      "Epoch 49/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.93 - 0s 161us/step - loss: 0.3066 - accuracy: 0.8626 - val_loss: 0.1219 - val_accuracy: 0.9670\n",
      "Epoch 50/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - 0s 148us/step - loss: 0.4279 - accuracy: 0.8297 - val_loss: 0.1208 - val_accuracy: 0.9670\n",
      "Epoch 51/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.87 - 0s 153us/step - loss: 0.4169 - accuracy: 0.8544 - val_loss: 0.1222 - val_accuracy: 0.9670\n",
      "Epoch 52/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.93 - 0s 155us/step - loss: 0.3340 - accuracy: 0.8462 - val_loss: 0.1209 - val_accuracy: 0.9670\n",
      "Epoch 53/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.81 - 0s 149us/step - loss: 0.3848 - accuracy: 0.8571 - val_loss: 0.1233 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.81 - 0s 159us/step - loss: 0.3478 - accuracy: 0.8379 - val_loss: 0.1248 - val_accuracy: 0.9670\n",
      "Epoch 55/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.81 - 0s 151us/step - loss: 0.3104 - accuracy: 0.8929 - val_loss: 0.1223 - val_accuracy: 0.9670\n",
      "Epoch 56/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.87 - 0s 142us/step - loss: 0.3037 - accuracy: 0.8819 - val_loss: 0.1198 - val_accuracy: 0.9670\n",
      "Epoch 57/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.93 - 0s 146us/step - loss: 0.3504 - accuracy: 0.8516 - val_loss: 0.1172 - val_accuracy: 0.9670\n",
      "Epoch 58/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.93 - 0s 146us/step - loss: 0.3181 - accuracy: 0.8681 - val_loss: 0.1160 - val_accuracy: 0.9670\n",
      "Epoch 59/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.75 - 0s 144us/step - loss: 0.3885 - accuracy: 0.8407 - val_loss: 0.1160 - val_accuracy: 0.9670\n",
      "Epoch 60/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.93 - 0s 147us/step - loss: 0.3153 - accuracy: 0.8819 - val_loss: 0.1154 - val_accuracy: 0.9670\n",
      "Epoch 61/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.8764 - accuracy: 0.81 - 0s 152us/step - loss: 0.3567 - accuracy: 0.8599 - val_loss: 0.1175 - val_accuracy: 0.9670\n",
      "Epoch 62/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.81 - 0s 143us/step - loss: 0.3291 - accuracy: 0.8626 - val_loss: 0.1167 - val_accuracy: 0.9670\n",
      "Epoch 63/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.87 - 0s 151us/step - loss: 0.3367 - accuracy: 0.8571 - val_loss: 0.1144 - val_accuracy: 0.9670\n",
      "Epoch 64/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.93 - 0s 144us/step - loss: 0.3203 - accuracy: 0.8819 - val_loss: 0.1136 - val_accuracy: 0.9670\n",
      "Epoch 65/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.87 - 0s 151us/step - loss: 0.3616 - accuracy: 0.8571 - val_loss: 0.1131 - val_accuracy: 0.9670\n",
      "Epoch 66/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.87 - 0s 143us/step - loss: 0.3407 - accuracy: 0.8626 - val_loss: 0.1147 - val_accuracy: 0.9670\n",
      "Epoch 67/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.93 - 0s 142us/step - loss: 0.3325 - accuracy: 0.8736 - val_loss: 0.1126 - val_accuracy: 0.9670\n",
      "Epoch 68/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.93 - 0s 138us/step - loss: 0.3476 - accuracy: 0.8516 - val_loss: 0.1117 - val_accuracy: 0.9670\n",
      "Epoch 69/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.93 - 0s 142us/step - loss: 0.3096 - accuracy: 0.8681 - val_loss: 0.1116 - val_accuracy: 0.9670\n",
      "Epoch 70/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.81 - 0s 142us/step - loss: 0.3756 - accuracy: 0.8654 - val_loss: 0.1135 - val_accuracy: 0.9670\n",
      "Epoch 71/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.81 - 0s 164us/step - loss: 0.3036 - accuracy: 0.8544 - val_loss: 0.1111 - val_accuracy: 0.9670\n",
      "Epoch 72/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.87 - ETA: 0s - loss: 0.3920 - accuracy: 0.83 - 0s 184us/step - loss: 0.3860 - accuracy: 0.8379 - val_loss: 0.1111 - val_accuracy: 0.9670\n",
      "Epoch 73/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.3371 - accuracy: 0.86 - 0s 192us/step - loss: 0.3389 - accuracy: 0.8626 - val_loss: 0.1134 - val_accuracy: 0.9670\n",
      "Epoch 74/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.68 - 0s 161us/step - loss: 0.2868 - accuracy: 0.8709 - val_loss: 0.1138 - val_accuracy: 0.9670\n",
      "Epoch 75/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.93 - 0s 164us/step - loss: 0.2783 - accuracy: 0.8956 - val_loss: 0.1108 - val_accuracy: 0.9670\n",
      "Epoch 76/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - 0s 161us/step - loss: 0.2816 - accuracy: 0.8764 - val_loss: 0.1095 - val_accuracy: 0.9670\n",
      "Epoch 77/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.93 - ETA: 0s - loss: 0.3232 - accuracy: 0.86 - 0s 197us/step - loss: 0.3232 - accuracy: 0.8654 - val_loss: 0.1075 - val_accuracy: 0.9670\n",
      "Epoch 78/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.68 - ETA: 0s - loss: 0.3225 - accuracy: 0.82 - 0s 202us/step - loss: 0.3126 - accuracy: 0.8379 - val_loss: 0.1085 - val_accuracy: 0.9670\n",
      "Epoch 79/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.87 - ETA: 0s - loss: 0.3606 - accuracy: 0.85 - 0s 223us/step - loss: 0.3338 - accuracy: 0.8654 - val_loss: 0.1094 - val_accuracy: 0.9670\n",
      "Epoch 80/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 1.6844 - accuracy: 0.81 - ETA: 0s - loss: 0.4455 - accuracy: 0.83 - 0s 234us/step - loss: 0.4392 - accuracy: 0.8297 - val_loss: 0.1152 - val_accuracy: 0.9670\n",
      "Epoch 81/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 1.00 - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - 0s 221us/step - loss: 0.2992 - accuracy: 0.8901 - val_loss: 0.1154 - val_accuracy: 0.9670\n",
      "Epoch 82/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.87 - ETA: 0s - loss: 0.2975 - accuracy: 0.87 - 0s 208us/step - loss: 0.3080 - accuracy: 0.8681 - val_loss: 0.1141 - val_accuracy: 0.9670\n",
      "Epoch 83/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.81 - ETA: 0s - loss: 0.2784 - accuracy: 0.87 - 0s 221us/step - loss: 0.2859 - accuracy: 0.8764 - val_loss: 0.1110 - val_accuracy: 0.9670\n",
      "Epoch 84/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.93 - 0s 169us/step - loss: 0.3391 - accuracy: 0.8242 - val_loss: 0.1114 - val_accuracy: 0.9670\n",
      "Epoch 85/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.81 - 0s 167us/step - loss: 0.2759 - accuracy: 0.8819 - val_loss: 0.1089 - val_accuracy: 0.9670\n",
      "Epoch 86/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.87 - 0s 161us/step - loss: 0.3151 - accuracy: 0.8709 - val_loss: 0.1066 - val_accuracy: 0.9670\n",
      "Epoch 87/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 1.00 - ETA: 0s - loss: 0.2932 - accuracy: 0.88 - 0s 186us/step - loss: 0.3074 - accuracy: 0.8819 - val_loss: 0.1036 - val_accuracy: 0.9670\n",
      "Epoch 88/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7244 - accuracy: 0.81 - 0s 163us/step - loss: 0.3129 - accuracy: 0.8874 - val_loss: 0.1030 - val_accuracy: 0.9670\n",
      "Epoch 89/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.87 - 0s 161us/step - loss: 0.3201 - accuracy: 0.8819 - val_loss: 0.1028 - val_accuracy: 0.9670\n",
      "Epoch 90/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.75 - 0s 168us/step - loss: 0.3058 - accuracy: 0.8791 - val_loss: 0.1025 - val_accuracy: 0.9670\n",
      "Epoch 91/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 1.00 - 0s 159us/step - loss: 0.2809 - accuracy: 0.8681 - val_loss: 0.1019 - val_accuracy: 0.9670\n",
      "Epoch 92/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4042 - accuracy: 0.81 - 0s 166us/step - loss: 0.3270 - accuracy: 0.8516 - val_loss: 0.0998 - val_accuracy: 0.9670\n",
      "Epoch 93/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.87 - 0s 170us/step - loss: 0.2985 - accuracy: 0.8764 - val_loss: 0.1014 - val_accuracy: 0.9670\n",
      "Epoch 94/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.87 - 0s 165us/step - loss: 0.2870 - accuracy: 0.8681 - val_loss: 0.1008 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.93 - 0s 162us/step - loss: 0.3067 - accuracy: 0.8984 - val_loss: 0.0989 - val_accuracy: 0.9670\n",
      "Epoch 96/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.81 - 0s 152us/step - loss: 0.3358 - accuracy: 0.8654 - val_loss: 0.1017 - val_accuracy: 0.9670\n",
      "Epoch 97/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.87 - 0s 143us/step - loss: 0.2531 - accuracy: 0.8984 - val_loss: 0.1019 - val_accuracy: 0.9670\n",
      "Epoch 98/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.81 - 0s 155us/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.1008 - val_accuracy: 0.9670\n",
      "Epoch 99/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.93 - 0s 152us/step - loss: 0.2872 - accuracy: 0.8901 - val_loss: 0.0993 - val_accuracy: 0.9670\n",
      "Epoch 100/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.87 - 0s 148us/step - loss: 0.2893 - accuracy: 0.8819 - val_loss: 0.0987 - val_accuracy: 0.9670\n",
      "Epoch 101/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.81 - 0s 154us/step - loss: 0.2897 - accuracy: 0.8791 - val_loss: 0.0976 - val_accuracy: 0.9670\n",
      "Epoch 102/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 1.00 - 0s 151us/step - loss: 0.3326 - accuracy: 0.8709 - val_loss: 0.0988 - val_accuracy: 0.9670\n",
      "Epoch 103/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.81 - 0s 148us/step - loss: 0.3304 - accuracy: 0.8736 - val_loss: 0.1013 - val_accuracy: 0.9670\n",
      "Epoch 104/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.81 - 0s 155us/step - loss: 0.3364 - accuracy: 0.8626 - val_loss: 0.1048 - val_accuracy: 0.9670\n",
      "Epoch 105/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.81 - 0s 149us/step - loss: 0.2497 - accuracy: 0.8929 - val_loss: 0.1024 - val_accuracy: 0.9670\n",
      "Epoch 106/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.81 - 0s 156us/step - loss: 0.3064 - accuracy: 0.8764 - val_loss: 0.1018 - val_accuracy: 0.9670\n",
      "Epoch 107/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.75 - 0s 146us/step - loss: 0.3740 - accuracy: 0.8434 - val_loss: 0.1070 - val_accuracy: 0.9670\n",
      "Epoch 108/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.75 - 0s 156us/step - loss: 0.3239 - accuracy: 0.8791 - val_loss: 0.1103 - val_accuracy: 0.9670\n",
      "Epoch 109/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.75 - 0s 163us/step - loss: 0.2834 - accuracy: 0.8654 - val_loss: 0.1091 - val_accuracy: 0.9670\n",
      "Epoch 110/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.87 - 0s 157us/step - loss: 0.3309 - accuracy: 0.8681 - val_loss: 0.1091 - val_accuracy: 0.9670\n",
      "Epoch 111/10000\n",
      "364/364 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.93 - 0s 147us/step - loss: 0.3169 - accuracy: 0.8736 - val_loss: 0.1068 - val_accuracy: 0.9670\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "early_stopping_rounds = 10\n",
    "random_state = 1522\n",
    "LGB_PREFDS, XGB_PREFDS, NN_PREFDS = Ensembler(n_splits, early_stopping_rounds, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NN_PREFDS[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.57022065, 0.55294585, 0.40247208, 0.6393956 , 0.6376007 ,\n",
       "        0.50960904, 0.574751  , 0.6830405 , 0.49283525, 0.48820832,\n",
       "        0.5854036 , 0.5346    , 0.5028987 , 0.6121161 , 0.63431627,\n",
       "        0.7052431 , 0.66133547, 0.7170806 , 0.60272336, 0.35079637,\n",
       "        0.7069379 , 0.64473104, 0.6684277 , 0.67253107, 0.67215466,\n",
       "        0.6718306 , 0.56431514, 0.68395567, 0.6608546 , 0.36157095,\n",
       "        0.5433242 , 0.70343256, 0.5832637 , 0.3604563 , 0.5604733 ,\n",
       "        0.683892  , 0.45104   , 0.5098082 , 0.65343094, 0.54954714,\n",
       "        0.40650433, 0.41608125, 0.4717652 , 0.49327046, 0.6069151 ,\n",
       "        0.59648246, 0.6125074 , 0.22451305, 0.64433146, 0.62314206,\n",
       "        0.4416331 , 0.64026165, 0.6400449 , 0.6206864 , 0.38110644,\n",
       "        0.59104747, 0.7345736 , 0.6199364 , 0.46585557, 0.44362682,\n",
       "        0.46650493, 0.4731216 , 0.2541491 , 0.72117555, 0.6026948 ,\n",
       "        0.66400814, 0.7433536 , 0.66620904, 0.76370543, 0.6483397 ,\n",
       "        0.59081286, 0.6547322 , 0.43350106, 0.60163146, 0.4338416 ,\n",
       "        0.55117106, 0.59431946, 0.59772307, 0.5482268 , 0.7297369 ,\n",
       "        0.6473928 , 0.41057098, 0.5883145 , 0.6686008 , 0.42735866,\n",
       "        0.6064872 , 0.37999812, 0.39919528, 0.5868852 , 0.6681781 ,\n",
       "        0.3952868 , 0.6628529 , 0.29204404, 0.7205875 , 0.58146214,\n",
       "        0.63419676, 0.71351486, 0.7646718 , 0.3348273 , 0.70916575,\n",
       "        0.61616665, 0.56495905, 0.6011219 , 0.64603555, 0.65529054,\n",
       "        0.64854115, 0.40734208, 0.9001612 , 0.62447906, 0.5166978 ,\n",
       "        0.6191259 , 0.6163933 , 0.43574306, 0.64047897], dtype=float32),\n",
       " array([0.63513136, 0.41349173, 0.3957768 , 0.6825919 , 0.7397752 ,\n",
       "        0.4476506 , 0.5329861 , 0.68596476, 0.4298496 , 0.4392078 ,\n",
       "        0.53078955, 0.5452084 , 0.61480975, 0.7139563 , 0.80067945,\n",
       "        0.7247343 , 0.580531  , 0.8280987 , 0.5390617 , 0.32664716,\n",
       "        0.6434037 , 0.7574607 , 0.65945137, 0.7077776 , 0.73763907,\n",
       "        0.6602932 , 0.5729075 , 0.79829323, 0.816718  , 0.3469266 ,\n",
       "        0.4740066 , 0.8531419 , 0.6766119 , 0.34325755, 0.5222842 ,\n",
       "        0.7019998 , 0.4537559 , 0.47351074, 0.66276693, 0.5076024 ,\n",
       "        0.3051902 , 0.3873082 , 0.44249678, 0.4462457 , 0.7389033 ,\n",
       "        0.5787938 , 0.599902  , 0.16295779, 0.62008065, 0.74651957,\n",
       "        0.40063936, 0.6497197 , 0.68082994, 0.718647  , 0.34533358,\n",
       "        0.52194035, 0.82294893, 0.82348   , 0.3956517 , 0.5019684 ,\n",
       "        0.36278415, 0.4016405 , 0.22889021, 0.73542553, 0.6597668 ,\n",
       "        0.74354625, 0.76653504, 0.7406229 , 0.782896  , 0.65717715,\n",
       "        0.74672776, 0.6867634 , 0.30651626, 0.6702026 , 0.4169953 ,\n",
       "        0.47205198, 0.5889216 , 0.7301444 , 0.48809266, 0.7985662 ,\n",
       "        0.71880054, 0.3316515 , 0.5842369 , 0.84684026, 0.36735868,\n",
       "        0.55098766, 0.3438896 , 0.37595475, 0.6231632 , 0.73974776,\n",
       "        0.39144498, 0.62326205, 0.23265865, 0.6888943 , 0.5392954 ,\n",
       "        0.6188165 , 0.8237756 , 0.856512  , 0.32306105, 0.8310889 ,\n",
       "        0.6728993 , 0.5944829 , 0.71598655, 0.65672535, 0.7308796 ,\n",
       "        0.6978375 , 0.35156745, 0.8548156 , 0.7189058 , 0.42062315,\n",
       "        0.6515756 , 0.6981723 , 0.28743705, 0.6382097 ], dtype=float32),\n",
       " array([0.5285732 , 0.4638139 , 0.41313142, 0.6206157 , 0.66467065,\n",
       "        0.4899405 , 0.50502104, 0.60780436, 0.5014728 , 0.43275502,\n",
       "        0.51652473, 0.51944554, 0.53468275, 0.66673577, 0.6438492 ,\n",
       "        0.6836103 , 0.5567084 , 0.6213042 , 0.5342831 , 0.37556928,\n",
       "        0.5678737 , 0.6601169 , 0.6108823 , 0.64536256, 0.6516837 ,\n",
       "        0.62974924, 0.5580789 , 0.641503  , 0.69826144, 0.38962597,\n",
       "        0.49219942, 0.6740723 , 0.550729  , 0.45130333, 0.5098324 ,\n",
       "        0.6262365 , 0.46787244, 0.48668757, 0.5942923 , 0.45789376,\n",
       "        0.37597093, 0.42452753, 0.50827855, 0.44644845, 0.64186853,\n",
       "        0.5471965 , 0.62053174, 0.13410905, 0.5993319 , 0.5987575 ,\n",
       "        0.46118578, 0.56769013, 0.61033046, 0.6122571 , 0.3699222 ,\n",
       "        0.5342185 , 0.6850584 , 0.5678954 , 0.4239129 , 0.47939557,\n",
       "        0.3866049 , 0.4618782 , 0.32193953, 0.6789119 , 0.5693275 ,\n",
       "        0.6706117 , 0.71584785, 0.63664275, 0.684703  , 0.63168424,\n",
       "        0.5809655 , 0.6163068 , 0.35474145, 0.55561197, 0.4247807 ,\n",
       "        0.48728752, 0.5729031 , 0.61823267, 0.5161461 , 0.6442245 ,\n",
       "        0.60879266, 0.4291997 , 0.5198685 , 0.64959306, 0.41895014,\n",
       "        0.5534004 , 0.44290745, 0.39512342, 0.5824625 , 0.65800947,\n",
       "        0.4393776 , 0.5962227 , 0.35300118, 0.6689266 , 0.5235245 ,\n",
       "        0.5720482 , 0.6956035 , 0.70175046, 0.37936738, 0.74690485,\n",
       "        0.613002  , 0.54560405, 0.55273217, 0.5597628 , 0.6571104 ,\n",
       "        0.56467307, 0.44095516, 0.70498884, 0.57986444, 0.44559413,\n",
       "        0.5893443 , 0.5894797 , 0.3826442 , 0.60042894], dtype=float32),\n",
       " array([0.5552589 , 0.48934317, 0.45550856, 0.59299314, 0.7555573 ,\n",
       "        0.56257415, 0.53909   , 0.6284553 , 0.55574024, 0.49540615,\n",
       "        0.57615113, 0.54167575, 0.5571269 , 0.695049  , 0.582463  ,\n",
       "        0.68420976, 0.6444021 , 0.6516623 , 0.61324155, 0.38784623,\n",
       "        0.69844466, 0.6795522 , 0.62885183, 0.6098019 , 0.6531038 ,\n",
       "        0.5962579 , 0.5860129 , 0.5882087 , 0.75796413, 0.4135579 ,\n",
       "        0.53406525, 0.6478055 , 0.5682829 , 0.37076244, 0.58864987,\n",
       "        0.5931152 , 0.39514276, 0.507574  , 0.59637743, 0.52749693,\n",
       "        0.41192567, 0.47963312, 0.5091416 , 0.55957305, 0.6163365 ,\n",
       "        0.7189153 , 0.6504389 , 0.22115591, 0.69301736, 0.6287446 ,\n",
       "        0.51177466, 0.6101595 , 0.6335628 , 0.632074  , 0.44408074,\n",
       "        0.58190686, 0.6666259 , 0.52364415, 0.43226844, 0.43557698,\n",
       "        0.4192256 , 0.5499194 , 0.31776494, 0.710276  , 0.61361724,\n",
       "        0.6435565 , 0.7594619 , 0.62386084, 0.7335302 , 0.5843755 ,\n",
       "        0.64804506, 0.58993906, 0.34762803, 0.61936724, 0.33340195,\n",
       "        0.5006271 , 0.67678076, 0.6219188 , 0.56862783, 0.64584523,\n",
       "        0.5959261 , 0.41463387, 0.59145904, 0.67833745, 0.4488587 ,\n",
       "        0.58270556, 0.48497725, 0.4601453 , 0.5696435 , 0.687651  ,\n",
       "        0.44178784, 0.64043844, 0.25397772, 0.7555164 , 0.50463504,\n",
       "        0.6244    , 0.7470256 , 0.6550726 , 0.30121323, 0.5568448 ,\n",
       "        0.6242624 , 0.58193517, 0.5850393 , 0.5805423 , 0.6374859 ,\n",
       "        0.5848509 , 0.45700976, 0.86912405, 0.6259841 , 0.4616547 ,\n",
       "        0.6327307 , 0.6327013 , 0.41155052, 0.61168325], dtype=float32),\n",
       " array([0.54117143, 0.3977059 , 0.4278747 , 0.64422596, 0.7457765 ,\n",
       "        0.49156448, 0.51532143, 0.64918494, 0.4990151 , 0.4906089 ,\n",
       "        0.5435353 , 0.52147055, 0.48872218, 0.7178552 , 0.7440025 ,\n",
       "        0.7027698 , 0.6187209 , 0.7040597 , 0.5735679 , 0.44026366,\n",
       "        0.6968837 , 0.7549746 , 0.58542836, 0.6920532 , 0.68831074,\n",
       "        0.59288836, 0.57503563, 0.7938625 , 0.76356184, 0.45977616,\n",
       "        0.49485794, 0.76718044, 0.5684198 , 0.43750328, 0.5276264 ,\n",
       "        0.66063327, 0.4930616 , 0.48266175, 0.6218014 , 0.5606017 ,\n",
       "        0.4435529 , 0.48964995, 0.5081686 , 0.50459874, 0.7091217 ,\n",
       "        0.63339365, 0.6564259 , 0.3582825 , 0.65350765, 0.6809778 ,\n",
       "        0.4713634 , 0.59739304, 0.66994053, 0.65715444, 0.45180318,\n",
       "        0.5228367 , 0.8193722 , 0.6265149 , 0.35896915, 0.5243038 ,\n",
       "        0.43848577, 0.42992625, 0.41679484, 0.7843652 , 0.5979927 ,\n",
       "        0.68236583, 0.7964698 , 0.65007687, 0.8103895 , 0.618976  ,\n",
       "        0.6552284 , 0.6283499 , 0.40654033, 0.6539296 , 0.45105425,\n",
       "        0.46578464, 0.61088616, 0.65811014, 0.48749554, 0.7416466 ,\n",
       "        0.6322635 , 0.41148165, 0.5324351 , 0.76814044, 0.4571509 ,\n",
       "        0.58010924, 0.45381546, 0.47716781, 0.5725959 , 0.77411246,\n",
       "        0.46944398, 0.6270844 , 0.3520825 , 0.80221355, 0.5155874 ,\n",
       "        0.61313033, 0.80632764, 0.8659425 , 0.4309513 , 0.736706  ,\n",
       "        0.6517688 , 0.6014846 , 0.61954165, 0.6333788 , 0.62826025,\n",
       "        0.5692143 , 0.4625931 , 0.9125161 , 0.66488886, 0.4538863 ,\n",
       "        0.65906584, 0.6094488 , 0.450038  , 0.6181459 ], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_PREFDS[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
